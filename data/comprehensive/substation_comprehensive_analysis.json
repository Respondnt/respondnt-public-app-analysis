{
    "application_name": "Substation",
    "credential-access": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Cloud Secrets Management Stores",
                "technique_stix_id": "cfb525cc-5494-401d-a82b-2539ca46a561",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Craft a malicious Substation configuration (JSON/Jsonnet or hosted config) that adds a utility_secret transform using the aws_secrets_manager retriever, pointing at one or more targeted AWS Secrets Manager ARNs and mapping them to logical IDs (for example, SECRET_DB, SECRET_API).",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type 'utility_secret' configuration (aws_secrets_manager retriever, secret ARN, logical ID)",
                            "SUBSTATION_CONFIG configuration files (Jsonnet/JSON/AppConfig profiles)"
                        ],
                        "related_data": [
                            "Secret ARNs and IDs",
                            "Substation configuration files"
                        ],
                        "notes": "This step assumes the attacker can edit or supply the configuration consumed by a Substation runtime (Lambda, CLI, playground, or GCP Function)."
                    },
                    {
                        "step_id": 2,
                        "description": "In the same configuration, define an HTTP sink transform (for example, send_http_post) that sends a request to an attacker-controlled HTTPS endpoint and embeds the retrieved secrets into headers, query parameters, or body fields via ${SECRET:ID} interpolation.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type 'send_http_post' (URL, headers, optional body template)",
                            "Interpolation syntax '${SECRET:ID}' inside headers/URL/body fields"
                        ],
                        "related_data": [
                            "HTTP request headers containing secret values",
                            "HTTP body fields containing secret values"
                        ],
                        "notes": "Because interpolation happens in arbitrary strings, the attacker can ensure the raw secret value is placed directly into an HTTP header or payload sent to their server."
                    },
                    {
                        "step_id": 3,
                        "description": "Deploy or inject the malicious configuration into a privileged Substation runtime, such as by updating the S3 object or HTTP URL referenced by SUBSTATION_CONFIG for a Lambda, pushing a new AppConfig profile, or providing the config to the playground /run endpoint or CLI commands (substation read/test).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI",
                            "Playground HTTP server",
                            "Configuration loading via internal/file and SUBSTATION_CONFIG"
                        ],
                        "related_interfaces": [
                            "Lambda environment variable SUBSTATION_CONFIG pointing to S3/HTTP/GCS config",
                            "AWS AppConfig configuration profiles consumed by Lambda",
                            "CLI commands: 'substation read [config]', 'substation test [config]', 'substation play' (playground)",
                            "Playground HTTP '/run' endpoint that accepts user-supplied config"
                        ],
                        "related_data": [
                            "SUBSTATION_CONFIG location (S3 key, HTTP URL, local path, AppConfig profile)"
                        ],
                        "notes": "How this is done depends on where configuration is stored (S3, HTTP, AppConfig, local files); the key point is that the attacker controls the effective config used at runtime."
                    },
                    {
                        "step_id": 4,
                        "description": "Trigger execution of the compromised pipeline under an IAM role that has secretsmanager:GetSecretValue and KMS decrypt permissions for the targeted secrets—for example, by sending HTTP POSTs to the public API Gateway → Lambda endpoint, causing a scheduled/EventBridge Lambda run, or invoking the CLI or playground server.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Local ingestion and transformation CLI",
                            "Playground HTTP server"
                        ],
                        "related_interfaces": [
                            "Public HTTP APIs via API Gateway (Lambda proxy POST method)",
                            "EventBridge rule triggering Lambda",
                            "CLI 'substation read' / 'substation test' commands",
                            "Playground HTTP '/run' endpoint"
                        ],
                        "related_data": [
                            "Lambda/API Gateway event payloads",
                            "CLI input data"
                        ],
                        "notes": "The input data itself can be benign; it is only used to cause the pipeline (including utility_secret and send_http_post) to run."
                    },
                    {
                        "step_id": 5,
                        "description": "During pipeline initialization/execution, the utility_secret transform calls AWS Secrets Manager (and KMS as needed) using the Lambda/host IAM role, retrieves the secret values, and stores them in the in-memory secrets cache under the configured logical IDs.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "internal/secrets/aws_secrets_manager retriever (GetSecretValue API)",
                            "Customer-managed KMS keys referenced by Secrets Manager and Lambda"
                        ],
                        "related_data": [
                            "AWS Secrets Manager secret values (passwords, API keys, tokens)",
                            "Decrypted secret plaintext in the in-memory cache"
                        ],
                        "notes": "These GetSecretValue/KMS calls are indistinguishable from legitimate secret retrieval at the API level, since they use the same IAM role and APIs."
                    },
                    {
                        "step_id": 6,
                        "description": "When the send_http_post transform runs, it interpolates ${SECRET:ID} placeholders in headers/URL/body from the in-memory secrets cache, then issues HTTPS requests to the attacker-controlled endpoint, thereby exfiltrating the raw secret values off the platform.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "Transform type 'send_http_post' using internal/http HTTP client",
                            "Outbound HTTPS connection from Lambda/host to attacker-controlled endpoint"
                        ],
                        "related_data": [
                            "Full secret values inside HTTP headers or payloads captured by attacker",
                            "Any additional contextual information (e.g., which pipeline/tenant the secret belongs to) encoded into the request"
                        ],
                        "notes": "Because send_http_post is a normal data sink, these calls may blend in with other outbound HTTP traffic from Substation if such traffic is expected."
                    },
                    {
                        "step_id": 7,
                        "description": "At the attacker-controlled HTTP service, log and store the received secrets and any context (e.g., which endpoint or function invoked the pipeline) for later use in accessing downstream systems (databases, external APIs, other AWS accounts, etc.).",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "Attacker-operated HTTPS endpoint"
                        ],
                        "related_data": [
                            "Captured Secrets Manager values and associated metadata"
                        ],
                        "notes": "Substation is no longer involved at this stage; the attacker now has reusable credentials obtained via the application."
                    }
                ],
                "capabilities_used": [
                    "Secrets retrieval and interpolation",
                    "HTTP enrichment and sending transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "Local ingestion and transformation CLI",
                    "Configuration management and validation CLI",
                    "Playground HTTP server",
                    "AWS Secrets Manager secrets",
                    "Configuration loading via internal/file and SUBSTATION_CONFIG",
                    "AWS and GCP sink transforms (as alternative exfil channels)"
                ],
                "interfaces_used": [
                    "Transform type 'utility_secret' (aws_secrets_manager retriever)",
                    "Interpolation syntax '${SECRET:ID}' in transform configuration strings",
                    "Transform type 'send_http_post' (configurable URL, headers, body)",
                    "SUBSTATION_CONFIG environment variable referencing config on S3/HTTP/GCS/local path",
                    "AppConfig configuration profiles consumed by Substation Lambdas",
                    "API Gateway → Lambda proxy POST method (public, authorization NONE by default)",
                    "CLI commands: 'substation read', 'substation test', 'substation play'",
                    "Playground HTTP '/run' endpoint executing user-supplied configs"
                ],
                "data_accessed": [
                    "AWS Secrets Manager secret values (passwords, API tokens, keys) accessible to Substation IAM roles",
                    "Secret ARNs and logical IDs referenced in utility_secret config",
                    "Decrypted secret plaintext stored in the in-memory secrets cache",
                    "HTTP request logs and payloads at the attacker-controlled endpoint containing exfiltrated secrets"
                ],
                "preconditions_required": [
                    "Attacker can control or meaningfully influence the SUBSTATION_CONFIG used by at least one Substation runtime (Lambda, CLI, playground, or GCP Function).",
                    "The execution role or environment for that runtime has secretsmanager:GetSecretValue and necessary KMS permissions for one or more high-value secrets (per build/terraform/aws/secret/main.tf and KMS modules).",
                    "The runtime has outbound network access to attacker-controlled HTTPS endpoints (via Internet/NAT or other egress).",
                    "Configuration governance does not prevent unreviewed transforms (such as utility_secret or send_http_post to arbitrary domains) from being added to production pipelines."
                ],
                "constraints_encountered": [
                    "Secrets Manager and KMS IAM policies may restrict which secrets a given Substation role can access; secrets outside those policies cannot be retrieved with this technique.",
                    "If outbound egress from Lambdas/private subnets is tightly restricted (for example, to a small allow-listed set of domains), direct exfiltration to arbitrary attacker URLs via send_http_post may be blocked.",
                    "Change-control around SUBSTATION_CONFIG (code review, CI validation, AppConfig validators) may detect or reject configs that send secrets to unexpected endpoints.",
                    "CloudTrail and Secrets Manager audit logs will record unusual GetSecretValue activity; aggressive monitoring could detect spikes or access to rarely used secrets."
                ],
                "evasion_considerations": [
                    "Reuse existing secret IDs and utility_secret patterns already present in legitimate configs so that the additional secret retrievals look routine.",
                    "Throttle or batch secret exfiltration so Secrets Manager access volume remains similar to normal operation.",
                    "Exfiltrate secrets to domains or paths that resemble legitimate third-party APIs already used by the environment, reducing the chance of egress anomaly detection.",
                    "Embed the secret within larger, normal-looking payloads (for example, as a field in JSON logged as telemetry) so that payload inspection tools are less likely to flag it."
                ],
                "comments": "This is the primary and most powerful credential-access vector: Substation’s built-in integration with AWS Secrets Manager, combined with arbitrary outbound HTTP sinks and fully config-driven behavior, makes it straightforward for a malicious config to read and exfiltrate any secret the execution role can access.",
                "credentials_obtained": "Plaintext values of AWS Secrets Manager secrets accessible to the compromised Substation IAM role, such as database passwords, API tokens for third-party services, internal service credentials, or even other AWS access keys stored as secrets."
            },
            {
                "can_achieve": true,
                "technique_name": "Unsecured Credentials",
                "technique_stix_id": "435dfb86-2697-4867-85b5-2fef496c0517",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify a Substation environment where the attacker can directly reach or invoke local developer/operator tooling—most notably a running 'substation play' playground HTTP server—or can run the Substation CLI on a host that holds sensitive environment variables or credentials.",
                        "related_capabilities": [
                            "Playground HTTP server",
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "CLI command 'substation play' (starts playground HTTP server)",
                            "Playground HTTP endpoints '/', '/run', '/test', '/fmt', '/share'",
                            "CLI commands 'substation read', 'substation test', 'substation vet'"
                        ],
                        "related_data": [
                            "Process environment variables on the host (including secrets and tokens)"
                        ],
                        "notes": "This scenario is particularly relevant on developer laptops, CI agents, or bastion hosts where many credentials are stored in environment variables or default AWS/GCP credential locations."
                    },
                    {
                        "step_id": 2,
                        "description": "Craft a Substation configuration that uses utility_secret with the environment_variable retriever to copy specific environment variables (for example, DB_PASSWORD, API_TOKEN, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY) into the secrets cache under logical IDs.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type 'utility_secret' with environment_variable retriever",
                            "Interpolation syntax '${SECRET:ID}' to reference retrieved env vars"
                        ],
                        "related_data": [
                            "Host environment variable values containing credentials or tokens"
                        ],
                        "notes": "The attacker must guess or know likely environment variable names; common patterns (DB_*, API_*, AWS_*) are often sufficient."
                    },
                    {
                        "step_id": 3,
                        "description": "Add transforms that move those secret values into message data or otherwise make them visible in outputs—for example, a transform that sets the message body to a JSON object containing ${SECRET:ID} fields, or configure send_http_post to include them in request headers/body to an attacker endpoint.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform configurations that embed ${SECRET:ID} into JSON payloads or HTTP headers (e.g., send_http_post)"
                        ],
                        "related_data": [
                            "Messages whose data fields now contain raw environment-derived secrets",
                            "HTTP requests containing secret-bearing headers or bodies"
                        ],
                        "notes": "Even without HTTP exfiltration, embedding secrets into message data is enough if the attacker can see the pipeline’s outputs (playground HTTP response, CLI stdout)."
                    },
                    {
                        "step_id": 4,
                        "description": "Invoke the playground /run endpoint or run the CLI with the malicious configuration so that the pipeline executes in the context of the host process that has the targeted environment variables set.",
                        "related_capabilities": [
                            "Playground HTTP server",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Playground HTTP '/run' endpoint accepting config and data",
                            "CLI 'substation read [config]' or 'substation test [config]'"
                        ],
                        "related_data": [
                            "HTTP responses from playground containing pipeline outputs",
                            "CLI stdout/stderr output of transformed messages or test results"
                        ],
                        "notes": "For the playground, the attacker simply POSTs the config and minimal input data to /run and inspects the JSON response body."
                    },
                    {
                        "step_id": 5,
                        "description": "Capture the secrets either directly from the HTTP response/CLI output (if the pipeline writes them into message outputs) or from attacker-controlled HTTP/cloud sinks if send_http_post or cloud send_* transforms were configured for exfiltration.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Playground HTTP responses",
                            "CLI stdout/stderr",
                            "send_http_post to attacker HTTP endpoint",
                            "send_aws_s3/send_gcp_storage to attacker-accessible buckets"
                        ],
                        "related_data": [
                            "Raw environment-derived credentials and tokens now visible in outputs or stored in attacker-controlled cloud resources"
                        ],
                        "notes": "If logs or metrics include these outputs, they may also be retrievable later via CloudWatch Logs or centralized Kinesis/Firehose destinations."
                    },
                    {
                        "step_id": 6,
                        "description": "Optionally, search logs and metrics generated by Substation components (for example, CLI errors, playground logs, CloudWatch Logs from Lambdas) for accidental inclusion of secret values that were interpolated into URLs, file paths, or metric attributes, then retrieve those logs via CloudWatch or centralized logging streams.",
                        "related_capabilities": [
                            "Metrics and observability transforms",
                            "Logging and audit behaviours (implicit in internal/log and CloudWatch integration)"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs groups receiving Lambda stdout/stderr",
                            "CloudWatch Logs subscription filters forwarding logs to central Kinesis/Firehose destinations"
                        ],
                        "related_data": [
                            "Log messages or EMF metric records that may contain secret-bearing strings (for example, URLs with embedded ${SECRET:ID} values resolved at runtime)"
                        ],
                        "notes": "This leverages misconfigurations where operators inadvertently log interpolated configuration strings or message fields containing secrets."
                    }
                ],
                "capabilities_used": [
                    "Secrets retrieval and interpolation",
                    "Playground HTTP server",
                    "Local ingestion and transformation CLI",
                    "Configuration management and validation CLI",
                    "HTTP enrichment and sending transforms",
                    "Metrics and observability transforms"
                ],
                "interfaces_used": [
                    "Transform type 'utility_secret' with environment_variable retriever",
                    "Interpolation syntax '${SECRET:ID}' in transform configs",
                    "CLI commands: 'substation play', 'substation read', 'substation test', 'substation vet'",
                    "Playground HTTP endpoints, especially '/run' that executes user-supplied configs",
                    "CloudWatch Logs groups and subscription destinations receiving Substation logs"
                ],
                "data_accessed": [
                    "Process environment variables on hosts running Substation (e.g., DB passwords, API tokens, cloud credentials)",
                    "Derived message data containing copied environment-variable secrets",
                    "HTTP requests and responses produced by playground/CLI that embed secret values",
                    "CloudWatch Logs entries and centralized log streams that may include secret-bearing strings due to misconfigured logging"
                ],
                "preconditions_required": [
                    "The attacker can access a Substation playground HTTP server or run Substation CLI commands in an environment that also holds sensitive environment variables or default cloud credentials.",
                    "Environment variables actually contain sensitive information (database passwords, API keys, static AWS/GCP credentials, etc.) rather than relying solely on instance roles.",
                    "For log-based leakage, operators must have misconfigured logging, metrics, or error reporting to include interpolated configuration strings or message data that contain secrets.",
                    "The attacker has read access to the relevant logs (CloudWatch Logs, centralized Kinesis/Firehose streams, CI logs, or playground/CLI stderr/stdout)."
                ],
                "constraints_encountered": [
                    "On hardened production Lambdas, long-lived credentials are typically not stored in environment variables; instead, IAM roles and secrets managers are used, which limits the value of this vector to developer/CI/ops environments.",
                    "Access to the playground HTTP server is usually local or tightly restricted; exposure to untrusted networks is often accidental rather than intentional.",
                    "Strong logging hygiene (avoiding logging of configuration values and message payloads) will significantly reduce the chance of secrets appearing in logs or metrics.",
                    "If the host environment is already locked down (no sensitive env vars, short-lived role-based credentials only), this technique may yield little or no credential material."
                ],
                "evasion_considerations": [
                    "Target only a small set of likely environment variables to avoid generating large, suspicious-looking outputs.",
                    "Embed environment-derived secrets within otherwise normal-looking payloads (for example, as nested fields) so they are less obvious in logs or casual inspection.",
                    "Use existing pipelines or test configs where possible, making minimal changes to include a utility_secret step and secret interpolation to avoid drawing attention in code review.",
                    "If reading from logs, focus on log groups and time windows where verbose/debug logging was enabled to maximize yield while limiting the scope of queries."
                ],
                "comments": "This vector abuses the fact that Substation can read arbitrary environment variables and freely move them into its data path and outputs. It is particularly relevant in development, CI, and playground contexts where both Substation and high-value credentials coexist on the same host and where configuration and access controls are weaker.",
                "credentials_obtained": "Any credentials or tokens stored in environment variables accessible to the Substation process—such as database passwords, API keys for third-party services, static cloud access keys—or accidentally logged secrets recovered from CloudWatch or centralized log streams."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Instance Metadata API",
                "technique_stix_id": "19bf235b-8620-4997-b5b4-94e0659ed7c3",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain the ability to supply or modify Substation configuration for a runtime that executes on infrastructure with a metadata service—most directly the GCP Cloud Storage Substation Function, but also any self-managed deployments of the Substation CLI or engine on virtual machines/containers with cloud metadata APIs enabled.",
                        "related_capabilities": [
                            "GCP Cloud Storage Substation Function",
                            "Core Substation transformation engine",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Cloud Function handler configured via SUBSTATION_FUNCTION_HANDLER=GCP_STORAGE",
                            "CLI 'substation read' or embedded substation.New(...) used in custom services"
                        ],
                        "related_data": [
                            "Runtime environment with access to a cloud provider metadata endpoint"
                        ],
                        "notes": "AWS Lambda does not expose the EC2 instance metadata service, so this technique is mainly relevant to GCP Functions and self-managed compute (VMs/containers) where Substation is deployed."
                    },
                    {
                        "step_id": 2,
                        "description": "Create or modify a Substation configuration to add an HTTP enrichment transform (for example, enrich_http_get) that targets the cloud provider’s metadata endpoint URL (such as http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token) and includes any required headers (e.g., Metadata-Flavor: Google). Configure the transform to write the response body into a message field or overwrite message data.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type 'enrich_http_get' (URL template, headers, target field or overwrite behavior)",
                            "internal/http HTTP client used for outbound requests"
                        ],
                        "related_data": [
                            "Cloud metadata API response containing access tokens, service account identity, or other sensitive instance information"
                        ],
                        "notes": "Because Substation’s HTTP client does not enforce a hostname allow-list or TLS pinning, it can reach metadata endpoints just like any other HTTP target, assuming the network path is available."
                    },
                    {
                        "step_id": 3,
                        "description": "Optionally add a subsequent sink transform (e.g., send_http_post, send_aws_s3, send_gcp_storage) that forwards the metadata API response (now in message data or a specific field) to an attacker-controlled HTTP endpoint or cloud storage location.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform type 'send_http_post' to attacker-controlled URL",
                            "Transform types 'send_aws_s3' or 'send_gcp_storage' writing to attacker-accessible buckets"
                        ],
                        "related_data": [
                            "Messages containing metadata-derived access tokens or identity documents"
                        ],
                        "notes": "Even without an explicit sink, if the attacker can see the function’s outputs directly (for example, via a CLI or playground response), they could read the tokens there; using a sink enables stealthier off-host exfiltration."
                    },
                    {
                        "step_id": 4,
                        "description": "Deploy the malicious configuration to the GCP Cloud Function (for example, by updating the object or URL referenced by SUBSTATION_CONFIG) or to a VM/container-based Substation deployment, ensuring that the process runs under a service account with useful permissions (for example, Storage Admin, BigQuery User).",
                        "related_capabilities": [
                            "GCP Cloud Storage Substation Function",
                            "Configuration loading via internal/file and SUBSTATION_CONFIG"
                        ],
                        "related_interfaces": [
                            "Cloud Function configuration referencing SUBSTATION_CONFIG (local path, GCS, HTTP)",
                            "GCP service account attached to the function or VM/container"
                        ],
                        "related_data": [
                            "Service account identity and its associated permissions"
                        ],
                        "notes": "The power of the stolen tokens is determined entirely by the service account’s IAM bindings."
                    },
                    {
                        "step_id": 5,
                        "description": "Trigger the Substation pipeline on that runtime—e.g., by writing a new object into a watched GCS bucket for the Cloud Function or invoking the CLI/daemon on the VM/container—so that the enrich_http_get transform calls the metadata API and captures the response into the message.",
                        "related_capabilities": [
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "GCS object creation events that trigger the Cloud Function",
                            "CLI 'substation read' or equivalent entrypoints"
                        ],
                        "related_data": [
                            "Metadata API HTTP responses (access tokens, instance info) now stored in message data"
                        ],
                        "notes": "The input object content is irrelevant; its role is only to cause the metadata-calling pipeline to execute."
                    },
                    {
                        "step_id": 6,
                        "description": "Receive or retrieve the metadata tokens via the configured sink (HTTP response to attacker, S3/GCS object, etc.) and then use those tokens outside of Substation to access additional cloud resources (for example, GCS buckets, BigQuery datasets, or other GCP APIs) with the permissions of the compromised service account.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Attacker-controlled HTTP endpoint or cloud storage where tokens are written"
                        ],
                        "related_data": [
                            "Short-lived OAuth or service account access tokens, instance identity documents"
                        ],
                        "notes": "This is credential access via the metadata service; subsequent use of the tokens to access cloud APIs falls under follow-on tactics (Valid Accounts, Lateral Movement) and is outside this agent’s scope."
                    }
                ],
                "capabilities_used": [
                    "HTTP enrichment and sending transforms",
                    "Core Substation transformation engine",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI"
                ],
                "interfaces_used": [
                    "Transform type 'enrich_http_get' (HTTP GET enrichment with configurable URL and headers)",
                    "internal/http HTTP client (no built-in hostname allow-listing)",
                    "SUBSTATION_CONFIG-driven pipeline selection in the GCP Cloud Function",
                    "GCS-triggered Cloud Function handler",
                    "CLI-based Substation deployments on VMs/containers (where present)"
                ],
                "data_accessed": [
                    "Cloud provider instance metadata API responses, particularly service account access tokens and identity documents",
                    "Any additional metadata fields returned by the API (project ID, instance/service identity, scopes) that can inform further access"
                ],
                "preconditions_required": [
                    "Substation is deployed on infrastructure with a reachable metadata service (for example, GCP Cloud Functions, GCE VMs, or container clusters with metadata access enabled).",
                    "The attacker can control or significantly influence the SUBSTATION_CONFIG used by that deployment to add/modify HTTP enrichment and sink transforms.",
                    "The runtime has network access to the metadata endpoint (169.254.169.254 or metadata.google.internal) and required request headers are statically configured in the transform.",
                    "The attached service account or instance role has meaningful permissions on cloud resources that the attacker wishes to access."
                ],
                "constraints_encountered": [
                    "AWS Lambda-based Substation deployments do not expose the EC2 instance metadata API, so this technique is ineffective there; it is mainly applicable to GCP Functions and self-managed compute.",
                    "Some hardened environments may disable or tightly restrict access to the metadata service from workloads, blocking requests from Substation’s HTTP client.",
                    "Service accounts may be scoped with minimal privileges, limiting the value of any tokens obtained from metadata.",
                    "Config validation or security review processes might flag direct calls to metadata endpoints in production configurations."
                ],
                "evasion_considerations": [
                    "Hide the metadata call within a broader enrichment chain that also queries legitimate HTTP APIs, so a single additional metadata endpoint is less conspicuous in config reviews.",
                    "Name the metadata-related transform and configuration fields in a way that suggests benign functionality (for example, 'env_discovery' or 'instance_metrics').",
                    "Limit the frequency of metadata queries by gating them with conditions or control messages to avoid anomalous volumes of metadata API traffic.",
                    "Exfiltrate tokens via cloud storage or messaging services that the environment already expects Substation to use, rather than via a clearly suspicious external HTTP domain."
                ],
                "comments": "This vector leverages Substation’s ability to call arbitrary HTTP(S) endpoints from within cloud workloads that have access to instance or function metadata services, enabling theft of short-lived access tokens tied to a privileged service account or instance identity.",
                "credentials_obtained": "Short-lived access tokens or identity credentials from the cloud instance metadata API (for example, GCP service account OAuth tokens) that can be used to authenticate directly to cloud APIs with the permissions of the compromised service account or instance."
            }
        ],
        "summary": "Substation’s most significant credential-access exposures arise from its generic, config-driven nature and deep integration with secret sources. The combination of the utility_secret transform, AWS Secrets Manager integration, environment-variable retrievers, and flexible HTTP/cloud sinks means that any actor who can influence Substation configuration—or operate the CLI/playground in a privileged environment—can convert it into a credential-stealing pipeline.\n\nThe highest-value vector is abusing Cloud Secrets Management Stores: by adding utility_secret and send_http_post transforms to a pipeline running under a role with secretsmanager:GetSecretValue and KMS permissions, an attacker can systematically retrieve and exfiltrate any secrets that role can access. Closely related, the Unsecured Credentials vector shows how environment variables and mismanaged logging can leak credentials when combined with the playground HTTP server, CLI outputs, or logs/metrics. Finally, in environments where Substation runs on compute with a metadata service (notably GCP Cloud Functions), HTTP enrichment transforms can be pointed at the metadata API to steal short-lived service account tokens.\n\nMost other credential-access techniques from ATT&CK (such as password guessing, password spraying, SAML token forgery, or hybrid identity backdoors) are not meaningfully enabled by Substation’s documented capabilities. The primary defenses against the identified vectors are strict control of SUBSTATION_CONFIG sources, limiting who can run playground/CLI in privileged environments, minimizing sensitive data in environment variables and logs, and tightly scoping IAM/secrets so Substation roles have access only to the minimum required secrets and metadata-driven privileges."
    },
    "execution": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Serverless Execution",
                "technique_stix_id": "attack-pattern--e848506b-8484-4410-8017-3d235a52f5b3",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify the public API Gateway endpoint that proxies HTTP POST requests to a Substation Lambda function (for example via DNS, documentation, or scanning).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API POST method integrated with Lambda using AWS_PROXY",
                            "Lambda handler AWS_API_GATEWAY selected via SUBSTATION_LAMBDA_HANDLER"
                        ],
                        "related_data": [
                            "API Gateway invoke URL",
                            "HTTP request path, headers, and body"
                        ],
                        "notes": "Terraform config shows authorization = NONE and no resource policy by default, so the endpoint is internet-reachable unless secured out-of-band."
                    },
                    {
                        "step_id": 2,
                        "description": "Craft HTTP POST bodies that conform to whatever schema the current pipeline expects, or use simple JSON that will still be accepted, in order to drive the Substation pipeline without causing immediate validation errors.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API POST method integrated with Lambda using AWS_PROXY"
                        ],
                        "related_data": [
                            "JSON payload sent in HTTP body",
                            "Message metadata derived from API Gateway event (source IP, request ID)"
                        ],
                        "notes": "Even without knowledge of the full pipeline, generic JSON objects will be wrapped into message.Message and processed."
                    },
                    {
                        "step_id": 3,
                        "description": "Send POST requests to the API Gateway endpoint at chosen frequency; API Gateway forwards each request as an AWS_PROXY event to the Substation Lambda function, causing the Lambda’s handler and configured Substation pipeline to execute for each request.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API POST method integrated with Lambda using AWS_PROXY",
                            "Lambda handler AWS_API_GATEWAY selected via SUBSTATION_LAMBDA_HANDLER"
                        ],
                        "related_data": [
                            "APIGatewayProxyRequest event structure",
                            "Transformed messages produced by the pipeline"
                        ],
                        "notes": "From the attacker’s perspective, each HTTP request is one execution of the container-image Lambda in the target VPC with its IAM role."
                    },
                    {
                        "step_id": 4,
                        "description": "Optionally tune payloads to exercise specific transforms (for example, fields used as KV keys, TTLs, or sink routing keys) so that downstream AWS/GCP sink transforms and HTTP transforms run in ways that benefit the attacker’s broader goals.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Transform types such as send_aws_kinesis_data_stream, send_aws_s3, send_http_post, enrich_http_get/enrich_http_post"
                        ],
                        "related_data": [
                            "Message fields used as keys, ARNs, URLs, and headers by transforms"
                        ],
                        "notes": "This step does not change code, but steers existing transforms via data, potentially driving additional compute in downstream Lambdas, Cloud Functions, or HTTP-based services."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Substation Lambda functions (container-image Lambdas)",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms"
                ],
                "interfaces_used": [
                    "API Gateway REST API POST method integrated with Lambda using AWS_PROXY",
                    "Lambda handler AWS_API_GATEWAY selected via SUBSTATION_LAMBDA_HANDLER",
                    "Substation.Transform over configured transform sequence"
                ],
                "data_accessed": [
                    "HTTP request bodies and headers from external clients",
                    "API Gateway event context (request IDs, source IPs, stage variables) mapped into message metadata",
                    "Any downstream AWS/GCP resources the pipeline is already configured to write to (Kinesis streams, S3 buckets, DynamoDB tables, SQS, SNS, EventBridge, Lambda, GCS)"
                ],
                "preconditions_required": [
                    "The API Gateway → Lambda proxy endpoint is deployed and reachable from the attacker’s network path.",
                    "Terraform’s default authorization = NONE for this method has not been overridden by an authorizer, WAF, or network restrictions that the attacker cannot satisfy.",
                    "The Substation Lambda function is configured as an AWS_API_GATEWAY handler and has an active SUBSTATION_CONFIG determining its pipeline."
                ],
                "constraints_encountered": [
                    "Lambda concurrency limits and API Gateway throttling may cap the rate of executions per account/region.",
                    "If operators later add custom authorizers, resource policies, or WAF rules, the attacker must also obtain valid credentials or originate traffic from allowed networks.",
                    "Pipeline logic itself may reject or drop malformed inputs, limiting what side effects each execution produces, though the code still runs."
                ],
                "evasion_considerations": [
                    "Mimic expected payload schemas and sizes (for example, similar JSON structure to legitimate producers) to avoid anomalous errors and logs.",
                    "Throttle request rate to stay below API Gateway and Lambda alarm thresholds and to blend into normal traffic patterns.",
                    "Randomize request identifiers but keep other headers benign (User-Agent, Accept) to look like standard clients."
                ],
                "comments": "This vector cleanly matches Serverless Execution: unauthenticated HTTP clients can directly trigger execution of Substation’s container-image Lambda with its full pipeline and IAM role. The likely crown jewels enabled by this are the ability to repeatedly run code that has write access to high-value data stores (S3, DynamoDB, Kinesis, Secrets, etc.) and to drive downstream compute through existing sink transforms.",
                "execution_result": "Repeated execution of the Substation Lambda container image and its configured pipeline for arbitrary attacker-controlled HTTP inputs, under the Lambda function’s IAM role and VPC configuration."
            },
            {
                "can_achieve": true,
                "technique_name": "Serverless Execution",
                "technique_stix_id": "attack-pattern--e848506b-8484-4410-8017-3d235a52f5b3",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "A Substation entrypoint (Lambda, Cloud Function, CLI, or playground) starts and loads its configuration from SUBSTATION_CONFIG via internal/file.Get, retrieving an attacker-controlled config that includes a send_aws_lambda transform.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG configuration loading via internal/file.Get (HTTP/S3/GCS/local)",
                            "substation.New(ctx, Config) pipeline construction"
                        ],
                        "related_data": [
                            "Jsonnet/JSON configuration defining transform list",
                            "SUBSTATION_CONFIG URI or path"
                        ],
                        "notes": "The compromise of the config location happens in earlier tactics; here we assume the malicious config is already in use."
                    },
                    {
                        "step_id": 2,
                        "description": "substation.New iterates cfg.Transforms and instantiates a send_aws_lambda Transformer using internal/config.NewAWS to configure an AWS Lambda client based on the function’s IAM role and region.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform type send_aws_lambda",
                            "internal/config.NewAWS for AWS SDK v2 clients"
                        ],
                        "related_data": [
                            "Target Lambda ARN(s) embedded in transform.Settings",
                            "AWS region and optional AssumeRoleARN resolved by NewAWS"
                        ],
                        "notes": "No explicit resource-based policy bypass occurs; the role’s lambda:InvokeFunction scope determines which targets can be hit."
                    },
                    {
                        "step_id": 3,
                        "description": "When the entrypoint receives events (API Gateway, Kinesis, S3, DynamoDB Streams, SNS, SQS, Cloud Storage, or CLI input), it wraps them as Messages and runs them through Substation.Transform so each message eventually reaches the send_aws_lambda transform.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Lambda handlers for AWS_API_GATEWAY, AWS_KINESIS_DATA_STREAM, AWS_S3, AWS_DYNAMODB_STREAM, AWS_SQS, AWS_SNS, etc.",
                            "Cloud Function handler for GCP_STORAGE",
                            "substation.Transform over configured transform sequence"
                        ],
                        "related_data": [
                            "Event payloads and metadata (ARNs, timestamps, partition keys, S3/GCS object locations) mapped into message.Message objects"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "For each batch/key defined in the transform config, send_aws_lambda asynchronously invokes the target Lambda function(s) with message payloads as the event body, using the current execution role’s permissions.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform type send_aws_lambda",
                            "AWS Lambda Invoke API via SDK (lambda:InvokeFunction)"
                        ],
                        "related_data": [
                            "Message payloads serialized to JSON for downstream Lambdas",
                            "Target Lambda ARNs",
                            "Invocation type (e.g., Event) encoded in transform settings"
                        ],
                        "notes": "Because invocation is asynchronous, the upstream pipeline often does not see target function results, only success/failure of the invoke calls."
                    },
                    {
                        "step_id": 5,
                        "description": "Each targeted Lambda function executes its own handler code with its configured IAM role and environment, potentially granting the attacker more privileged compute (for example, a function with broad access to S3, DynamoDB, or Secrets).",
                        "related_capabilities": [
                            "Substation Lambda functions (container-image Lambdas)",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "AWS Lambda service executing target function handlers"
                        ],
                        "related_data": [
                            "Downstream Lambda environment variables and IAM-attached permissions",
                            "Any data those Lambdas read/write in S3, DynamoDB, Kinesis, etc."
                        ],
                        "notes": "What the downstream Lambda does (discovery, exfiltration, persistence) is outside the Execution scope but is enabled by this vector."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "AWS and GCP sink transforms",
                    "Secrets retrieval and interpolation"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG-based configuration loading via internal/file.Get",
                    "Transform type send_aws_lambda",
                    "AWS Lambda Invoke API via AWS SDK v2",
                    "All configured entrypoint handlers (Lambda, Cloud Function, CLI, playground) that execute pipelines"
                ],
                "data_accessed": [
                    "Substation configuration files specifying send_aws_lambda transforms and target ARNs",
                    "Event payloads used as downstream Lambda inputs",
                    "IAM role credentials attached to the Substation runtime, used implicitly by AWS SDK clients",
                    "Any data the invoked Lambdas subsequently touch in AWS data stores"
                ],
                "preconditions_required": [
                    "Attacker has already gained the ability to modify or control the SUBSTATION_CONFIG artifact (S3 object, HTTP URL, GCS object, local file, or AppConfig configuration) used by a Substation runtime.",
                    "The execution role of the Substation runtime has lambda:InvokeFunction permissions on at least one Lambda function (configured via var.access or inline policies).",
                    "Target Lambdas’ resource-based policies (if any) allow invocation from the Substation role/account."
                ],
                "constraints_encountered": [
                    "IAM policies may restrict which Lambda ARNs can be invoked; attempts outside scope will fail and may generate CloudTrail events.",
                    "If configuration validation (CLI vet/test, validate Lambda, AppConfig validators) is mandatory in the deployment workflow, obviously malicious send_aws_lambda usage may be caught before reaching production.",
                    "Transform error handling means that repeated invoke failures (e.g., AccessDenied) can cause the entire pipeline invocation to fail, generating logs but still representing successful code execution up to that point."
                ],
                "evasion_considerations": [
                    "Use target Lambda ARNs that already exist and appear legitimate in the environment (for example, existing analytics or ETL functions) rather than creating obviously suspicious new functions.",
                    "Place the send_aws_lambda transform late in the pipeline so its presence is less obvious in high-level configs and most message fields are already normalized.",
                    "Throttle invoking events or gate the transform behind benign-looking conditions so only certain messages trigger downstream Lambdas, reducing noise in logs and metrics."
                ],
                "comments": "This is a classic Serverless Execution pattern where a compromised, fully config-driven function becomes a dispatcher for other Lambdas. The crown jewels are downstream Lambdas with broader or different privileges (for example, powerful ETL or admin utilities) that can be turned into attacker-controlled compute through malicious Substation configuration.",
                "execution_result": "Execution of attacker-chosen AWS Lambda functions, invoked asynchronously from Substation pipelines using the Substation runtime’s IAM role, with attacker-controlled payloads."
            },
            {
                "can_achieve": true,
                "technique_name": "Serverless Execution",
                "technique_stix_id": "attack-pattern--e848506b-8484-4410-8017-3d235a52f5b3",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "A Substation runtime (Lambda, Cloud Function, or CLI) loads a configuration that includes sink transforms targeting event-driven services such as EventBridge, Kinesis Data Streams, DynamoDB tables with streams enabled, or GCS buckets tied to Cloud Functions.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform types send_aws_eventbridge, send_aws_kinesis_data_stream, send_aws_dynamodb_put, send_aws_s3, send_gcp_storage",
                            "substation.New(ctx, Config) pipeline construction"
                        ],
                        "related_data": [
                            "Service ARNs / resource names embedded in transform settings",
                            "Batching and partition-key configuration for streams"
                        ],
                        "notes": "Config compromise to point these transforms at sensitive event sources is an earlier-phase action; here we assume those settings are already present."
                    },
                    {
                        "step_id": 2,
                        "description": "As events arrive (e.g., HTTP→Lambda, S3 uploads, Kinesis records, DynamoDB changes, GCS object events, or CLI inputs), the Substation pipeline runs and eventually reaches the configured sink transforms that publish to the chosen services.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Lambda handlers for Kinesis, DynamoDB Streams, S3, SNS, SQS, Firehose, generic AWS_LAMBDA",
                            "Cloud Function handler for GCP_STORAGE",
                            "CLI read/tap commands"
                        ],
                        "related_data": [
                            "Incoming events and metadata mapped to message.Message",
                            "Transformed payloads ready to be published"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "send_aws_eventbridge publishes crafted events to the configured EventBridge bus; matching rules route those events to their targets (such as Lambda functions) which then execute their handlers.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform type send_aws_eventbridge",
                            "AWS EventBridge PutEvents API"
                        ],
                        "related_data": [
                            "EventBridge event bus ARN",
                            "Event detail JSON, detail-type, source fields used for rule matching"
                        ],
                        "notes": "Existing rules for Substation or other workloads can be abused by shaping events to match their patterns."
                    },
                    {
                        "step_id": 4,
                        "description": "send_aws_kinesis_data_stream writes records into Kinesis streams that may already have Lambda or Kinesis Data Analytics consumers, leading to execution of those consumers’ code on attacker-controlled records.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "Transform type send_aws_kinesis_data_stream",
                            "Kinesis PutRecord/PutRecords APIs",
                            "Lambda Kinesis event handlers consuming those streams (if configured)"
                        ],
                        "related_data": [
                            "Stream ARN/name",
                            "Partition keys and record payloads"
                        ],
                        "notes": "The repository defines generic Kinesis ingestion but not specific consumers; however, any existing Substation Lambdas or other stream processors on these streams will execute."
                    },
                    {
                        "step_id": 5,
                        "description": "send_aws_dynamodb_put writes items into DynamoDB tables with streams enabled; downstream consumers (potentially Substation-based Lambdas defined elsewhere) that subscribe to those streams will execute for each new change record.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "Transform type send_aws_dynamodb_put",
                            "DynamoDB BatchWriteItem/PutItem APIs",
                            "DynamoDB Streams and any Lambda/event processor subscribed to them"
                        ],
                        "related_data": [
                            "DynamoDB table name/ARN",
                            "Item attribute values constructed from message data"
                        ],
                        "notes": "Terraform explicitly supports DynamoDB Streams and IAM policies for stream consumption; those consumers represent additional compute the attacker can drive."
                    },
                    {
                        "step_id": 6,
                        "description": "send_gcp_storage uploads objects into GCS buckets that may have Cloud Storage–triggered Cloud Functions (including the provided Substation Cloud Function) attached, causing those functions to execute on the attacker-supplied object contents.",
                        "related_capabilities": [
                            "GCP Cloud Storage Substation Function",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform type send_gcp_storage",
                            "GCS storage.objects.create API",
                            "Cloud Function handler for GCP_STORAGE"
                        ],
                        "related_data": [
                            "GCS bucket and object path",
                            "Serialized payload written as object content"
                        ],
                        "notes": "The included Cloud Function is one such consumer; other organization-specific functions may also be attached."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "AWS and GCP sink transforms"
                ],
                "interfaces_used": [
                    "Transform types send_aws_eventbridge, send_aws_kinesis_data_stream, send_aws_dynamodb_put, send_aws_s3, send_gcp_storage",
                    "AWS EventBridge PutEvents API",
                    "Kinesis PutRecord/PutRecords APIs",
                    "DynamoDB PutItem/BatchWriteItem APIs",
                    "GCS storage.objects.create API",
                    "Lambda and Cloud Function event handlers attached to these resources"
                ],
                "data_accessed": [
                    "Configuration specifying target event buses, streams, tables, and buckets",
                    "Transformed message payloads used as event/record/object bodies",
                    "Metadata such as partition keys, event sources, and detail-types used for routing by EventBridge and stream consumers"
                ],
                "preconditions_required": [
                    "Substation configurations in use include sink transforms pointing at resources that have event-driven compute attached (EventBridge rules with Lambda targets, Kinesis streams with consumers, DynamoDB Streams with processors, GCS buckets with Cloud Functions).",
                    "The Substation runtime’s IAM role has permissions to publish to these services (events:PutEvents, kinesis:PutRecord/PutRecords, dynamodb:PutItem/BatchWriteItem, storage.objects.create, etc.).",
                    "Event-driven targets (Lambdas, Cloud Functions, analytics jobs) are deployed and active on those resources."
                ],
                "constraints_encountered": [
                    "If IAM policies on the Substation role are tightly scoped, only a subset of potential event sources can be abused for execution.",
                    "EventBridge rules, stream consumers, and Cloud Function triggers must already exist; the application itself does not create them dynamically from pipeline config.",
                    "Service-specific limits (record sizes, batch sizes, throughput limits) constrain how much data can be pushed per execution but not whether execution occurs."
                ],
                "evasion_considerations": [
                    "Shape EventBridge event sources, detail-types, and payloads to match legitimate application patterns so rule-triggered Lambdas see apparently normal traffic.",
                    "Use existing production streams/tables/buckets rather than introducing new ones that may attract attention in deployment change reviews.",
                    "Throttle the rate of event publication to stay within normal utilization bands for Kinesis, DynamoDB, and GCS to avoid autoscaling anomalies that may be investigated."
                ],
                "comments": "This vector leverages Substation as a broker into other serverless and stream-oriented compute via event-driven services. The high-value outcome is the ability to indirectly drive execution in multiple downstream Lambdas/Cloud Functions that may each have distinct access to sensitive S3/DynamoDB/Kinesis/Secrets data or privileged control-plane actions.",
                "execution_result": "Indirect execution of multiple downstream serverless functions and stream consumers by publishing crafted events, records, and objects via Substation sink transforms into EventBridge, Kinesis, DynamoDB Streams, and GCS-triggered pipelines."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud API",
                "technique_stix_id": "attack-pattern--55bb4471-ff1f-43b4-88c1-c9384ec47abf",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Locate a running instance of the Substation playground HTTP server (substation play) that exposes the /run (and potentially /test) endpoints to the attacker’s network, with no or weak authentication.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "substation play HTTP server endpoints ('/','/run','/test','/demo','/fmt','/share') as defined in cmd/substation/playground.go"
                        ],
                        "related_data": [
                            "Playground base URL and paths"
                        ],
                        "notes": "Although intended for development, if deployed in shared or cloud environments this can become a remotely accessible API for executing Substation pipelines."
                    },
                    {
                        "step_id": 2,
                        "description": "Prepare a request body for /run that includes (a) a malicious Substation configuration with HTTP and/or AWS/GCP sink transforms (for example, send_aws_lambda, send_aws_eventbridge, send_http_post) and (b) a set of environment variables to be applied for this run, such as AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, and AWS_REGION.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "/run endpoint which temporarily sets process environment variables from user input before executing a pipeline"
                        ],
                        "related_data": [
                            "Jsonnet/JSON pipeline configuration embedded in the request",
                            "Environment variable key/value pairs, including cloud API credentials",
                            "Test input messages included in the request body"
                        ],
                        "notes": "Per the analysis, /run temporarily mutates process env vars from user input, directly feeding AWS/GCP SDK credential resolution."
                    },
                    {
                        "step_id": 3,
                        "description": "Send the crafted /run request to the playground server; the handler applies the supplied environment variables to the process, compiles/builds the provided configuration, and constructs a Substation pipeline that includes the configured cloud or HTTP sink transforms.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "/run endpoint",
                            "substation.New(ctx, Config) pipeline construction",
                            "AWS SDK default credential chain inside internal/config.NewAWS"
                        ],
                        "related_data": [
                            "Effective environment variables after override",
                            "Compiled substation.Config including sink transforms"
                        ],
                        "notes": "The AWS/GCP SDKs will preferentially use env-based credentials, meaning the attacker’s supplied keys are now used for all outbound cloud API calls during this run."
                    },
                    {
                        "step_id": 4,
                        "description": "As the /run handler executes the pipeline over attacker-supplied test messages, the configured sink transforms invoke cloud APIs (for example, lambda:InvokeFunction, events:PutEvents, kinesis:PutRecords, storage.objects.create) and/or arbitrary HTTP(S) endpoints using the supplied credentials and parameters.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Transform types send_aws_lambda, send_aws_eventbridge, send_aws_kinesis_data_stream, send_aws_s3, send_aws_dynamodb_put, send_gcp_storage, send_http_post, enrich_http_get, enrich_http_post",
                            "AWS SDK v2 APIs via internal/config.NewAWS",
                            "retryablehttp-based HTTP client in internal/http"
                        ],
                        "related_data": [
                            "Cloud resource ARNs and URLs targeted in transform settings",
                            "Payloads and headers derived from test messages and secrets"
                        ],
                        "notes": "This effectively turns the playground into a remotely controlled cloud API client, similar in spirit to tools like Pacu using AWS CLI/SDKs."
                    },
                    {
                        "step_id": 5,
                        "description": "Optionally repeat /run invocations with different configurations and environment variables to perform iterative cloud actions, such as invoking attacker-controlled Lambdas, writing to sensitive data stores, or calling HTTP-based management APIs in other environments.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "/run endpoint",
                            "All configured transform types that invoke external services"
                        ],
                        "related_data": [
                            "Sequences of configurations and env var sets representing evolving cloud API operations"
                        ],
                        "notes": "From an adversary’s view, this is a flexible, authenticated cloud API pivot that runs from the playground host’s network location and logs."
                    }
                ],
                "capabilities_used": [
                    "Configuration management and validation CLI",
                    "Local ingestion and transformation CLI",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms",
                    "Secrets retrieval and interpolation"
                ],
                "interfaces_used": [
                    "substation play HTTP server /run endpoint that sets process environment variables from user input",
                    "Transform types send_aws_lambda, send_aws_eventbridge, send_aws_kinesis_data_stream, send_aws_s3, send_aws_dynamodb_put, send_gcp_storage, send_http_post, enrich_http_get, enrich_http_post",
                    "AWS SDK v2 clients created via internal/config.NewAWS",
                    "retryablehttp HTTP client in internal/http"
                ],
                "data_accessed": [
                    "Attacker-supplied JSON/Jsonnet configuration and test messages",
                    "Environment variables set via /run, including potential cloud credentials and region settings",
                    "Cloud resource identifiers and URLs used in transform settings",
                    "Any cloud resources reached by those transforms using the supplied credentials"
                ],
                "preconditions_required": [
                    "The substation play HTTP server is running in an environment reachable by the attacker, with /run exposed and not adequately authenticated or restricted.",
                    "The attacker can supply arbitrary configuration and environment variables in /run requests (as designed for development).",
                    "The supplied credentials (or the playground host’s own IAM role/credentials) have meaningful permissions in the target AWS/GCP environment."
                ],
                "constraints_encountered": [
                    "Environment-variable overrides are temporary for the duration of each /run call and do not persist beyond it, so each desired set of cloud actions must be re-specified per request.",
                    "If the host environment lacks outbound network access to specific cloud APIs or HTTP endpoints, those particular actions will fail even though the pipeline executes.",
                    "Application logs for the playground and cloud audit logs (CloudTrail, GCP audit logs) will reflect these operations, potentially aiding detection."
                ],
                "evasion_considerations": [
                    "Blend malicious cloud API calls into nominal-looking test configurations (for example, combining benign transforms with a few targeted sink calls).",
                    "Use cloud accounts and roles that the defenders expect to see from that playground host, to avoid anomalous principal usage.",
                    "Throttle /run invocations and avoid obviously malicious resource names or ARNs to reduce operator suspicion if logs are reviewed."
                ],
                "comments": "This vector maps closely to Cloud API: the playground effectively becomes a remotely controllable cloud API client that can execute arbitrary AWS/GCP operations (including invoking Lambdas or writing to trigger resources) using attacker-supplied credentials and configuration. The key crown jewels here are whatever those credentials and transforms can reach—often production S3/Kinesis/DynamoDB, and serverless functions with high privilege.",
                "execution_result": "Execution of arbitrary cloud API operations (including serverless invocations and data-plane writes) from the playground host by driving Substation pipelines with attacker-specified configuration and environment-based credentials over the /run HTTP interface."
            },
            {
                "can_achieve": true,
                "technique_name": "Malicious Image",
                "technique_stix_id": "attack-pattern--b0c74ef9-c61e-4986-88cb-78da98a355ec",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Build a container image that embeds Substation (optionally) but includes additional or replacement malicious entrypoint logic (for example, a crypto-miner or a remote access agent) to run whenever the Lambda container starts.",
                        "related_capabilities": [
                            "Substation Lambda functions (container-image Lambdas)",
                            "ECR repositories storing Lambda container images"
                        ],
                        "related_interfaces": [
                            "Docker/OCI image build process targeting the ECR repository used by aws_lambda_function.lambda_function"
                        ],
                        "related_data": [
                            "Dockerfile and image layers containing malicious binaries and scripts"
                        ],
                        "notes": "The malicious code can run before or instead of invoking the normal Substation handler, but that behavior is controlled by the image’s entrypoint/CMD."
                    },
                    {
                        "step_id": 2,
                        "description": "Push the crafted image to the ECR repository defined in build/terraform/aws/ecr/main.tf, using appropriate repository name and a new immutable tag.",
                        "related_capabilities": [
                            "ECR repositories storing Lambda container images"
                        ],
                        "related_interfaces": [
                            "ECR APIs (ecr:BatchCheckLayerAvailability, ecr:PutImage, etc.)"
                        ],
                        "related_data": [
                            "ECR repository ARN/name",
                            "Image manifest and tag reference"
                        ],
                        "notes": "Terraform config enables immutable tags and scan-on-push, but scans generally do not block pushes; they only surface findings."
                    },
                    {
                        "step_id": 3,
                        "description": "Update the Lambda function configuration (for example, via Terraform, CloudFormation, or direct AWS API) so that aws_lambda_function.lambda_function references the malicious image_uri in ECR.",
                        "related_capabilities": [
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "Lambda UpdateFunctionCode/UpdateFunctionConfiguration APIs or deployment pipelines that manage image_uri"
                        ],
                        "related_data": [
                            "Lambda function ARN and new image_uri pointing to the malicious image"
                        ],
                        "notes": "This configuration change may be part of a compromised CI/CD pipeline or manual admin action."
                    },
                    {
                        "step_id": 4,
                        "description": "When the Lambda function next cold starts, AWS Lambda pulls the new image from ECR and executes its entrypoint, running the malicious code inside the configured VPC and with the Lambda’s IAM execution role and environment variables.",
                        "related_capabilities": [
                            "Substation Lambda functions (container-image Lambdas)",
                            "VPC with public and private subnets, NAT, and Internet gateway"
                        ],
                        "related_interfaces": [
                            "Lambda service integration with ECR (ecr:BatchGetImage, ecr:GetDownloadUrlForLayer)",
                            "Lambda execution environment startup sequence"
                        ],
                        "related_data": [
                            "Lambda execution role permissions across S3, DynamoDB, Kinesis, SQS, SNS, Secrets, KMS, etc. (granted via var.access and inline policies)",
                            "Any sensitive environment variables (for example, SUBSTATION_CONFIG, appconfig settings) available to the container"
                        ],
                        "notes": "At this point, arbitrary attacker code is running under the guise of a Substation Lambda, regardless of whether Substation itself is invoked."
                    },
                    {
                        "step_id": 5,
                        "description": "Use existing triggers (API Gateway, EventBridge, S3/Kinesis/SQS/SNS events, AppConfig validators) to cause repeated cold and warm executions of the compromised Lambda, allowing the malicious image to perform ongoing tasks such as data theft, crypto-mining, or lateral movement.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "EventBridge rule triggering Lambda",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "API Gateway → Lambda proxy integration",
                            "EventBridge → Lambda rule target",
                            "Other event sources wired to this function"
                        ],
                        "related_data": [
                            "Incoming event payloads, which can be ignored or minimally processed by the malicious code"
                        ],
                        "notes": "The compromised image can treat incoming events as mere execution triggers without honoring the Substation semantics."
                    }
                ],
                "capabilities_used": [
                    "Substation Lambda functions (container-image Lambdas)",
                    "ECR repositories storing Lambda container images",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "EventBridge rule triggering Lambda",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "ECR repository for Substation Lambda images",
                    "Lambda image-based function configuration (image_uri)",
                    "API Gateway → Lambda proxy integration",
                    "EventBridge → Lambda rule target"
                ],
                "data_accessed": [
                    "Lambda execution role credentials and their permissions over S3, DynamoDB, Kinesis, SQS, SNS, Secrets Manager, and KMS keys",
                    "Environment variables for the Lambda (including SUBSTATION_CONFIG, AppConfig identifiers, and any custom secrets)",
                    "Any data in the VPC-reachable networks and services that the compromised Lambda can connect to via NAT/IGW"
                ],
                "preconditions_required": [
                    "The attacker has obtained credentials or CI/CD control sufficient to push images to the relevant ECR repository and to update the Lambda function’s image_uri (for example, administrator-level access or a compromised deployment pipeline).",
                    "Defenders have not locked down deployment so that only vetted images/tags can be referenced in Lambda functions.",
                    "The Lambda function in question is triggered in production (via API Gateway, events, or schedules), so the malicious image will actually execute."
                ],
                "constraints_encountered": [
                    "ECR is configured with immutable tags and scan-on-push; while this does not prevent malicious images, it forces the attacker to introduce new tags and may generate vulnerability or anomaly findings.",
                    "Infrastructure change management (Terraform/CloudFormation drift detection, code review) may detect unauthorized updates to image_uri or new images in the repository.",
                    "The Lambda’s IAM role may not be highly privileged; execution is still constrained to actions allowed by that role and its network environment."
                ],
                "evasion_considerations": [
                    "Mimic existing image structure and naming conventions, embedding malicious functionality alongside legitimate Substation binaries to appear as a normal version bump.",
                    "Ensure the malicious image passes basic vulnerability scans (or looks similar to previous images) to avoid automated rejection by security tooling.",
                    "Throttle resource-intensive behavior (such as mining or scanning) to avoid obvious spikes in Lambda duration, errors, or CloudWatch metrics."
                ],
                "comments": "This is a direct realization of the Malicious Image technique in a serverless/container context: compromised container images cause arbitrary code to run whenever Substation Lambdas are invoked. The primary crown jewels at risk are the broad IAM privileges and data-plane access those Lambdas already possess, repurposed for attacker goals.",
                "execution_result": "Arbitrary attacker-controlled code runs inside the Substation Lambda container whenever the function is invoked, under its existing IAM role and VPC/network context, regardless of the intended Substation pipeline."
            },
            {
                "can_achieve": true,
                "technique_name": "User Execution",
                "technique_stix_id": "attack-pattern--8c32eb4d-805f-4fc5-bf60-c4d476c131b5",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Deliver a seemingly legitimate Substation configuration (Jsonnet/JSON) to a developer or CI pipeline operator, for example as a proposed pipeline, test case, or sample, which actually contains side-effectful transforms such as send_aws_lambda, send_http_post to attacker infrastructure, or high-privilege AWS/GCP sinks.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Configuration files consumed by substation build/test/vet/read commands"
                        ],
                        "related_data": [
                            "Malicious transform list and settings embedded in configuration",
                            "Resource ARNs and URLs for attacker-controlled endpoints or Lambdas"
                        ],
                        "notes": "Convincing the user that this config is benign is the social-engineering component typical of User Execution."
                    },
                    {
                        "step_id": 2,
                        "description": "The victim runs a CLI command such as `substation test`, `substation read`, or `substation play` locally or in CI, pointing at the attacker-supplied configuration and potentially using real cloud credentials (via environment variables, shared credentials file, or instance/role).",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "substation test [path]",
                            "substation read [config] --file/--http/--aws s3://...",
                            "substation play (local HTTP interface)"
                        ],
                        "related_data": [
                            "AWS/GCP credentials available to the CLI process",
                            "Input data paths/URLs used in the test"
                        ],
                        "notes": "The CLI inherits the operator’s credentials and network location, which may have broad access to production accounts or internal networks."
                    },
                    {
                        "step_id": 3,
                        "description": "The CLI command compiles Jsonnet (if used), loads the JSON configuration, and constructs a Substation pipeline via substation.New, instantiating all configured transforms including malicious sinks and HTTP calls.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "substation.New(ctx, Config) pipeline construction",
                            "internal/config.NewAWS for SDK clients",
                            "internal/http for HTTP transforms"
                        ],
                        "related_data": [
                            "Compiled substation.Config and config.Config entries",
                            "Resolved cloud resource identifiers and HTTP URLs"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "During the test or read run, the CLI executes the pipeline over sample or real input data, invoking malicious transforms that call cloud APIs (e.g., lambda:InvokeFunction, events:PutEvents, S3/DynamoDB/SQS/SNS writes) or send HTTP(S) requests to attacker-controlled endpoints, effectively running the attacker’s chosen compute in the victim’s cloud environment.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Transform types send_aws_lambda, send_aws_s3, send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_sns, send_aws_sqs, send_gcp_storage, send_http_post, enrich_http_get, enrich_http_post"
                        ],
                        "related_data": [
                            "Input records passed through the pipeline",
                            "Cloud and HTTP endpoints specified by the attacker in the config"
                        ],
                        "notes": "This mirrors how adversaries coerce users to run malware or admin tools in other campaigns, but here the payload is an apparently benign data pipeline."
                    },
                    {
                        "step_id": 5,
                        "description": "If CI pipelines or scheduled jobs also run these CLI commands with production-like credentials, the malicious configuration can repeatedly trigger these side-effectful transforms during automated runs, providing the attacker with ongoing execution opportunities.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "CI/CD jobs invoking substation build/test/vet/read"
                        ],
                        "related_data": [
                            "CI environment variables (including cloud credentials, secrets, and endpoints)",
                            "Repeatedly processed test/validation datasets"
                        ],
                        "notes": "In such cases, execution is no longer purely interactive but still originates from initial user/organization acceptance of the malicious config."
                    }
                ],
                "capabilities_used": [
                    "Configuration management and validation CLI",
                    "Local ingestion and transformation CLI",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms"
                ],
                "interfaces_used": [
                    "substation test / build / vet commands",
                    "substation read CLI with file/HTTP/S3 sources",
                    "substation play HTTP server (if used by developers)",
                    "Transform types that call AWS/GCP or HTTP endpoints"
                ],
                "data_accessed": [
                    "Developer or CI cloud credentials and associated IAM permissions",
                    "Configuration contents that specify attacker-chosen sinks and endpoints",
                    "Any input data used during tests (which may themselves be sensitive logs or records)"
                ],
                "preconditions_required": [
                    "A developer, operator, or CI pipeline must be convinced to use the attacker-supplied configuration in their normal Substation workflows.",
                    "The environment in which the CLI runs must have valid AWS/GCP credentials and network access to relevant cloud APIs or attacker infrastructure.",
                    "Security review of configurations (for example, vet/test outputs) must not flag the malicious transforms as inappropriate before they are executed."
                ],
                "constraints_encountered": [
                    "Local and CI environments may use separate, limited cloud accounts; execution is constrained to whatever permissions those credentials grant.",
                    "Some organizations may run tests against isolated sandboxes with no access to production resources, limiting the damage of this vector.",
                    "Transform errors (for example, due to missing permissions or bad ARNs) may cause pipeline or test failures that alert operators."
                ],
                "evasion_considerations": [
                    "Hide malicious sinks among otherwise legitimate transforms, using reasonable resource names and ARNs that match the target organization’s naming patterns.",
                    "Scope per-run side effects small enough that tests still appear to succeed (for example, writing a few records or invoking a single Lambda per run).",
                    "Use HTTP endpoints that appear to belong to trusted services (for example, internal-looking hostnames) while still under attacker control."
                ],
                "comments": "This is a pure User Execution vector: the code path only runs because a human or CI system agrees to execute attacker-supplied Substation configs with real credentials. It can be used to trigger further serverless execution, data movement, or external HTTP-based compute, placing production data and IAM roles at risk.",
                "execution_result": "Execution of attacker-chosen Substation pipelines (including cloud and HTTP sinks) under developer or CI credentials, leading to cloud API operations and potential downstream Lambda/Cloud Function invocations initiated from trusted environments."
            },
            {
                "can_achieve": false,
                "technique_name": "Command and Scripting Interpreter",
                "technique_stix_id": "attack-pattern--7385dfaf-6886-4229-9ecd-6fd678040830",
                "method_steps": [],
                "capabilities_used": [],
                "interfaces_used": [],
                "data_accessed": [],
                "preconditions_required": [
                    "An attacker would need some way to cause Substation to execute arbitrary OS commands, shell scripts, or embedded scripting languages (for example, Bash, PowerShell, Python, JavaScript) from within its runtime."
                ],
                "constraints_encountered": [
                    "Substation’s design strictly limits behavior to compiled Go transforms chosen by a Type string; there is no generic \"execute shell command\" or \"run script\" transform in the codebase analyzed.",
                    "Pipeline configuration is data-driven only: JSON/Jsonnet configs select from a fixed registry of transforms and conditions and pass structured settings, but they are not executed as code in the target environment.",
                    "While Jsonnet used for config generation is Turing-complete, it is evaluated in CLI tools or potentially a validator Lambda, not exposed as an interpreter for arbitrary untrusted input in production data-plane paths."
                ],
                "evasion_considerations": [],
                "comments": "Direct use of a command or scripting interpreter (e.g., spawning a shell or running arbitrary scripts) is not supported by any documented Substation capability. Attackers must instead rely on higher-level transforms (HTTP calls, cloud APIs, serverless function invocations) for execution, as captured in other vectors.",
                "execution_result": "Not achievable: there is no mechanism in Substation to directly execute arbitrary OS commands or scripts via a command/scripting interpreter."
            },
            {
                "can_achieve": false,
                "technique_name": "Cloud Administration Command",
                "technique_stix_id": "attack-pattern--d94b3ae9-8059-4989-8e9f-ea0f601f80a7",
                "method_steps": [],
                "capabilities_used": [],
                "interfaces_used": [],
                "data_accessed": [],
                "preconditions_required": [
                    "To realize this technique, Substation would need to expose or indirectly drive services like AWS Systems Manager Run Command, Azure RunCommand, or similar VM agent-based remote command channels."
                ],
                "constraints_encountered": [
                    "The application and Terraform modules analyzed do not use Systems Manager, VM guest agents, or similar cloud management services that can push arbitrary commands into virtual machines.",
                    "Substation’s AWS integrations are data-plane (Kinesis, S3, DynamoDB, SQS, SNS, EventBridge, Lambda, Firehose, Secrets) plus some control-plane for autoscaling, but none map to generic command execution on EC2 instances or other VMs.",
                    "No transform or module provides a way to call SSM:SendCommand/StartSession or equivalent APIs from config, and the Kinesis autoscaling Lambda’s usage of CloudWatch and Kinesis APIs is constrained to scaling operations, not VM command execution."
                ],
                "evasion_considerations": [],
                "comments": "Cloud Administration Command is not directly enabled by Substation’s documented capabilities. Execution in this environment is achieved through serverless functions and cloud APIs rather than by issuing commands to VMs through management agents.",
                "execution_result": "Not achievable: Substation does not interface with cloud management services that can execute arbitrary commands inside virtual machines."
            }
        ],
        "summary": "Execution in Substation centers on serverless and cloud-API–driven compute rather than direct OS command execution. Realistic execution vectors include: (1) unauthenticated HTTP clients triggering Substation Lambda functions via public API Gateway, executing pipelines under privileged IAM roles; (2) malicious or compromised configurations that add send_aws_lambda or other sink transforms to invoke downstream Lambdas and event-driven consumers (Serverless Execution); (3) abuse of event/stream/object sinks (EventBridge, Kinesis, DynamoDB Streams, GCS) to drive additional Lambda/Cloud Function execution; (4) using the Substation playground’s /run endpoint as a remote cloud-API harness by supplying both pipeline configs and environment-based AWS/GCP credentials; (5) deploying malicious container images into the ECR repository used by Substation Lambdas (Malicious Image); and (6) social engineering developers or CI to run Substation CLI commands with attacker-supplied configs (User Execution). Classic command shell and cloud-administration-command techniques are not directly supported by the application; attackers must instead rely on these higher-level serverless and API-based execution paths, which in turn provide access to the real crown jewels: highly privileged Lambda roles and data-plane access to S3, DynamoDB, Kinesis, Secrets Manager, and other core cloud resources."
    },
    "discovery": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Cloud Infrastructure Discovery",
                "technique_stix_id": "attack-pattern--57a3d31a-d04f-4663-b2da-7df8ec3f8c9d",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "From their initial foothold, the attacker has read access to Substation’s configuration artifacts and IaC (for example a cloned repo/CI workspace or an S3/GCS location referenced by SUBSTATION_CONFIG and Terraform). They enumerate Jsonnet/JSON config trees and Terraform under build/terraform/aws/*.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "substation build [path]",
                            "substation fmt [path]",
                            "substation vet [path]",
                            "substation test [path]"
                        ],
                        "related_data": [
                            "Jsonnet and JSON Substation configuration files",
                            "Terraform modules under build/terraform/aws/*"
                        ],
                        "notes": "This is analogous to an adversary using tooling like Pacu to collect cloud inventory, but here the attacker mines the application’s own config and IaC instead of calling cloud APIs directly."
                    },
                    {
                        "step_id": 2,
                        "description": "The attacker runs `substation build`/`fmt`/`vet` recursively over the config tree to compile Jsonnet into JSON and validate pipelines, capturing the resulting normalized substation.Config / []config.Config structures or their JSON output.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "substation build [path]",
                            "substation fmt [path]",
                            "substation vet [path]"
                        ],
                        "related_data": [
                            "Compiled substation.Config objects (lists of config.Config entries per pipeline)"
                        ],
                        "notes": "Validation errors also echo transform IDs and snippets of configuration, helping confirm which transforms and resources are actually wired in."
                    },
                    {
                        "step_id": 3,
                        "description": "They parse each config.Config in substation.Config to enumerate infrastructure-touching transforms: send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_s3, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage, HTTP transforms, KV transforms, secrets, and metrics. For each, they extract embedded config.AWS/config.GCP objects and settings (ARNs, bucket names, stream names, regions, AssumeRoleARNs, KMS aliases).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms",
                            "KV store integration and distributed locking",
                            "Secrets retrieval and interpolation",
                            "Metrics and observability transforms"
                        ],
                        "related_interfaces": [
                            "transform types send_aws_dynamodb_put / send_aws_kinesis_data_stream / send_aws_data_firehose / send_aws_s3 / send_aws_sns / send_aws_sqs / send_aws_eventbridge / send_aws_lambda / send_gcp_storage",
                            "transform types enrich_http_get / enrich_http_post / send_http_post",
                            "transform types enrich_kv_store_item_get / enrich_kv_store_item_set / enrich_kv_store_set_add / meta_kv_store_lock",
                            "transform types utility_secret, utility_metric_* , meta_metric_duration"
                        ],
                        "related_data": [
                            "config.AWS and config.GCP blocks containing ARNs, regions, and optional AssumeRoleARNs",
                            "HTTP URLs and hosts configured in enrich_http_* and send_http_post transforms",
                            "KV backend identifiers and table/file names",
                            "Metric namespaces, names, and dimensions that often include resource identifiers"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "Next, they inspect Terraform modules under build/terraform/aws/* (lambda, s3, dynamodb, kinesis_data_stream, sqs, sns, secret, kms, api_gateway, eventbridge, cloudwatch/*, networking, ecr, appconfig) to extract all declared AWS resources (names, ARNs, regions, encryption keys) and the IAM roles/principals in var.access and var.config.account_ids that can access them.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms",
                            "Kinesis autoscaling controller"
                        ],
                        "related_interfaces": [
                            "Terraform modules in build/terraform/aws/lambda/main.tf",
                            "build/terraform/aws/s3/main.tf",
                            "build/terraform/aws/dynamodb/main.tf",
                            "build/terraform/aws/kinesis_data_stream/main.tf",
                            "build/terraform/aws/sqs/main.tf",
                            "build/terraform/aws/sns/main.tf",
                            "build/terraform/aws/secret/main.tf",
                            "build/terraform/aws/kms/main.tf",
                            "build/terraform/aws/api_gateway/*/main.tf",
                            "build/terraform/aws/eventbridge/lambda/main.tf",
                            "build/terraform/aws/cloudwatch/*/main.tf",
                            "build/terraform/aws/networking/vpc/main.tf",
                            "build/terraform/aws/ecr/main.tf",
                            "build/terraform/aws/appconfig/main.tf"
                        ],
                        "related_data": [
                            "Resource names and ARNs for S3 buckets, DynamoDB tables, Kinesis streams, SQS queues, SNS topics, Lambda functions, API Gateways, EventBridge rules/buses, AppConfig apps/environments, CloudWatch log destinations/subscriptions, KMS keys, Secrets Manager secrets, VPCs/subnets/security groups, and ECR repositories",
                            "Lists of IAM roles in var.access and external AWS account IDs in var.config.account_ids"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 5,
                        "description": "They correlate identifiers from runtime configs with Terraform resources: matching bucket/stream/table names and ARNs, mapping which Lambda handlers and Cloud Functions use which SUBSTATION_CONFIG sources, and which IAM roles (from var.access) are attached to each function or data store. This yields an end-to-end infrastructure map of all AWS/GCP components touched by Substation.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS and GCP sink transforms",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "substation build / fmt / vet outputs",
                            "Lambda and Cloud Function definitions in Terraform",
                            "Data flows documented under \"Lambda → encrypted data stores\" and \"HTTP → API Gateway → Lambda/Kinesis\""
                        ],
                        "related_data": [
                            "End-to-end mapping of ingestion endpoints (API Gateway, CloudWatch log subscriptions, S3/GCS events, DynamoDB Streams, Kinesis) to downstream sinks (S3, DynamoDB, Kinesis, SQS, SNS, EventBridge, Lambda, GCS) and associated IAM roles and regions"
                        ],
                        "notes": "At this point the attacker has a resource and trust graph similar in richness to what tools like Pacu build via Describe/List APIs, but derived purely from configuration and IaC."
                    }
                ],
                "capabilities_used": [
                    "Configuration management and validation CLI",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms",
                    "KV store integration and distributed locking",
                    "Secrets retrieval and interpolation",
                    "Metrics and observability transforms",
                    "Kinesis autoscaling controller"
                ],
                "interfaces_used": [
                    "substation build [path]",
                    "substation fmt [path]",
                    "substation vet [path]",
                    "substation test [path]",
                    "Jsonnet/JSON configuration files referenced by SUBSTATION_CONFIG",
                    "Terraform modules under build/terraform/aws/*",
                    "Documented data flows linking Lambda, API Gateway, Kinesis, S3, DynamoDB, SQS/SNS, AppConfig, CloudWatch Logs, and KMS"
                ],
                "data_accessed": [
                    "Jsonnet/JSON Substation pipeline configs (substation.Config / config.Config)",
                    "config.AWS/config.GCP blocks containing ARNs, resource names, regions, and optional AssumeRoleARNs",
                    "HTTP sink/enrichment URLs and hosts in HTTP transforms",
                    "Terraform definitions for S3, DynamoDB, Kinesis, SQS, SNS, Lambda, AppConfig, Secrets Manager, KMS, ECR, API Gateway, EventBridge, CloudWatch Logs destinations/subscriptions, and networking",
                    "Lists of IAM roles and external AWS account IDs (var.access, var.config.account_ids)",
                    "Documented data flows that tie event sources to downstream data stores"
                ],
                "preconditions_required": [
                    "Read access to the Substation code/config repository, CI workspace, or to S3/GCS locations that hold SUBSTATION_CONFIG and Terraform modules.",
                    "Ability to run the Substation CLI tools (build/fmt/vet/test) or to parse Jsonnet/JSON and Terraform offline.",
                    "Terraform and runtime configs must not be heavily redacted or separated into private repos that the compromised principal cannot access."
                ],
                "constraints_encountered": [
                    "If Terraform is split across multiple private repositories or maintained centrally by a separate team, the attacker may only see a partial infrastructure picture from the Substation repo alone.",
                    "Hosted configuration via AWS AppConfig or remote HTTP/S3 locations may include additional pipelines not present in the local repo; without read access to those sources, discovery is incomplete.",
                    "Config obfuscation (for example, using environment variables or indirection instead of explicit ARNs) can slightly hinder automated parsing, though most resource identifiers must still appear somewhere for the system to function."
                ],
                "evasion_considerations": [
                    "Operate entirely offline on local copies of configs and Terraform, avoiding cloud API calls that would generate CloudTrail events.",
                    "Use the same Substation CLI commands developers and CI pipelines legitimately run (build/fmt/vet/test), blending into normal workflows.",
                    "Limit any additional cloning or artifact access to expected paths and times (for example, during regular CI windows) to avoid anomalous repository-access patterns."
                ],
                "information_discovered": "Comprehensive inventory of the AWS and GCP infrastructure directly used by Substation: all configured S3 buckets, DynamoDB tables, Kinesis streams, SQS queues, SNS topics, EventBridge buses/rules, Lambda functions, CloudWatch log destinations/subscriptions, Secrets Manager secrets, KMS keys, AppConfig applications/environments, VPCs/subnets, and ECR repositories, plus the IAM roles and external accounts allowed to interact with them.",
                "comments": "This vector uses configuration and IaC to achieve a level of cloud infrastructure discovery similar to Pacu’s enumerate-* modules, without needing direct Describe/List access from the compromised runtime."
            },
            {
                "can_achieve": true,
                "technique_name": "Account Discovery",
                "technique_stix_id": "attack-pattern--72b74d71-8169-42aa-92e0-e7b04b9f5a08",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "With read access to Substation configs and Terraform (as in the previous vector), the attacker searches pipeline configs and IaC for tenant/account identifiers: KV key prefixes, per-tenant table or stream names, and lists of external AWS accounts that can send logs.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "Configuration management and validation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "substation build [path]",
                            "substation fmt [path]",
                            "substation vet [path]",
                            "Transform types enrich_kv_store_item_get / enrich_kv_store_item_set / enrich_kv_store_set_add / meta_kv_store_lock",
                            "CloudWatch Logs destination Terraform (var.config.account_ids)"
                        ],
                        "related_data": [
                            "KV transform configurations (key templates and prefixes)",
                            "DynamoDB KV backend/table definitions",
                            "Terraform variables var.config.account_ids and var.access",
                            "Per-tenant or per-account naming patterns in stream/bucket/table names"
                        ],
                        "notes": "This is analogous to adversaries querying domain controllers or Exchange to list users and roles; here, tenants and accounts are inferred from configuration structure rather than directory services."
                    },
                    {
                        "step_id": 2,
                        "description": "They enumerate all KV-backed transforms and meta_kv_store_lock instances to understand how tenant or account IDs are encoded into keys/prefixes in shared DynamoDB or file-based KV stores (for example, `tenant:{id}:state` or per-account hash keys).",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "enrich_kv_store_item_get",
                            "enrich_kv_store_item_set",
                            "enrich_kv_store_set_add",
                            "meta_kv_store_lock"
                        ],
                        "related_data": [
                            "KV key templates and prefixes",
                            "Configured TTLs and lock keys that incorporate tenant/account IDs"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "If the attacker also has network access to the unauthenticated API Gateway → Lambda proxy endpoint, and a pipeline behind it uses attacker-controlled fields as KV keys or lock keys, they send crafted POST bodies with varying candidate tenant/account identifiers and observe differences in JSON responses (for example, enriched vs. un-enriched data, different error codes, or message drops) to infer which identifiers exist in the KV store.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "KV store integration and distributed locking",
                            "Public HTTP APIs via API Gateway (Lambda proxy)"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API (Lambda proxy) POST / with authorization = NONE",
                            "AWS_API_GATEWAY handler in cmd/aws/lambda/substation/api_gateway.go",
                            "KV transforms inside the API-facing pipeline"
                        ],
                        "related_data": [
                            "HTTP request/response bodies on the public API",
                            "Implicit KV lookups keyed by attacker-controlled fields (for example, tenant or account IDs)"
                        ],
                        "notes": "This mirrors classic application-level account enumeration, but the backing source of truth is a shared KV/DynamoDB table rather than a user directory."
                    },
                    {
                        "step_id": 4,
                        "description": "If the attacker compromises an IAM role in var.access that has read permissions on shared DynamoDB KV tables or ingestion Kinesis streams, they use `substation tap` or equivalent Kinesis/DynamoDB tooling with those credentials to read items/records and enumerate distinct tenant or account identifiers present in keys, partition keys, and payload fields.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "Local ingestion and transformation CLI",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "substation tap (Kinesis tap CLI)",
                            "DynamoDB KV backend used by internal/kv",
                            "Kinesis Data Streams for ingestion or centralized logs"
                        ],
                        "related_data": [
                            "DynamoDB item keys and attributes storing per-tenant state",
                            "Kinesis record partition keys and payloads containing tenant/account IDs",
                            "CloudWatch log records forwarded into Kinesis/Firehose that include accountId, tenant IDs, or ARNs"
                        ],
                        "notes": "This parallels adversaries using tools like ShimRatReporter or OS commands to list accounts, but applied to multi-tenant keys and shared streams rather than OS user databases."
                    }
                ],
                "capabilities_used": [
                    "KV store integration and distributed locking",
                    "Core Substation transformation engine",
                    "Configuration management and validation CLI",
                    "AWS Lambda Substation event processors",
                    "Local ingestion and transformation CLI",
                    "CloudWatch Logs destinations for centralized forwarding"
                ],
                "interfaces_used": [
                    "substation build / fmt / vet over configuration directories",
                    "KV transforms enrich_kv_store_item_get / enrich_kv_store_item_set / enrich_kv_store_set_add / meta_kv_store_lock",
                    "API Gateway → Lambda proxy REST API (POST /, authorization NONE)",
                    "substation tap (Kinesis stream reader)",
                    "DynamoDB KV backend configured via internal/kv",
                    "CloudWatch Logs destination and subscription filters for centralized log forwarding"
                ],
                "data_accessed": [
                    "Jsonnet/JSON configuration files defining KV prefixes and key schemas",
                    "DynamoDB tables or file-based KV stores used for cross-message state and locking",
                    "Kinesis streams carrying multi-tenant ingestion or centralized logs",
                    "CloudWatch log events that include accountId, logGroup names, tenant identifiers, or ARNs",
                    "Terraform variables (var.config.account_ids, var.access) listing external accounts and roles participating in logging and data access"
                ],
                "preconditions_required": [
                    "Read access to Substation configuration and Terraform to understand KV key patterns and per-tenant naming schemes.",
                    "For active probing: a public API Gateway → Lambda endpoint that is still configured with authorization = NONE and routes to a pipeline that uses attacker-controlled fields as KV keys or lock keys and exposes behavioral differences in responses.",
                    "For direct data inspection: stolen or misused IAM credentials for a role in var.access that has read permissions on the relevant DynamoDB KV tables or Kinesis streams.",
                    "Sufficient knowledge of likely tenant/account ID formats to construct plausible candidate identifiers for probing."
                ],
                "constraints_encountered": [
                    "If KV prefixes are fully opaque random values (for example, GUIDs not derived from human-meaningful tenant IDs), active probing via API responses yields little usable enumeration information.",
                    "Well-designed API responses that normalize behavior for unknown tenants (for example always returning a generic error) can significantly reduce side channels, forcing the attacker to rely on back-end data access instead.",
                    "Strong IAM isolation (for example, separate KV tables per tenant and no cross-tenant read permissions) will constrain enumeration to a single tenant’s scope even with compromised credentials."
                ],
                "evasion_considerations": [
                    "Throttle enumeration requests to the public API over time and distribute them across IP addresses to blend into normal ingestion traffic patterns.",
                    "Randomize tenant/account probe order and interleave with legitimate-looking payloads to avoid simple anomaly detection based on value patterns.",
                    "When reading KV or Kinesis directly, use existing operational tools (for example substation tap or existing observability pipelines) instead of introducing custom binaries that might stand out."
                ],
                "information_discovered": "Lists of tenant and/or account identifiers encoded in KV key prefixes, DynamoDB items, ingestion stream partition keys and payloads, CloudWatch log records, and Terraform variables (including external AWS accounts allowed to send logs), along with partial mapping of which pipelines and resources belong to which tenants.",
                "comments": "This vector covers both passive enumeration via configuration and shared data stores and active enumeration via API Gateway side channels when pipelines use KV-backed multi-tenant routing."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Storage Object Discovery",
                "technique_stix_id": "attack-pattern--8565825b-21c8-4518-b75e-cbc4c717a156",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "With access to Terraform and pipeline configs (from earlier vectors), the attacker enumerates all S3 and GCS buckets used by Substation via the S3/GCS Terraform modules and the send_aws_s3 / send_gcp_storage transforms, recording bucket names and any configured key-prefix patterns.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "transform send_aws_s3",
                            "transform send_gcp_storage",
                            "Terraform module build/terraform/aws/s3/main.tf",
                            "Terraform module build/terraform/gcp storage (if present)",
                            "GCP Cloud Storage Substation Function handler (GCP_STORAGE)"
                        ],
                        "related_data": [
                            "S3 bucket names and object key templates from send_aws_s3 config",
                            "GCS bucket names and object naming strategies from send_gcp_storage config",
                            "Terraform-defined S3 buckets (including optional object-lock and SSE-KMS)",
                            "SUBSTATION_CONFIG for GCS Cloud Functions indicating buckets and prefixes"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "If the attacker has access to CloudWatch Logs for the S3 ingestion Lambdas or to the centralized Kinesis/Firehose log destination, they read log streams and filter for events produced by the S3 and GCS handlers (cmd/aws/lambda/substation/s3.go and cmd/gcp/function/substation/storage.go) to extract bucket and object key information from log messages and event payloads.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs groups for S3/GCS ingestion Lambdas",
                            "CloudWatch Logs destination_arn and subscription filters",
                            "substation tap (reading central Kinesis streams if logs are forwarded there)"
                        ],
                        "related_data": [
                            "S3 event payloads including bucket name and object key",
                            "GCS CloudStorageEvent payloads with bucket and object name",
                            "Log lines emitted by S3/GCS handlers that reference processed object keys and metadata",
                            "Kinesis or Firehose records carrying forwarded CloudWatch Logs events"
                        ],
                        "notes": "This is conceptually similar to Pacu/Peirates listing S3 buckets/objects, but discovery happens by mining ingestion and log records rather than directly calling ListObjects APIs."
                    },
                    {
                        "step_id": 3,
                        "description": "They aggregate unique object keys and prefixes observed in logs across time windows, reconstructing directory-like structures (for example, per-tenant prefixes, date-based folders) and estimating data volumes and change rates per bucket and per logical path.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs queries or log consumer pipelines",
                            "Kinesis/Firehose consumer reading central log streams"
                        ],
                        "related_data": [
                            "Aggregated lists of S3/GCS object keys and prefixes",
                            "Counts and timestamps of object-creation events per bucket/prefix"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "If the attacker also compromises credentials for a role in var.access that has S3 or GCS read/list permissions, they can optionally use cloud-native tooling (for example, S3 ListObjectsV2 or GCS object listing) guided by discovered bucket names and prefixes to enumerate additional objects beyond those seen in logs, focusing effort on high-value prefixes identified from pipeline usage.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "AWS S3 API (ListObjectsV2 etc.) or equivalent tooling executed with compromised Substation IAM roles",
                            "GCS Storage APIs / CLI executed with the compromised Cloud Function service account"
                        ],
                        "related_data": [
                            "Full or partial object listings for Substation-managed S3 and GCS buckets, including key names, sizes, and timestamps"
                        ],
                        "notes": "This step moves closer to Pacu-style direct bucket/object enumeration, but is seeded and scoped by information obtained from Substation’s own configuration and logging."
                    }
                ],
                "capabilities_used": [
                    "AWS and GCP sink transforms",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "Configuration management and validation CLI",
                    "Local ingestion and transformation CLI"
                ],
                "interfaces_used": [
                    "send_aws_s3 transform configuration",
                    "send_gcp_storage transform configuration",
                    "S3/GCS ingestion handlers (cmd/aws/lambda/substation/s3.go, cmd/gcp/function/substation/storage.go)",
                    "CloudWatch Logs groups for ingestion Lambdas",
                    "CloudWatch Logs destination and subscription filters feeding logs into Kinesis/Firehose",
                    "substation tap for reading Kinesis streams carrying forwarded logs"
                ],
                "data_accessed": [
                    "S3 bucket names and object key patterns from send_aws_s3 configs and S3 Terraform modules",
                    "GCS bucket names and object naming patterns from send_gcp_storage configs and Cloud Function configs",
                    "CloudWatch Logs entries or Kinesis/Firehose records containing S3/GCS event payloads with bucket and key names",
                    "Aggregated lists of observed object keys and prefixes, with timestamps and sizes where available"
                ],
                "preconditions_required": [
                    "Read access to Substation configuration and Terraform to learn which S3/GCS buckets and key patterns are in use.",
                    "Read access to CloudWatch Logs for S3/GCS ingestion Lambdas or to the central Kinesis/Firehose stream used as a CloudWatch Logs destination, in order to see object-related events.",
                    "Optionally, compromised IAM credentials for a Substation-related role with S3/GCS list/read permissions to expand discovery beyond what is visible in logs."
                ],
                "constraints_encountered": [
                    "Log-based enumeration only reveals objects that were recently created/updated and that triggered ingestion or logging; cold or rarely used objects may not appear.",
                    "If CloudWatch Logs are not centrally forwarded, the attacker needs per-function log-group access, which may be more tightly controlled.",
                    "IAM policies on S3/GCS may permit PutObject but not List or GetObject, limiting the ability to do API-level enumeration even with compromised credentials."
                ],
                "evasion_considerations": [
                    "Prefer mining existing logs and ingestion records over active ListObjects scans to reduce noisy API usage that would appear in CloudTrail or GCP Audit Logs.",
                    "Scope any follow-on bucket/object listing to prefixes already seen in logs (for example, single tenant or pipeline), keeping enumeration narrow and plausibly aligned with normal operations.",
                    "Use existing operational log analysis tooling or dashboards where possible rather than introducing new consumers that might draw attention."
                ],
                "information_discovered": "Bucket-level and object-level inventory for the S3 and GCS storage used by Substation, including bucket names, key-prefix schemes (often encoding tenants or time-based partitions), and many specific object keys, along with approximate data volumes and activity patterns per prefix.",
                "comments": "This vector aligns with MITRE’s Cloud Storage Object Discovery, but uses Substation’s ingestion paths and centralized logging as the primary discovery channel rather than relying solely on direct S3/GCS listing APIs."
            },
            {
                "can_achieve": true,
                "technique_name": "Log Enumeration",
                "technique_stix_id": "attack-pattern--866d0d6d-02c6-42bd-aa2f-02907fdc0969",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "The attacker compromises credentials for a role that can read from the centralized Kinesis/Firehose destination used by the CloudWatch Logs destination module, or directly from relevant CloudWatch log groups for Substation Lambdas and the Kinesis autoscaling Lambda.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "AWS Lambda Substation event processors",
                            "Kinesis autoscaling controller"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs destination_arn and associated IAM role",
                            "CloudWatch Logs subscription filters for configured log groups",
                            "CloudWatch log groups for Substation Lambdas and the autoscale Lambda"
                        ],
                        "related_data": [
                            "CloudWatch log events for Substation Lambdas (stdout/stderr and EMF metrics)",
                            "CloudWatch log events for the autoscale Lambda, including alarm payloads and scaling decisions"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Using `substation tap` or another Kinesis consumer with the compromised credentials, they subscribe to the central Kinesis stream (or Firehose delivery stream) that receives forwarded CloudWatch Logs, passively collecting log records from all subscribed log groups, including those of Substation and potentially external accounts allowed via var.config.account_ids.",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "substation tap (cmd/substation/tap.go) configured against the central Kinesis stream",
                            "CloudWatch Logs destination writing log batches into Kinesis/Firehose"
                        ],
                        "related_data": [
                            "Kinesis records containing CloudWatch log event batches",
                            "Log group and log stream identifiers for each record",
                            "accountId fields indicating which AWS account produced each log event"
                        ],
                        "notes": "This is similar to Pacu’s ability to collect CloudTrail and CloudWatch logs, but uses Substation’s own log-forwarding pipeline as the aggregation point."
                    },
                    {
                        "step_id": 3,
                        "description": "They parse log batches to enumerate all log groups and streams, identifying which Lambda functions, services, and external AWS accounts are actively logging into the central destination. For Substation Lambdas, function names and structured logs/metrics reveal which handlers and pipelines exist and how often they run.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Metrics and observability transforms"
                        ],
                        "related_interfaces": [
                            "CloudWatch log event schema carried over Kinesis/Firehose",
                            "internal/metrics/aws_cloudwatch_embedded_metrics.go (EMF JSON printed to stdout)"
                        ],
                        "related_data": [
                            "Log group names such as /aws/lambda/<substation-function-name>",
                            "EMF metric payloads with namespaces, metric names, and dimensions",
                            "Application logs including error messages and configuration snippets"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "They focus on EMF metrics and autoscaling-related logs to understand monitoring coverage: which Kinesis streams have metric-math alarms, what utilization thresholds and evaluation windows are configured, and which SNS topics and Lambdas are wired into alarming and autoscaling workflows.",
                        "related_capabilities": [
                            "Metrics and observability transforms",
                            "Kinesis autoscaling controller",
                            "CloudWatch metric alarms for Kinesis auto-scaling"
                        ],
                        "related_interfaces": [
                            "EMF metric emission via internal/metrics/aws_cloudwatch_embedded_metrics.go",
                            "Autoscale Lambda handler receiving CloudWatch Alarm SNS notifications",
                            "CloudWatch alarm configurations referenced in build/terraform/aws/kinesis_data_stream/main.tf"
                        ],
                        "related_data": [
                            "Metric namespaces, names, and dimensions for Kinesis and pipeline metrics",
                            "Alarm names, thresholds, and metric-math expressions from alarm payloads logged by the autoscale Lambda",
                            "SNS topic ARNs used for autoscaling notifications"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "AWS Lambda Substation event processors",
                    "Kinesis autoscaling controller",
                    "Metrics and observability transforms",
                    "Local ingestion and transformation CLI"
                ],
                "interfaces_used": [
                    "CloudWatch Logs destination and destination policy",
                    "CloudWatch Logs subscription filters for selected log groups",
                    "substation tap against the central Kinesis stream carrying logs",
                    "EMF metrics emitted to stdout by Substation and autoscale components",
                    "Autoscale Lambda’s SNS-triggered handler for CloudWatch alarms"
                ],
                "data_accessed": [
                    "CloudWatch log events for all Substation Lambdas and the autoscale Lambda",
                    "EMF metrics describing counts, bytes, freshness, and durations per pipeline or transform",
                    "CloudWatch Alarm SNS payloads describing Kinesis utilization alarms and their configuration",
                    "Log group and log stream names and associated AWS account IDs",
                    "Potential logs from external AWS accounts allowed by var.config.account_ids"
                ],
                "preconditions_required": [
                    "Compromised IAM credentials for a principal that can read from the central Kinesis/Firehose stream used as a CloudWatch Logs destination, or from individual Substation-related CloudWatch log groups.",
                    "Knowledge of the destination Kinesis/Firehose stream ARN or log group names (obtainable from Terraform or configuration)."
                ],
                "constraints_encountered": [
                    "If CloudWatch Logs are not forwarded centrally, the attacker needs read access to many individual log groups, which may be more tightly controlled.",
                    "Logs may be encrypted with KMS keys whose decrypt permissions are limited; without those, raw log content may be inaccessible even if the stream is reachable.",
                    "Very restrictive CloudWatch Logs retention periods can limit historical visibility, constraining how far back the attacker can analyze monitoring posture and past activity."
                ],
                "evasion_considerations": [
                    "Use existing logging analysis mechanisms (for example, an already-deployed analytics Lambda or consumer) rather than introducing new consumers where possible.",
                    "Limit the volume and time range of log reads to avoid large, anomalous CloudWatch Logs or Kinesis GetRecords activity.",
                    "Avoid modifying or deleting logs during discovery to keep activity purely read-only and less suspicious."
                ],
                "information_discovered": "A detailed picture of the logging and monitoring environment around Substation: which Lambda functions and services produce logs, which log groups are centrally forwarded, which AWS accounts contribute logs, what EMF metrics are emitted (and with what dimensions), and how Kinesis autoscaling alarms and SNS topics are configured.",
                "comments": "This vector directly matches MITRE’s Log Enumeration and mirrors real-world use of tools like Pacu to collect CloudWatch logs, but leverages Substation’s CloudWatch Logs destination and Kinesis-based aggregation for efficiency."
            },
            {
                "can_achieve": true,
                "technique_name": "Network Service Discovery",
                "technique_stix_id": "attack-pattern--e3a12395-188d-4051-9a16-ea8e14d07b88",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "An external attacker discovers or is given the public API Gateway → Lambda proxy endpoint (authorization = NONE) and can send arbitrary HTTPS POST requests to it, which API Gateway forwards via AWS_PROXY to a Substation Lambda running inside a VPC.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API (Lambda proxy) POST / with authorization = NONE",
                            "AWS_API_GATEWAY handler in cmd/aws/lambda/substation/api_gateway.go"
                        ],
                        "related_data": [
                            "HTTP request/response bodies between attacker and API Gateway",
                            "Lambda invocation context data encapsulated in APIGatewayProxyRequest"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "The Lambda’s SUBSTATION_CONFIG includes one or more HTTP enrichment/sending transforms (enrich_http_get, enrich_http_post, send_http_post) that contact internal or external HTTP(S) services from within the VPC. The attacker sends test requests and observes the JSON array of transformed messages returned by the handler to infer whether these HTTP calls succeeded, failed, or timed out, and what data came back.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "enrich_http_get",
                            "enrich_http_post",
                            "send_http_post",
                            "AWS_API_GATEWAY handler’s JSON response format"
                        ],
                        "related_data": [
                            "Configured HTTP URLs and hosts in HTTP transforms (from SUBSTATION_CONFIG)",
                            "HTTP response codes and bodies written into message fields and returned via API Gateway"
                        ],
                        "notes": "This is analogous to an attacker triggering existing service calls and using their responses to map reachable services, similar in spirit to limited-scope application-layer scanning."
                    },
                    {
                        "step_id": 3,
                        "description": "If the attacker (from a prior compromise) can modify the SUBSTATION_CONFIG source (for example, by writing to the S3 object, GCS object, or HTTP location referenced by SUBSTATION_CONFIG), they deploy a malicious pipeline that parameterizes HTTP transforms with message-derived targets so that each request hits a different internal host:port or path (for example, http://10.0.0.5:8080/health, http://10.0.1.10:443/). They then send crafted POST bodies enumerating candidate internal endpoints and observe which invocations succeed, fail quickly, or time out.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG loaded via internal/file.Get (local, HTTP, S3, GCS)",
                            "enrich_http_get/enrich_http_post/send_http_post with URL templates that interpolate ${DATA} fields",
                            "API Gateway → Lambda proxy endpoint used as a control channel for scanning"
                        ],
                        "related_data": [
                            "Malicious SUBSTATION_CONFIG that encodes scanning logic",
                            "Lists of internal hostnames/IPs and ports to probe, embedded in attacker-supplied request bodies",
                            "HTTP responses or error conditions returned for each target endpoint"
                        ],
                        "notes": "This approximates port/service scanning (as in Pupy or nmap-based campaigns) but limited to HTTP/HTTPS and whatever hosts/ports are reachable from the Lambda’s subnets and security groups."
                    },
                    {
                        "step_id": 4,
                        "description": "By correlating which targets are reachable, which require TLS, which present specific banners or response bodies, and which are unreachable from the Lambda’s VPC, the attacker builds a map of internal HTTP(S) services and external egress behavior (for example, which CIDR ranges are routable via NAT, presence of internal load balancers or service meshes).",
                        "related_capabilities": [
                            "VPC with public and private subnets, NAT, and Internet gateway",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "Lambda VPC configuration (var.config.vpc_config) specifying subnets and security groups",
                            "Networking/VPC Terraform (build/terraform/aws/networking/vpc/main.tf) describing routes via NAT and IGW"
                        ],
                        "related_data": [
                            "Set of internal and external endpoints confirmed reachable from Lambda subnets",
                            "Observed response headers and payload characteristics per target",
                            "Inferred mapping of which subnets egress via NAT versus directly via the IGW"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "HTTP enrichment and sending transforms",
                    "Substation Lambda functions (container-image Lambdas)",
                    "VPC with public and private subnets, NAT, and Internet gateway",
                    "Public HTTP APIs via API Gateway (Lambda proxy)"
                ],
                "interfaces_used": [
                    "API Gateway REST API (Lambda proxy) with POST / and authorization = NONE",
                    "AWS_API_GATEWAY Lambda handler (cmd/aws/lambda/substation/api_gateway.go)",
                    "HTTP transform types enrich_http_get / enrich_http_post / send_http_post",
                    "SUBSTATION_CONFIG loaded via internal/file.Get from S3/HTTP/GCS/local paths",
                    "Terraform Lambda VPC configuration and networking/vpc module defining subnets, NAT gateways, and IGW routes"
                ],
                "data_accessed": [
                    "SUBSTATION_CONFIG for the API-facing Lambda, including HTTP transform configuration and URL templates",
                    "HTTP request/response traffic between the Lambda and internal/external HTTP(S) endpoints",
                    "Aggregated results of probes (success/failure/timeout) per internal host:port and external service",
                    "VPC topology information inferred from which destinations are reachable from which Lambda subnets"
                ],
                "preconditions_required": [
                    "Network access to the public API Gateway → Lambda proxy endpoint (it must remain configured with authorization = NONE or otherwise accessible to the attacker).",
                    "At least one pipeline behind this API must already use HTTP transforms whose results flow into the API response, OR the attacker must be able to modify the SUBSTATION_CONFIG source used by the Lambda.",
                    "Lambda functions must be attached to VPC subnets that can reach internal or external targets of interest (via security groups and NAT/IGW routes)."
                ],
                "constraints_encountered": [
                    "HTTP transforms only support HTTP(S); the attacker cannot directly perform arbitrary TCP scanning or raw port scans.",
                    "If SUBSTATION_CONFIG is tightly controlled (for example, stored in a locked-down S3 bucket or AppConfig profile with validator enforcement) and the attacker cannot modify it, scanning is limited to whatever fixed HTTP endpoints the legitimate pipeline already contacts.",
                    "Aggressive outbound scanning from Lambda (many distinct hosts/ports) may create noticeable patterns in VPC flow logs and external service logs."
                ],
                "evasion_considerations": [
                    "Keep probe volume low and time-distributed, mixing probes with seemingly normal API calls to avoid easy detection based on traffic spikes.",
                    "Mimic expected request shapes and headers (for example, reusing legitimate payload patterns) so HTTP transforms and downstream services see traffic that looks operational rather than obviously malicious.",
                    "Target only a constrained set of high-value internal CIDRs or known service hostnames inferred from configuration to reduce noise."
                ],
                "information_discovered": "A map of HTTP(S) services and reachable network endpoints as seen from Substation Lambdas’ VPC subnets, including which internal hosts and external services are accessible, basic service banners/behaviors, and inferred egress paths through NAT gateways or the Internet gateway.",
                "comments": "This vector provides application-layer network service discovery using Substation’s HTTP transforms and public API exposure, analogous to adversaries using built-in tools to scan networks from compromised hosts."
            },
            {
                "can_achieve": true,
                "technique_name": "System Information Discovery",
                "technique_stix_id": "attack-pattern--354a7f88-63fb-41b5-a801-ce3b377b36f1",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "From access to Terraform and deployment artifacts, the attacker enumerates environment-level properties of Substation components: Lambda function names, regions, memory/timeouts, VPC attachments, KMS keys for encryption, and AppConfig applications/environments, inferring environment names (for example, dev/stage/prod) and organizational structure from naming conventions.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Substation Lambda functions (container-image Lambdas)",
                            "AWS AppConfig application & environments"
                        ],
                        "related_interfaces": [
                            "Terraform modules build/terraform/aws/lambda/main.tf",
                            "build/terraform/aws/appconfig/main.tf",
                            "build/terraform/aws/networking/vpc/main.tf",
                            "build/terraform/aws/kms/main.tf"
                        ],
                        "related_data": [
                            "Lambda function names and ARNs (including region and accountId segments)",
                            "Environment variables and VPC configuration (subnet and security group IDs)",
                            "KMS key ARNs and aliases used for Lambda and data-store encryption",
                            "AppConfig application and environment identifiers"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "If the attacker can read CloudWatch Logs for Substation Lambdas or the central Kinesis/Firehose log destination, they extract function-level and environment-level context from logGroup ARNs, log messages, and EMF metrics—such as AWS account IDs, regions, Lambda runtime identifiers, and any environment tags included in metric dimensions or log lines.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Metrics and observability transforms",
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "CloudWatch log groups for Substation Lambdas",
                            "CloudWatch Logs destination_arn and associated Kinesis/Firehose streams",
                            "EMF metrics emitted by internal/metrics/aws_cloudwatch_embedded_metrics.go"
                        ],
                        "related_data": [
                            "Log group ARNs of the form arn:aws:logs:<region>:<accountId>:log-group:/aws/lambda/<function-name>",
                            "EMF metric payloads including dimensions such as pipeline IDs, environment names, or tenant tags",
                            "Debug/Info logs that reference environment variables, handler types, or runtime details"
                        ],
                        "notes": "This parallels malware that collects hostnames, OS versions, and domain information, but at the cloud-function and account/region level."
                    },
                    {
                        "step_id": 3,
                        "description": "Where the attacker can observe event payloads processed by Substation (for example, via substation tap on Kinesis streams or via compromised Lambda roles), they mine those events for system identifiers such as awsRegion, eventSource, eventSourceARN, accountId, and service-specific ARNs, further refining their understanding of which cloud accounts, regions, and services participate in each data flow.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Kinesis Data Streams carrying application or log events",
                            "substation tap reading from those streams",
                            "DynamoDB Streams, S3 event notifications, SNS/SQS messages processed by Substation Lambdas"
                        ],
                        "related_data": [
                            "AWS event fields such as awsRegion, accountId, eventSource, eventSourceARN",
                            "Service-specific ARNs for S3 buckets, DynamoDB tables, Kinesis streams, SNS topics, and SQS queues appearing in event payloads"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "Substation Lambda functions (container-image Lambdas)",
                    "AWS AppConfig application & environments",
                    "Metrics and observability transforms",
                    "CloudWatch Logs destinations for centralized forwarding",
                    "Local ingestion and transformation CLI"
                ],
                "interfaces_used": [
                    "Terraform definitions for Lambda, AppConfig, VPC, and KMS",
                    "CloudWatch log groups and central log destinations carrying Substation logs and metrics",
                    "EMF metrics emitted by internal/metrics/aws_cloudwatch_embedded_metrics.go",
                    "Kinesis Data Streams and other AWS event sources consumed by Substation Lambdas",
                    "substation tap for reading Kinesis streams"
                ],
                "data_accessed": [
                    "Lambda function configuration details (names, ARNs, regions, memory/timeouts, VPC attachments) from Terraform and deployment artifacts",
                    "KMS key ARNs and aliases associated with Lambda and data stores",
                    "AppConfig application and environment identifiers that encode deployment contexts",
                    "CloudWatch log group ARNs and EMF metric payloads revealing account IDs, regions, and environment naming",
                    "AWS event metadata (awsRegion, accountId, eventSource, eventSourceARN) carried in Kinesis, S3, DynamoDB Streams, SNS, and SQS events"
                ],
                "preconditions_required": [
                    "Read access to Terraform or equivalent deployment descriptors for the Substation stack.",
                    "Read access to CloudWatch Logs for Substation Lambdas or to the central Kinesis/Firehose log destination, or compromised credentials for a consumer of those logs.",
                    "Access to at least one event source (for example, Kinesis stream) where raw AWS events processed by Substation can be observed, either via substation tap or separate tooling."
                ],
                "constraints_encountered": [
                    "If access is limited to a single environment (for example, only the production account), system information discovery will be scoped to that account/region set.",
                    "Minimalistic logging and metric dimensions that omit environment or tenant tags will reduce the amount of context that can be inferred from logs alone.",
                    "Strong separation of duties (for example, Terraform stored in a separate privileged repo) can force the attacker to rely more on runtime telemetry than on static configuration."
                ],
                "evasion_considerations": [
                    "Favor passive observation of logs and event streams over active Describe/List API calls to reduce CloudTrail noise.",
                    "Use existing observability tools (for example, dashboards or log-analysis Lambdas) where possible instead of adding new consumers.",
                    "Limit the breadth and duration of log and stream inspection to what a troubleshooting or operations workflow might legitimately require."
                ],
                "information_discovered": "High-level system information about the Substation deployment, including AWS account IDs and regions in use, Lambda function inventory and runtime characteristics, KMS key usage, VPC attachment and networking context, and which AWS services (S3, DynamoDB, Kinesis, SQS, SNS, EventBridge, AppConfig) and environments participate in each data flow.",
                "comments": "This vector complements the more resource-focused Cloud Infrastructure Discovery by providing contextual information about where and how Substation runs (accounts, regions, environments, VPCs, runtimes), akin to host-level system information discovery in traditional environments."
            }
        ],
        "summary": "Substation’s design—config-driven pipelines, rich Terraform IaC, centralized CloudWatch logging/metrics, extensive use of AWS/GCP data stores, and unauthenticated API Gateway endpoints—creates multiple realistic Discovery paths. An attacker who gains access to configuration/IaC artifacts, CloudWatch logs or the central log Kinesis/Firehose destination, public API Gateway endpoints, or Substation-related IAM roles can:\n\n- Build a detailed inventory of all AWS/GCP resources tied to the deployment (Cloud Infrastructure Discovery).\n- Enumerate tenants/accounts via KV prefixes, shared DynamoDB/Kinesis state, and multi-account log destinations (Account Discovery).\n- Infer bucket and object inventories for S3 and GCS used by Substation from configuration and ingestion/log records (Cloud Storage Object Discovery).\n- Catalog logging and monitoring posture, including which log groups are centralized and how Kinesis autoscaling alarms and metrics are configured (Log Enumeration and Cloud Service Discovery).\n- Map reachable internal and external HTTP(S) services from Lambda VPC subnets by abusing HTTP transforms exposed through public API Gateway (Network Service Discovery).\n- Derive broader system information such as accounts, regions, environments, KMS usage, and VPC topology from Terraform, logs, and event metadata (System Information Discovery).\n\nThese discovery methods do not require code execution beyond what the application and its infrastructure already perform; most rely on reading configuration, logs, and telemetry or on exercising legitimate HTTP and AWS APIs with compromised or overly exposed interfaces and roles. Defensive controls that strictly protect SUBSTATION_CONFIG sources, lock down IAM roles (especially var.access and autoscaling roles), restrict access to centralized logs, and add strong authentication/rate limiting in front of API Gateway significantly reduce the feasibility and granularity of these discovery vectors."
    },
    "privilege-escalation": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Temporary Elevated Cloud Access",
                "technique_stix_id": "attack-pattern--6fa224c7-5091-4595-bf15-3fc9fe2f2c7c",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify a higher-privilege or cross-account IAM role that the Substation Lambda execution role (or other Substation AWS role) is allowed to assume, and obtain its ARN.",
                        "related_capabilities": [
                            "Terraform IAM access patterns via var.access – S3, DynamoDB, Kinesis, SQS, SNS, Secrets, EventBridge, and Lambda modules attach powerful data-plane and KMS permissions to every role listed in var.access, so compromise of any such role (or its configuration usage) yields wide-reaching capabilities across multiple services.",
                            "Substation Lambda functions (container-image Lambdas) – Terraform-defined Lambda functions run with execution roles that have access to encrypted S3, DynamoDB, Kinesis, SQS, SNS, Secrets, and KMS, meaning compromise of these functions or roles grants extensive admin-like data-plane and decryption capabilities."
                        ],
                        "related_interfaces": [
                            "Lambda invocation APIs (lambda:GetFunctionConfiguration, lambda:InvokeFunction) exposed to principals listed in var.access via the Substation Lambda access policy",
                            "AWS IAM / STS APIs available to the operator outside of Substation (used to inspect roles and trust policies)"
                        ],
                        "related_data": [
                            "IAM role ARNs and trust policies for Substation-related roles and any assumable cross-account roles",
                            "Terraform definitions under build/terraform/aws/* that reveal role names and policies"
                        ],
                        "notes": "This reconnaissance step is typically done via AWS CLI/console or by reading Terraform, not via Substation itself, but it is a prerequisite for abusing AssumeRole in Substation’s AWS config."
                    },
                    {
                        "step_id": 2,
                        "description": "Gain control over a Substation configuration used by a privileged runtime (for example, the SUBSTATION_CONFIG object in S3 or the AppConfig profile consumed by a Substation Lambda) so you can edit transform settings.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "AWS AppConfig application & environments – AppConfig applications/environments store hosted configuration consumed by Lambdas via appconfig:GetConfiguration*.",
                            "S3 buckets for Substation data – buckets with IAM policies granting GetObject/PutObject to roles in var.access"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable on the Lambda / function entrypoint",
                            "internal/file.Get used by getConfig to read configuration from S3/HTTP/GCS/local paths",
                            "AWS AppConfig configuration profiles and environments used by the Lambda"
                        ],
                        "related_data": [
                            "Substation configuration files (Jsonnet/JSON) defining transform chains and AWS target settings",
                            "Object(s) in configuration S3 buckets referenced by SUBSTATION_CONFIG",
                            "AppConfig configuration profiles that contain serialized Substation configs"
                        ],
                        "notes": "Control of configuration may come from compromising the IaC/CI pipeline, the S3 bucket that stores configs, or AppConfig publishers. Substation assumes configs are trusted; if that assumption fails, configuration becomes an attack surface."
                    },
                    {
                        "step_id": 3,
                        "description": "Modify one or more AWS sink transforms in the Substation config (for example send_aws_kinesis_data_stream, send_aws_s3, send_aws_eventbridge, send_aws_lambda) to include an AssumeRoleARN (or equivalent) field pointing at the higher-privilege role.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms – send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_s3, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda create AWS clients via internal/config.NewAWS and can write to many services, amplifying the impact of any assumed or compromised IAM role and enabling cross-account access where AssumeRole is configured.",
                            "internal/config.NewAWS – Central AWS SDK helper that derives credentials from the default chain and optionally configures an STS AssumeRoleARN for cross-account access, providing an explicit mechanism for role assumption and potential privilege escalation via configuration changes.",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform types send_aws_kinesis_data_stream, send_aws_s3, send_aws_data_firehose, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda",
                            "internal/config.NewAWS helper, including its optional STS AssumeRoleARN handling"
                        ],
                        "related_data": [
                            "AWS configuration blocks embedded in Substation transform settings (region, ARN, optional AssumeRoleARN)",
                            "Target AWS resource ARNs (streams, buckets, topics, Lambdas, event buses) that will be accessed using the assumed role"
                        ],
                        "notes": "This embeds role assumption into normal-looking data-plane transforms, so config review must explicitly look for AssumeRole-style options."
                    },
                    {
                        "step_id": 4,
                        "description": "Deploy or otherwise cause the modified configuration to be used by the privileged Substation runtime (for example by overwriting the S3 object referenced in SUBSTATION_CONFIG, updating the AppConfig version, or pointing SUBSTATION_CONFIG at a new remote config).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS AppConfig application & environments",
                            "S3 buckets for Substation data"
                        ],
                        "related_interfaces": [
                            "S3 PutObject to the configuration object key used by SUBSTATION_CONFIG",
                            "AppConfig CreateConfigurationVersion / deployment mechanisms (invoked outside Substation but acting on its config source)",
                            "Lambda configuration that binds the function to SUBSTATION_CONFIG or AppConfig"
                        ],
                        "related_data": [
                            "Updated Substation configuration artifact containing the AssumeRole configuration",
                            "Function configuration metadata in Lambda / AppConfig that determines which config version is active"
                        ],
                        "notes": "In many real environments this step occurs via CI/CD; compromising that pipeline or the backing S3/AppConfig resources is sufficient."
                    },
                    {
                        "step_id": 5,
                        "description": "Trigger Substation execution (for example via public API Gateway -> Lambda, S3/Kinesis/SQS events, or scheduled EventBridge rules) so the modified transforms run and internal/config.NewAWS calls STS:AssumeRole to obtain temporary credentials for the higher-privilege role.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "EventBridge rule triggering Lambda"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API POST method integrated with the Substation Lambda (AWS_PROXY)",
                            "Kinesis, S3, DynamoDB Streams, SNS, or SQS event sources bound to the Substation Lambda",
                            "EventBridge rules invoking the Lambda on schedules or patterns"
                        ],
                        "related_data": [
                            "Inbound event payloads that cause the Substation pipeline to run",
                            "STS temporary credentials for the assumed role (held in memory within the AWS SDK clients)",
                            "AWS resources that are now accessed using the higher-privilege role"
                        ],
                        "notes": "From this point onward, any write performed by the affected transforms runs under the assumed role. The attacker does not need to extract the temporary credentials; they can abuse the elevated actions directly via the pipeline."
                    },
                    {
                        "step_id": 6,
                        "description": "Abuse the newly elevated AWS actions available through Substation under the assumed role—for example, writing into more sensitive cross-account Kinesis streams or S3 buckets used by other systems, invoking higher-privilege Lambdas, or injecting events onto EventBridge buses in another account.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "Substation Lambda functions (container-image Lambdas)",
                            "Customer-managed KMS keys"
                        ],
                        "related_interfaces": [
                            "send_aws_kinesis_data_stream to cross-account or high-privilege Kinesis Data Streams",
                            "send_aws_s3 to buckets in other accounts or with stricter base access controls",
                            "send_aws_lambda to invoke privileged Lambda orchestrators",
                            "send_aws_eventbridge to inject events onto sensitive event buses"
                        ],
                        "related_data": [
                            "High-value data sinks such as central logging streams, admin-controlled S3 buckets, or orchestration event buses",
                            "Any data the attacker can feed into Substation that will be forwarded under the assumed role’s identity"
                        ],
                        "notes": "These downstream actions can be used to pivot further (for example, by triggering other privileged serverless functions or poisoning central data stores), but those later steps fall outside the scope of this privilege-escalation-focused analysis."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "AWS and GCP sink transforms",
                    "internal/config.NewAWS – Central AWS SDK helper that derives credentials from the default chain and optionally configures an STS AssumeRoleARN for cross-account access, providing an explicit mechanism for role assumption and potential privilege escalation via configuration changes.",
                    "Substation Lambda functions (container-image Lambdas)",
                    "Terraform IAM access patterns via var.access – S3, DynamoDB, Kinesis, SQS, SNS, Secrets, EventBridge, and Lambda modules attach powerful data-plane and KMS permissions to every role listed in var.access, so compromise of any such role (or its configuration usage) yields wide-reaching capabilities across multiple services."
                ],
                "interfaces_used": [
                    "Transform types send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_s3, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda",
                    "internal/config.NewAWS helper (including optional AssumeRoleARN support)",
                    "SUBSTATION_CONFIG environment variable and internal/file.Get config loader",
                    "AWS AppConfig application, environments, and configuration profiles",
                    "API Gateway REST APIs fronting Substation Lambdas",
                    "EventBridge rules and other AWS event sources (S3, Kinesis, DynamoDB Streams, SNS, SQS) that trigger the Lambda",
                    "Lambda invocation APIs (lambda:InvokeFunction / lambda:InvokeAsync) where used to drive execution directly"
                ],
                "data_accessed": [
                    "Substation configuration artifacts (Jsonnet/JSON) containing AWS transform definitions and AssumeRole ARNs",
                    "IAM role ARNs and trust policies for target roles",
                    "Event payloads processed by Substation and forwarded under the assumed role",
                    "Target AWS resources (S3 objects, Kinesis stream records, EventBridge events, Lambda invocations) written under elevated privileges"
                ],
                "preconditions_required": [
                    "An IAM role with higher privileges or in another account exists and is configured to trust a Substation-related role (for example the Lambda execution role) via STS:AssumeRole.",
                    "The Substation AWS configuration, via internal/config.NewAWS, is allowed by IAM policy to call sts:AssumeRole on the target role.",
                    "The attacker can modify or replace a Substation configuration used by a privileged runtime (for example, by controlling the S3 object or AppConfig profile referenced by SUBSTATION_CONFIG).",
                    "Outbound network access from the runtime to AWS STS and the target AWS services is available (typical for Lambda in a VPC with NAT)."
                ],
                "constraints_encountered": [
                    "Substation’s transform suite only exposes a limited subset of AWS APIs (primarily data-plane writes and Lambda/EventBridge invocations), so the attacker cannot directly call arbitrary admin APIs like iam:CreateUser; further escalation must be chained through reachable services.",
                    "If configuration is tightly controlled (for example, immutable images with embedded configs or AppConfig validator Lambdas that reject transforms using AssumeRoleARN), this vector may be blocked.",
                    "CloudTrail logging of sts:AssumeRole and data-plane calls may generate detectable traces, especially if the assumed role was not previously used by Substation."
                ],
                "evasion_considerations": [
                    "Embed AssumeRoleARN only into existing transforms rather than adding obvious new sinks, so pipeline structure changes minimally.",
                    "Target roles and resources that are plausible for the Substation deployment (for example, a cross-account logging stream) to reduce suspicion.",
                    "Revert configuration to its previous state after achieving the necessary elevated operations to minimize the observable window of abuse.",
                    "Throttle the volume and frequency of elevated actions to blend in with expected traffic patterns and CloudWatch metrics."
                ],
                "comments": "This vector turns Substation into a just-in-time role-assumption engine: once config is compromised, any event that drives the pipeline can silently exercise higher-privilege roles for the limited but powerful set of AWS APIs exposed by the send_aws_* transforms.",
                "escalated_access": "Temporary STS sessions for higher-privilege or cross-account IAM roles are transparently used by Substation’s AWS clients, allowing the attacker to perform privileged writes and invocations (S3, Kinesis, EventBridge, Lambda, etc.) that exceed the base Substation role’s intended scope."
            },
            {
                "can_achieve": true,
                "technique_name": "Event Triggered Execution",
                "technique_stix_id": "attack-pattern--b6301b64-ef57-4cce-bb0b-77026f14a8db",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise an IAM principal that is in var.access and thus has lambda:GetFunctionConfiguration and lambda:InvokeFunction permissions on a Substation Lambda, plus read/write access to the S3 bucket (or other store) that holds its SUBSTATION_CONFIG.",
                        "related_capabilities": [
                            "Terraform IAM access patterns via var.access – S3, DynamoDB, Kinesis, SQS, SNS, Secrets, EventBridge, and Lambda modules attach powerful data-plane and KMS permissions to every role listed in var.access.",
                            "Substation Lambda functions (container-image Lambdas) – execution roles with access to encrypted data stores and secrets.",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "Lambda access policy (substation-lambda-access-*) granting lambda:GetFunctionConfiguration and lambda:InvokeFunction to var.access roles",
                            "S3 bucket IAM policies created by build/terraform/aws/s3/main.tf that grant s3:GetObject/s3:PutObject to var.access roles"
                        ],
                        "related_data": [
                            "AWS access keys or role session for a var.access principal",
                            "Lambda function ARN and configuration metadata",
                            "S3 bucket names and prefixes used for configuration and/or data"
                        ],
                        "notes": "This is a realistic outcome of prior credential theft (for example, via compromised CI runner or developer workstation) and is explicitly enabled by the shared var.access policy pattern."
                    },
                    {
                        "step_id": 2,
                        "description": "Use lambda:GetFunctionConfiguration to read the Substation Lambda’s environment variables and determine how it loads its configuration (for example, SUBSTATION_CONFIG pointing at an S3 URL or AppConfig profile).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "Lambda invocation/configuration APIs exposed to var.access roles",
                            "SUBSTATION_CONFIG environment variable consumed by cmd/aws/lambda/substation/main.go:getConfig"
                        ],
                        "related_data": [
                            "Full Lambda configuration including environment variables, KMS key references, and possibly AppConfig identifiers",
                            "Configuration source URI (such as s3://config-bucket/path/to/config.json)"
                        ],
                        "notes": "This step turns opaque Lambda behavior into a concrete target: a specific config object or AppConfig profile that can be overwritten."
                    },
                    {
                        "step_id": 3,
                        "description": "Craft a malicious Substation configuration that, when loaded by the Lambda, retrieves sensitive secrets using utility_secret and then exfiltrates them using HTTP transforms.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "Secrets retrieval and interpolation – The 'Secrets retrieval and interpolation' capability plus internal/secrets and the utility_secret transform load secrets from AWS Secrets Manager and environment variables into an in-memory cache and expose them via ${SECRET:ID}, enabling broad secrets access to any configured transform.",
                            "HTTP enrichment and sending transforms – enrich_http_get, enrich_http_post, and send_http_post can interpolate cached secrets into URLs and headers, allowing an attacker who controls configuration to exfiltrate secrets or use high-privilege credentials against arbitrary HTTP endpoints."
                        ],
                        "related_interfaces": [
                            "utility_secret transform and ${SECRET:ID} interpolation syntax",
                            "internal/secrets retrievers: aws_secrets_manager and environment_variable",
                            "send_http_post (or enrich_http_post) transform to POST data to an attacker-controlled HTTPS endpoint"
                        ],
                        "related_data": [
                            "Logical secret IDs and ARNs for AWS Secrets Manager secrets accessible to the Lambda execution role",
                            "Environment variable names holding sensitive values (database passwords, API keys, AWS credentials) to be read via the environment_variable retriever",
                            "Attacker-controlled HTTPS URL used as the exfiltration sink"
                        ],
                        "notes": "The key is that all sensitive retrieval (secretsmanager:GetSecretValue, kms:Decrypt) happens under the Lambda execution role, which may have broader access than the compromised var.access principal."
                    },
                    {
                        "step_id": 4,
                        "description": "Overwrite the existing configuration artifact (for example, the S3 object referenced by SUBSTATION_CONFIG) with the malicious configuration using s3:PutObject or the equivalent mechanism for the active config source.",
                        "related_capabilities": [
                            "Terraform IAM access patterns via var.access",
                            "S3 buckets for Substation data"
                        ],
                        "related_interfaces": [
                            "S3 PutObject on the configuration object key",
                            "internal/file.Get (indirectly, when the Lambda reloads configuration from the modified S3 location)"
                        ],
                        "related_data": [
                            "Previous and new versions of the Substation configuration file",
                            "S3 object metadata (version IDs, timestamps) that may later be used for forensic analysis"
                        ],
                        "notes": "Because Substation loads configuration at runtime via internal/file.Get, modifying the backing object is sufficient; the Lambda configuration itself need not be updated."
                    },
                    {
                        "step_id": 5,
                        "description": "Invoke the Substation Lambda (for example via lambda:InvokeFunction, API Gateway, or another existing trigger path) so it loads the modified configuration, executes utility_secret under its execution role, and issues outbound HTTP requests containing the retrieved secrets.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Secrets retrieval and interpolation",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "lambda:InvokeFunction or InvokeAsync on the Substation Lambda function",
                            "API Gateway REST API POST method integrated with the Substation Lambda (if available)",
                            "send_http_post transform’s HTTP client, which uses internal/http with standard TLS"
                        ],
                        "related_data": [
                            "SNS/Kinesis/S3/API Gateway event payload used as a benign trigger",
                            "Secret values (for example AWS access keys, database credentials) placed into Substation message fields by utility_secret",
                            "HTTPS request bodies and headers sent to the attacker-controlled endpoint"
                        ],
                        "notes": "From the cloud provider’s perspective, all privileged actions (secrets retrieval, KMS decrypt) are performed by the Lambda execution role in response to a normal-looking invocation."
                    },
                    {
                        "step_id": 6,
                        "description": "Use the exfiltrated secrets outside of Substation—for example, log into the AWS console or CLI as more-privileged users, or connect to databases and other services whose credentials were stolen.",
                        "related_capabilities": [
                            "AWS Secrets Manager secrets (Terraform secret module) – secrets created for use by Substation and other workloads."
                        ],
                        "related_interfaces": [
                            "AWS CLI/SDK or web console using the stolen credentials",
                            "Non-AWS services (databases, SaaS APIs) that trust credentials stored in the stolen secrets"
                        ],
                        "related_data": [
                            "Exfiltrated cloud and application credentials recovered from HTTP payloads",
                            "Subsequent CloudTrail and service logs generated under the newly used accounts"
                        ],
                        "notes": "This step moves beyond Substation but is the point at which the attacker’s effective privileges in the cloud environment have clearly increased relative to the original var.access principal."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "Substation Lambda functions (container-image Lambdas)",
                    "Terraform IAM access patterns via var.access – S3, DynamoDB, Kinesis, SQS, SNS, Secrets, EventBridge, and Lambda modules attach powerful data-plane and KMS permissions to every role listed in var.access.",
                    "Secrets retrieval and interpolation – internal/secrets and utility_secret",
                    "HTTP enrichment and sending transforms – enrich_http_post and send_http_post",
                    "AWS Secrets Manager secrets (Terraform secret module)",
                    "Customer-managed KMS keys"
                ],
                "interfaces_used": [
                    "Lambda access policy granting lambda:GetFunctionConfiguration and lambda:InvokeFunction to var.access roles",
                    "SUBSTATION_CONFIG environment variable and config loader (internal/file.Get)",
                    "S3 GetObject/PutObject APIs on configuration buckets",
                    "utility_secret transform with aws_secrets_manager and environment_variable retrievers",
                    "send_http_post transform for outbound HTTPS",
                    "API Gateway REST API / direct Lambda invocation, where exposed publicly"
                ],
                "data_accessed": [
                    "Lambda configuration (environment variables, including SUBSTATION_CONFIG and AppConfig identifiers if used)",
                    "Substation configuration artifact overwritten with attacker-controlled content",
                    "Secrets Manager secret values and KMS-encrypted fields decrypted by the Lambda execution role",
                    "Environment variables on the Lambda that may hold additional secrets",
                    "HTTP payloads carrying exfiltrated credentials to attacker infrastructure"
                ],
                "preconditions_required": [
                    "An IAM principal in var.access has been compromised, giving the attacker lambda:GetFunctionConfiguration and lambda:InvokeFunction on the Substation Lambda.",
                    "The configuration source (typically an S3 object or AppConfig profile) is writable or replaceable by the compromised principal (for example, via s3:PutObject or AppConfig deployment permissions).",
                    "The Lambda execution role has more powerful secretsmanager:GetSecretValue and kms:Decrypt permissions than the compromised principal (or at least access to secrets that the var.access role cannot read directly).",
                    "Substation is configured to load configuration dynamically at runtime from the mutable source (rather than shipping a baked-in static config)."
                ],
                "constraints_encountered": [
                    "If SUBSTATION_CONFIG points to a read-only local file inside the container image or to a bucket the var.access roles cannot write to, the attacker cannot swap in a malicious config.",
                    "AppConfig validator Lambdas or external config review processes may detect suspicious additions such as utility_secret combined with send_http_post to external endpoints.",
                    "Outbound HTTP from the Lambda to arbitrary endpoints must be allowed by VPC and egress controls; strict egress filtering could limit or block exfiltration."
                ],
                "evasion_considerations": [
                    "Inject secret exfiltration into an existing HTTP integration (for example, adding headers or fields on an already-configured send_http_post) rather than adding an obviously new exfiltration endpoint.",
                    "Limit the number of malicious invocations and revert the configuration to its previous state after obtaining the needed secrets to reduce forensic visibility.",
                    "Keep the pipeline otherwise functionally equivalent (so that downstream consumers do not notice behavioral changes)."
                ],
                "comments": "This vector uses Substation’s Lambda as a privileged \"broker\" that can be driven by a lower-privilege principal: by corrupting configuration and triggering execution, an attacker can coerce the Lambda’s execution role into retrieving and exfiltrating secrets or other data they could not access directly.",
                "escalated_access": "The attacker upgrades from a var.access principal that can only invoke the Lambda and write configs to effectively wield the Lambda’s more-privileged execution role, retrieving secrets and performing sensitive operations via event-triggered execution."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Accounts",
                "technique_stix_id": "attack-pattern--f232fa7a-025c-4d43-abc7-318e81a73d65",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Obtain the ability to modify Substation pipeline configuration that runs under a privileged runtime (for example, a production Substation Lambda, Cloud Function, or CI-driven CLI run) that already has access to AWS Secrets Manager secrets and KMS keys.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS Secrets Manager secrets (Terraform secret module)",
                            "Customer-managed KMS keys"
                        ],
                        "related_interfaces": [
                            "Substation configuration files stored in Git/S3/AppConfig and processed by substation build/test/vet",
                            "SUBSTATION_CONFIG environment variable and internal/file.Get-based config loading",
                            "AppConfig application & environments providing hosted configuration"
                        ],
                        "related_data": [
                            "Production Substation configuration artifacts (including references to secrets and AWS resources)",
                            "Terraform secret definitions in build/terraform/aws/secret/main.tf that reveal secret names and ARNs"
                        ],
                        "notes": "This may be achieved by compromising the source repository, CI pipeline, S3 config bucket, or AppConfig configuration management process."
                    },
                    {
                        "step_id": 2,
                        "description": "Identify which Secrets Manager secrets or environment variables are likely to hold high-privilege cloud credentials, such as AWS IAM access keys, federated SSO tokens, or credentials for other administrative systems.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation – internal/secrets and utility_secret",
                            "AWS Secrets Manager secrets (Terraform secret module)"
                        ],
                        "related_interfaces": [
                            "Terraform secret module in build/terraform/aws/secret/main.tf (names and policies)",
                            "Existing Substation configs that already reference logical secret IDs via ${SECRET:ID}"
                        ],
                        "related_data": [
                            "Secret logical IDs and corresponding ARNs (for example, prod/admin/aws-root, cicd/admin/iam-user-keys)",
                            "Environment variable names that may store sensitive credentials"
                        ],
                        "notes": "In many real deployments, naming conventions and Terraform variable names make it obvious which secrets correspond to high-privilege identities."
                    },
                    {
                        "step_id": 3,
                        "description": "Augment the Substation configuration with additional utility_secret transforms that load the targeted secrets (or environment variables) into message fields using the ${SECRET:ID} and environment_variable mechanisms.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "utility_secret transform configuration with aws_secrets_manager retriever",
                            "utility_secret transform configuration with environment_variable retriever"
                        ],
                        "related_data": [
                            "Secret values retrieved from AWS Secrets Manager under the Lambda or process execution role",
                            "Environment variable–backed secrets cached into the in-memory KV store"
                        ],
                        "notes": "These transforms can be inserted early in the pipeline so that later transforms see the decrypted credential material as just another JSON field."
                    },
                    {
                        "step_id": 4,
                        "description": "Add or modify HTTP transforms (send_http_post or enrich_http_post) in the same configuration so that the message body or headers include the secret values, and point the HTTP target to an attacker-controlled HTTPS endpoint.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms – enrich_http_post and send_http_post",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "send_http_post transform with URL and headers that interpolate ${DATA} and ${SECRET:ID}",
                            "internal/http HTTP client wrapper using TLS to reach arbitrary HTTPS endpoints"
                        ],
                        "related_data": [
                            "Serialized JSON payloads containing exfiltrated credentials",
                            "HTTP headers or body fields carrying secrets (for example, Authorization-like fields or embedded base64 blobs)"
                        ],
                        "notes": "Because Substation does not enforce a hostname allow-list or TLS pinning, almost any HTTPS endpoint is a viable exfiltration sink."
                    },
                    {
                        "step_id": 5,
                        "description": "Ensure the modified configuration is deployed into the privileged runtime (Lambda, Cloud Function, or CLI job) and then trigger normal data processing so that the pipeline executes the secret-loading and exfiltration transforms.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Event sources such as API Gateway, S3 events, Kinesis, DynamoDB Streams, SNS, or SQS for AWS Lambdas",
                            "Cloud Storage events for the GCP Function",
                            "substation read / substation test / CI jobs for the CLI runner"
                        ],
                        "related_data": [
                            "Regular production messages (used only to drive the pipeline; content may be irrelevant to the secret theft)",
                            "Outgoing HTTP traffic to the attacker-controlled endpoint containing secrets"
                        ],
                        "notes": "To operators this may look like an additional observability or webhook sink unless endpoints and payload contents are carefully inspected."
                    },
                    {
                        "step_id": 6,
                        "description": "Use the stolen cloud credentials outside of Substation to authenticate as more-privileged cloud accounts (for example, AWS IAM users or roles), and then perform further operations such as reading proprietary data, modifying infrastructure, or creating additional persistence mechanisms.",
                        "related_capabilities": [
                            "AWS Secrets Manager secrets (Terraform secret module)",
                            "Customer-managed KMS keys"
                        ],
                        "related_interfaces": [
                            "AWS CLI/SDK using the exfiltrated keys to call CloudTrail, IAM, KMS, S3, DynamoDB, and other APIs",
                            "Cloud provider management consoles accessed with the stolen credentials"
                        ],
                        "related_data": [
                            "Exfiltrated key material, session tokens, or passwords",
                            "Subsequent high-privilege API calls and management actions in the victim’s cloud environment"
                        ],
                        "notes": "At this point the attacker’s privileges are no longer limited to what Substation itself can do; they hold independent high-privilege cloud identities."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "Configuration management and validation CLI",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Secrets retrieval and interpolation – internal/secrets and utility_secret",
                    "HTTP enrichment and sending transforms – enrich_http_get, enrich_http_post, send_http_post",
                    "AWS Secrets Manager secrets (Terraform secret module)",
                    "Customer-managed KMS keys"
                ],
                "interfaces_used": [
                    "utility_secret transform and ${SECRET:ID} interpolation syntax",
                    "internal/secrets aws_secrets_manager and environment_variable retrievers",
                    "send_http_post and enrich_http_post transforms for outbound HTTPS calls",
                    "Substation configuration artifacts referenced via SUBSTATION_CONFIG or AppConfig",
                    "Entry-point commands (Lambda handlers, GCP Function handler, substation CLI commands) that execute the compromised configuration"
                ],
                "data_accessed": [
                    "Sensitive secrets stored in AWS Secrets Manager (for example IAM access keys, database passwords, OAuth or SSO tokens)",
                    "Environment variables on Lambda/CLI processes that contain credentials or other security-sensitive values",
                    "Production message data used as a carrier or to blend exfiltrated secrets into normal traffic",
                    "HTTP logs and payloads at the attacker’s endpoint containing stolen credentials"
                ],
                "preconditions_required": [
                    "The attacker can modify Substation configurations that are executed under a runtime with secretsmanager:GetSecretValue and kms:Decrypt permissions.",
                    "The runtime environment has network egress to arbitrary HTTPS endpoints (no strict egress filtering or HTTP proxy with strong allow-listing).",
                    "Some of the accessible Secrets Manager secrets or environment variables actually contain higher-privilege cloud credentials (or credentials for systems from which the attacker can pivot to higher privileges)."
                ],
                "constraints_encountered": [
                    "If secrets are never exposed to Substation (for example, credentials are injected only into other services, or Substation uses IAM roles exclusively without static keys stored in Secrets Manager), this vector yields less value.",
                    "Strict outbound network controls or inspection (for example, egress firewalls or DLP on HTTP traffic) could detect or block exfiltration attempts.",
                    "Configuration review and testing processes (substation vet/test, AppConfig validators, code review) may flag unexpected HTTP sinks or references to highly sensitive secrets."
                ],
                "evasion_considerations": [
                    "Reuse existing HTTP destinations (for example, an internal webhook) and tunnel secrets through innocuous-looking fields to avoid drawing attention to new endpoints.",
                    "Throttle execution so that only a small number of messages per batch carry credential material, minimizing anomalies in traffic volume.",
                    "Leverage Jsonnet or complex configs to hide the malicious transforms among many legitimate ones, making static review harder."
                ],
                "comments": "This vector weaponizes Substation’s legitimate need to fetch and interpolate secrets: once an attacker controls configuration for a privileged runtime, they can exfiltrate high-value cloud credentials and then operate as those cloud accounts directly.",
                "escalated_access": "Control of configuration on a privileged Substation runtime allows the attacker to steal credentials for more-privileged cloud accounts (for example, administrative IAM users or roles) and use them independently, substantially increasing their control over the victim’s cloud environment."
            },
            {
                "can_achieve": true,
                "technique_name": "Valid Accounts",
                "technique_stix_id": "attack-pattern--b17a1a56-e99c-403c-8948-561df0cffe81",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain network access to a running Substation playground instance (the 'substation play' HTTP server) that is listening on an address reachable from the attacker (for example, bound to 0.0.0.0 or exposed via port forwarding/VPN).",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "Playground HTTP '/run' endpoint – The playground’s /run handler temporarily sets process environment variables from user input and runs Substation pipelines, providing a direct path to manipulate env-based configuration (including AWS credentials, SUBSTATION_CONFIG, and AppConfig-related variables) if the playground is reachable by an attacker."
                        ],
                        "related_interfaces": [
                            "cmd/substation/playground.go HTTP handlers '/', '/run', '/test', '/demo', '/fmt', '/share'",
                            "TCP port on which the playground HTTP server is listening"
                        ],
                        "related_data": [
                            "Playground URL and port (for example, http://developer-host:8080/)",
                            "Any banner or HTML served at '/' that identifies the Substation playground"
                        ],
                        "notes": "In many dev/test environments, the playground is started without authentication and may be accidentally exposed beyond localhost."
                    },
                    {
                        "step_id": 2,
                        "description": "Confirm that the /run endpoint accepts configuration and environment variable overrides from the HTTP request body by issuing benign test runs and inspecting responses.",
                        "related_capabilities": [
                            "Playground HTTP '/run' endpoint",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "HTTP POST /run with JSON body as implemented in cmd/substation/playground.go",
                            "Temporary environment variable setting/restoration behavior in /run"
                        ],
                        "related_data": [
                            "Echoed results of simple test pipelines run via /run",
                            "Any error messages that reveal supported request structure (for example, env fields, config fields)"
                        ],
                        "notes": "This reconnaissance step lets the attacker learn the exact JSON schema expected by /run without needing source access."
                    },
                    {
                        "step_id": 3,
                        "description": "Craft a malicious /run request whose embedded Substation configuration includes a utility_secret transform using the environment_variable retriever to read AWS credential environment variables (for example AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN), followed by an HTTP send transform to exfiltrate them.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation – internal/secrets/environment_variable retriever",
                            "HTTP enrichment and sending transforms – send_http_post",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "utility_secret transform with environment_variable retriever",
                            "send_http_post transform targeting an attacker-controlled HTTPS endpoint",
                            "Playground /run handler that applies env overrides and executes the provided pipeline"
                        ],
                        "related_data": [
                            "AWS credential environment variables present on the host running the playground (for example from a configured profile, instance role, or hard-coded variables)",
                            "HTTP request payload from the playground back to the attacker containing those credentials"
                        ],
                        "notes": "Because the playground temporarily applies environment-variable changes from the request, the attacker can also set or override variables like AWS_REGION or SUBSTATION_CONFIG if needed, but the key abuse is reading existing high-privilege credentials."
                    },
                    {
                        "step_id": 4,
                        "description": "Send the crafted /run request to the playground. The process sets any requested environment overrides, runs the Substation pipeline under the host’s AWS identity, loads the environment variable–backed secrets into messages, and then posts them to the attacker’s endpoint.",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "Playground HTTP '/run' endpoint",
                            "Secrets retrieval and interpolation",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "HTTP POST /run with attacker-supplied config and env overrides",
                            "internal/secrets environment_variable retriever executing in the playground process",
                            "send_http_post transform using internal/http to send data over HTTPS"
                        ],
                        "related_data": [
                            "AWS IAM access keys and session tokens from the developer’s or host’s environment",
                            "Any additional environment-based secrets (for example, database passwords, API tokens) captured by the same pipeline",
                            "HTTP logs on the attacker’s endpoint containing the exfiltrated credentials"
                        ],
                        "notes": "The playground restores the original environment after the run, but the attacker already has a copy of the credentials."
                    },
                    {
                        "step_id": 5,
                        "description": "Use the stolen AWS credentials as valid accounts to authenticate directly to the victim’s AWS environment via the CLI, SDKs, or console and perform further actions (for example, enumerating resources, reading sensitive data, or leveraging AssumeRole paths).",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "AWS CLI/SDK using the exfiltrated keys and tokens",
                            "AWS Management Console sessions authenticated with the stolen credentials"
                        ],
                        "related_data": [
                            "CloudTrail and service logs generated under the stolen account",
                            "Downloaded configuration, data, and metadata from the victim’s AWS services"
                        ],
                        "notes": "Depending on how the host is configured, the stolen credentials may correspond to highly privileged IAM users or roles (for example, a developer-admin profile or an instance role used for deployments)."
                    }
                ],
                "capabilities_used": [
                    "Local ingestion and transformation CLI",
                    "Playground HTTP '/run' endpoint – /run handler temporarily sets process environment variables from user input and runs Substation pipelines.",
                    "Secrets retrieval and interpolation – environment_variable retriever",
                    "HTTP enrichment and sending transforms – send_http_post"
                ],
                "interfaces_used": [
                    "cmd/substation/playground.go '/run' HTTP handler",
                    "HTTP POST /run endpoint accepting configuration and env overrides",
                    "utility_secret transform with environment_variable retriever",
                    "send_http_post transform to arbitrary HTTPS endpoints"
                ],
                "data_accessed": [
                    "AWS credential environment variables on the host running the playground (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, and similar)",
                    "Other sensitive environment variables (database credentials, API tokens) accessible to the playground process",
                    "HTTP payloads from the playground to the attacker carrying exfiltrated secrets"
                ],
                "preconditions_required": [
                    "A Substation playground instance is running and reachable from the attacker’s network location.",
                    "The playground process is running under an AWS identity that has nontrivial privileges (for example, a developer’s AWS profile or an instance role with access to production resources).",
                    "Environment_variable-based secrets are used (or the host stores AWS credentials in environment variables compatible with the internal/secrets environment_variable retriever)."
                ],
                "constraints_encountered": [
                    "If the playground is bound only to localhost and not exposed via SSH port forwarding, VPN, or misconfigured firewall rules, remote exploitation is not possible.",
                    "If the host lacks AWS credentials in environment variables (for example relying solely on local metadata-based roles that the process cannot expose as environment variables), the attacker may retrieve fewer useful secrets.",
                    "Local security tooling (endpoint protection, egress monitoring) may flag unusual outbound HTTPS requests from the playground process."
                ],
                "evasion_considerations": [
                    "Limit the number of /run invocations and keep request sizes small to avoid attracting attention in HTTP access logs.",
                    "Obfuscate payloads (for example, base64-encode credentials and embed them in fields that look like normal application data).",
                    "Avoid changing visible behavior of the playground (for example, still returning plausible results to the caller) to keep the compromise unnoticed by the legitimate user."
                ],
                "comments": "This vector turns an unauthenticated or weakly protected development-time feature into a serious privilege-escalation path: a remote attacker can coerce the playground to run arbitrary Substation pipelines under the host’s AWS identity and exfiltrate any credentials exposed via environment variables.",
                "escalated_access": "The attacker upgrades from having no valid cloud account to possessing valid AWS credentials stolen from a developer or instance running the playground, allowing direct authenticated access to the victim’s AWS environment."
            },
            {
                "can_achieve": true,
                "technique_name": "Additional Cloud Roles",
                "technique_stix_id": "attack-pattern--2dbbdcd5-92cf-44c0-aea2-fe24783a6bc3",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise the infrastructure-as-code workflow that manages Substation’s Terraform modules (for example, gain the ability to push changes to the repository and have them applied by CI/CD, or directly run terraform apply with appropriate credentials).",
                        "related_capabilities": [
                            "Configuration management and validation CLI (for Substation itself, indicating an established CI/CD culture)",
                            "Terraform IAM access patterns via var.access – shared IAM policies used across multiple modules"
                        ],
                        "related_interfaces": [
                            "Version control system hosting build/terraform/aws/* files",
                            "CI/CD pipelines or operator workflows that run terraform plan/apply for these modules"
                        ],
                        "related_data": [
                            "Terraform state and configuration for the Substation deployment",
                            "Credentials or roles used by the Terraform runner (typically highly privileged)"
                        ],
                        "notes": "This is a classic supply-chain foothold: the attacker becomes able to change how IAM is provisioned for Substation-related resources."
                    },
                    {
                        "step_id": 2,
                        "description": "Review the Terraform modules under build/terraform/aws/ to understand the var.access pattern that attaches broad permissions (S3, DynamoDB, Kinesis, SQS, SNS, Secrets, EventBridge, Lambda, KMS) to any principal listed in var.access.",
                        "related_capabilities": [
                            "Terraform IAM access patterns via var.access",
                            "S3 buckets for Substation data",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "DynamoDB tables for state and streaming change data",
                            "AWS Secrets Manager secrets",
                            "Customer-managed KMS keys"
                        ],
                        "related_interfaces": [
                            "IAM policies and role attachments declared in build/terraform/aws/s3.main.tf, dynamodb.main.tf, kinesis_data_stream.main.tf, sqs.main.tf, sns.main.tf, secret.main.tf, kms.main.tf, lambda.main.tf, eventbridge/lambda.main.tf"
                        ],
                        "related_data": [
                            "Current var.access values (role ARNs or principal IDs)",
                            "Action/Resource combinations in the access policies attached to var.access roles"
                        ],
                        "notes": "The analysis will show that being added to var.access effectively grants wide, multi-service data-plane and KMS privileges, which is much closer to an admin role than a narrow application role."
                    },
                    {
                        "step_id": 3,
                        "description": "Modify the Terraform configuration to add one or more attacker-controlled principals (for example, an external AWS account role or a lower-privilege in-tenant role the attacker already controls) into var.access, or to attach additional high-privilege policies to existing Substation roles.",
                        "related_capabilities": [
                            "Terraform IAM access patterns via var.access",
                            "Customer-managed KMS keys",
                            "AWS Secrets Manager secrets"
                        ],
                        "related_interfaces": [
                            "Terraform variables and module inputs that set var.access",
                            "Inline IAM policy documents within the Terraform modules"
                        ],
                        "related_data": [
                            "Updated var.access principal list including attacker-controlled role ARNs",
                            "Modified IAM policies granting broader actions (for example, additional kms:*, iam:*, or sts:* permissions) to Substation-related roles"
                        ],
                        "notes": "This is directly analogous to adversary playbooks where they add their own service principals or admin roles into cloud IAM after compromising an admin account."
                    },
                    {
                        "step_id": 4,
                        "description": "Trigger terraform apply so that AWS creates or updates IAM roles and policies, granting the attacker-controlled principals the new, broader permissions defined by the Substation modules.",
                        "related_capabilities": [
                            "Terraform IAM access patterns via var.access"
                        ],
                        "related_interfaces": [
                            "Terraform apply run by CI/CD or an operator",
                            "AWS IAM APIs invoked by Terraform to create/update roles and policies"
                        ],
                        "related_data": [
                            "New or updated IAM roles and policies in the victim AWS account",
                            "CloudTrail logs for IAM CreateRole, AttachRolePolicy, PutRolePolicy, and similar events"
                        ],
                        "notes": "Once the apply completes, the attacker has effectively granted themselves a \"Substation super-role\" spanning data-plane and KMS access to all resources managed by these modules."
                    },
                    {
                        "step_id": 5,
                        "description": "Authenticate as the attacker-controlled principal that was added to var.access, and exercise the newly obtained privileges across S3, DynamoDB, Kinesis, SQS/SNS, Secrets Manager, EventBridge, Lambda, and KMS.",
                        "related_capabilities": [
                            "S3 buckets for Substation data",
                            "DynamoDB tables for state and streaming change data",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "SQS queues for buffered processing",
                            "SNS topics for notifications and autoscaling",
                            "AWS Secrets Manager secrets",
                            "Customer-managed KMS keys",
                            "Substation Lambda functions (container-image Lambdas)",
                            "CloudWatch Logs destinations and subscriptions"
                        ],
                        "related_interfaces": [
                            "Data-plane APIs: s3:GetObject/s3:PutObject, dynamodb:GetItem/PutItem/UpdateItem/BatchWriteItem, kinesis:GetRecords/PutRecords/UpdateShardCount, sqs:SendMessage/ReceiveMessage/DeleteMessage, sns:Publish, events:PutEvents, lambda:InvokeFunction",
                            "KMS APIs: kms:Decrypt and kms:GenerateDataKey",
                            "Secrets Manager API: secretsmanager:GetSecretValue"
                        ],
                        "related_data": [
                            "All data in Substation-managed S3 buckets, DynamoDB tables, and Kinesis streams",
                            "Messages in SQS/SNS, including those from other systems integrated via Substation",
                            "Secrets in Secrets Manager and the plaintext of all KMS-encrypted data under the granted keys"
                        ],
                        "notes": "At this point the attacker has effectively obtained a powerful cross-service cloud role that goes far beyond what any individual Substation component strictly needs."
                    }
                ],
                "capabilities_used": [
                    "Terraform IAM access patterns via var.access – S3, DynamoDB, Kinesis, SQS, SNS, Secrets, EventBridge, and Lambda modules attach powerful data-plane and KMS permissions to every role listed in var.access.",
                    "Customer-managed KMS keys",
                    "AWS Secrets Manager secrets",
                    "S3 buckets for Substation data",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "DynamoDB tables for state and streaming change data",
                    "SQS queues for buffered processing",
                    "SNS topics for notifications and autoscaling",
                    "Substation Lambda functions (container-image Lambdas)"
                ],
                "interfaces_used": [
                    "Terraform modules under build/terraform/aws/* that define IAM roles and access policies",
                    "CI/CD or operator-run terraform plan/apply workflows",
                    "AWS IAM APIs used by Terraform to create and update roles and policies",
                    "Data-plane and KMS APIs exposed to principals listed in var.access (S3, DynamoDB, Kinesis, SQS, SNS, EventBridge, Lambda, Secrets Manager, KMS)"
                ],
                "data_accessed": [
                    "Terraform configuration and state for Substation infrastructure",
                    "IAM roles, policies, and trust relationships defined or modified by the Substation Terraform modules",
                    "Data and secrets stored in all AWS services to which var.access roles are granted access",
                    "KMS-encrypted payloads across S3, DynamoDB, Kinesis, SQS, SNS, Secrets, ECR, and Lambda environment variables"
                ],
                "preconditions_required": [
                    "The attacker can modify the Substation Terraform configuration and cause terraform apply to run (for example by compromising the IaC repository and CI/CD runner or by abusing an operator’s credentials).",
                    "The organization is using the provided Terraform modules (or close derivatives) and has not significantly constrained var.access usage.",
                    "The attacker controls or can impersonate at least one principal (user or role) that they can safely add to var.access without immediate detection."
                ],
                "constraints_encountered": [
                    "Strong change-management and code-review processes for Terraform may detect suspicious changes to var.access or IAM policies.",
                    "Drift detection and security tooling (for example, IAM analyzers, CIS scanners) might highlight sudden expansion of permissions.",
                    "If Terraform is not the authoritative source for IAM (for example manual changes are common, or other stacks manage IAM), this path may be less effective or could trigger conflicts."
                ],
                "evasion_considerations": [
                    "Add the attacker-controlled principal in a way that appears consistent with existing patterns (for example, as another application role rather than an obviously external account).",
                    "Avoid granting explicit AdministratorAccess; instead, rely on the already-broad Substation module policies to keep changes subtle.",
                    "Stage changes across multiple smaller commits to reduce the chance that a single review catches the full blast radius."
                ],
                "comments": "Because multiple Substation Terraform modules share a common var.access-based access pattern, compromising that configuration allows an adversary to grant themselves a de facto cross-service admin role spanning storage, streaming, messaging, secrets, and KMS—exactly the type of long-lived privileged identity that Additional Cloud Roles in MITRE ATT&CK describes.",
                "escalated_access": "The attacker gains one or more newly privileged IAM roles (or expands existing ones) that provide broad, persistent access to Substation-managed resources across S3, DynamoDB, Kinesis, SQS/SNS, Secrets Manager, EventBridge, Lambda, and KMS, far exceeding their original permissions."
            }
        ],
        "summary": "Within Substation and its accompanying AWS/GCP infrastructure, realistic privilege escalation revolves around three main themes: (1) abusing configuration-driven AWS client behavior (especially internal/config.NewAWS and configuration sources like SUBSTATION_CONFIG/AppConfig) to assume higher-privilege roles or drive privileged Lambdas (Temporary Elevated Cloud Access and Event Triggered Execution); (2) using Substation’s secrets and HTTP capabilities to steal high-value cloud credentials and then operate as those more-privileged cloud accounts (Cloud Accounts and Valid Accounts via the playground /run endpoint); and (3) compromising the Terraform/IaC layer to add attacker-controlled principals into the shared var.access access pattern, effectively minting new cross-service admin-like roles (Additional Cloud Roles). All of these vectors depend on governance weaknesses around configuration, IaC, and development-time tooling rather than code-level vulnerabilities in Substation itself, but if those governance assumptions fail, Substation becomes a powerful vehicle for escalating privileges across the surrounding cloud environment."
    },
    "defense-evasion": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Disable or Modify Tools",
                "technique_stix_id": "attack-pattern--ac08589e-ee59-4935-8667-d845e38fe579",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify how each targeted Substation workload (Lambda, GCP Function, CLI job) loads its pipeline configuration, using environment variables such as SUBSTATION_CONFIG or AppConfig bindings to locate the Jsonnet/JSON config files that define transforms, including metric transforms.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Configuration management and validation CLI",
                            "Metrics and observability transforms",
                            "AWS AppConfig application & environments"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable and getConfig helpers (cmd/aws/lambda/substation/main.go, cmd/gcp/function/substation/main.go)",
                            "AppConfig → Lambda configuration consumption (build/terraform/aws/appconfig/main.tf)",
                            "Jsonnet/JSON configuration files for substation.Config / []config.Config",
                            "substation.New(ctx, Config) constructor"
                        ],
                        "related_data": [
                            "Jsonnet/JSON pipeline configuration files defining []config.Config",
                            "substation.Config including ordered transform list",
                            "AppConfig configuration profiles that store hosted Substation configs",
                            "Environment variables for configuration selection (SUBSTATION_CONFIG, SUBSTATION_LAMBDA_HANDLER, SUBSTATION_FUNCTION_HANDLER)"
                        ],
                        "notes": "Mirrors how real attackers first map where security tooling gets its configuration before disabling it (e.g., SUNBURST enumerating and then disabling security services)."
                    },
                    {
                        "step_id": 2,
                        "description": "Gain write access to those configuration artifacts or sources (e.g., config repo, S3 bucket, GCS bucket, HTTP config host, or AppConfig profiles) and retrieve the active config for each high-value pipeline that processes crown-jewel data such as central logs, business transactions, or change streams.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Local ingestion and transformation CLI",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "CLI commands: substation build, substation fmt, substation test, substation vet",
                            "internal/file.Get() for local/HTTP/S3/GCS config loading",
                            "AppConfig configuration profiles and environments"
                        ],
                        "related_data": [
                            "Config repositories and files used by CI/CD or operators",
                            "S3 or GCS objects referenced by SUBSTATION_CONFIG",
                            "AppConfig hosted configuration JSON"
                        ],
                        "notes": "This step assumes the attacker has already compromised a developer, CI pipeline, or cloud admin with write access to configuration."
                    },
                    {
                        "step_id": 3,
                        "description": "Edit each targeted config to remove or neuter metric-related transforms (utility_metric_bytes, utility_metric_count, utility_metric_freshness, meta_metric_duration) from the main processing path, or move them into rarely-executed branches so normal traffic no longer triggers metric emission.",
                        "related_capabilities": [
                            "Metrics and observability transforms",
                            "Core Substation transformation engine",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "Transform types: utility_metric_bytes, utility_metric_count, utility_metric_freshness, meta_metric_duration",
                            "Jsonnet/JSON transform lists in substation.Config / []config.Config",
                            "substation fmt / substation build for editing/writing configs"
                        ],
                        "related_data": [
                            "Metric-transform configuration blocks (metric names, dimensions, thresholds)",
                            "Per-pipeline transform order and branching configuration"
                        ],
                        "notes": "Analogous to malware that stops or disables endpoint AV/EDR agents: the metric transforms are the primary in-app observability tools."
                    },
                    {
                        "step_id": 4,
                        "description": "Adjust pipeline control-message behavior so that even residual metric transforms emit as little telemetry as possible—for example, suppressing control messages in hot paths or placing metric transforms only in setup/teardown branches that are rarely executed.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "Metrics and observability transforms"
                        ],
                        "related_interfaces": [
                            "Message control flag semantics in message.Message",
                            "Control-message generation at CLI/Lambda/Function entry points",
                            "Metric transforms’ reliance on control messages for EMF emission"
                        ],
                        "related_data": [
                            "Message batches and final control messages per invocation",
                            "Metrics.Data aggregation state inside metric transforms"
                        ],
                        "notes": "Because metrics are emitted on control messages, starving control messages effectively disables metrics without touching AWS logging configuration."
                    },
                    {
                        "step_id": 5,
                        "description": "Optionally reduce human-readable logging by ensuring SUBSTATION_DEBUG is unset or disabled in Lambda/Function environments and CLI runs, keeping internal/log at Info level and minimizing operational detail that might reveal missing metrics or anomalous behavior.",
                        "related_capabilities": [
                            "internal/log logging wrapper",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_DEBUG environment variable",
                            "internal/log package (logrus wrapper)"
                        ],
                        "related_data": [
                            "Lambda and CLI stdout/stderr log streams in CloudWatch Logs",
                            "Playground HTTP responses and logs if used in dev/test"
                        ],
                        "notes": "This mirrors attacker behavior that disables verbose logging or debug traces in security tools to limit forensics."
                    },
                    {
                        "step_id": 6,
                        "description": "Deploy the modified configs back to their original locations (S3/GCS/HTTP/AppConfig config profile) and allow running Lambdas/Functions/CLIs to reload them on next invocation, verifying that business functionality continues while Substation-specific metrics disappear from CloudWatch.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Configuration management and validation CLI",
                            "Metrics and observability transforms"
                        ],
                        "related_interfaces": [
                            "Lambda cold-start configuration fetch via internal/file.Get and/or AppConfig",
                            "CloudWatch Logs groups and embedded metrics",
                            "substation test / substation vet for pre-deploy validation"
                        ],
                        "related_data": [
                            "CloudWatch EMF metric series created by Substation",
                            "CloudWatch metric alarms (if any) bound to Substation EMF metrics"
                        ],
                        "notes": "As with real-world tool disabling, the attacker attempts to keep primary functionality intact so operators do not immediately notice observability loss."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "Metrics and observability transforms",
                    "Configuration management and validation CLI",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "internal/log logging wrapper",
                    "AWS AppConfig application & environments",
                    "CloudWatch Logs groups and embedded metrics"
                ],
                "interfaces_used": [
                    "Transform types utility_metric_bytes, utility_metric_count, utility_metric_freshness, meta_metric_duration",
                    "Jsonnet/JSON pipeline configuration files (substation.Config, []config.Config)",
                    "SUBSTATION_CONFIG environment variable and internal/file.Get() resolution",
                    "AppConfig configuration profiles and GetConfiguration* APIs",
                    "CLI commands: substation build, substation fmt, substation test, substation vet",
                    "internal/log package controlled by SUBSTATION_DEBUG"
                ],
                "data_accessed": [
                    "Pipeline configuration files and hosted configs that determine which transforms run",
                    "Metric configuration (metric names, dimensions, thresholds) embedded in utility_metric_* and meta_metric_duration settings",
                    "Embedded metrics EMF JSON emitted to stdout",
                    "CloudWatch metric series derived from EMF output",
                    "Lambda/Function stdout/stderr used for operational logs"
                ],
                "preconditions_required": [
                    "Attacker has write access to Substation configuration artifacts (Git/Jsonnet/JSON files, S3/GCS/HTTP config sources, or AppConfig profiles) used by targeted workloads.",
                    "Attacker can ensure modified configs are deployed or referenced (e.g., by changing SUBSTATION_CONFIG or AppConfig bindings if needed).",
                    "Defenders rely significantly on Substation’s internal metrics for observability, rather than only on underlying AWS/GCP service logs."
                ],
                "constraints_encountered": [
                    "Configuration changes may be subject to code review or CI validation (substation vet/test); the attacker must craft syntactically valid configurations that preserve functional behavior.",
                    "Even with Substation metrics disabled, AWS-managed telemetry such as Lambda invocation metrics and CloudWatch Logs for function executions will still exist and may reveal anomalous behavior.",
                    "If external monitoring explicitly checks for the presence of specific Substation metrics, the sudden disappearance of metric series could itself be a detection signal."
                ],
                "evasion_considerations": [
                    "Instead of removing all metric transforms, keep a minimal subset that reports only coarse-grained or innocuous metrics to avoid obviously blank dashboards.",
                    "Rename metrics and dimensions subtly so existing alert rules no longer match while dashboards still display some data.",
                    "Stage changes gradually across pipelines to look like normal refactoring or optimization work rather than a sudden stop in observability."
                ],
                "comments": "This is the lowest-friction defense evasion path because Substation’s metrics are entirely config-driven and optional; disabling or starving metric transforms is akin to turning off a monitoring agent while leaving the workload itself untouched.",
                "evasion_achieved": "Application-level monitoring via Substation EMF metrics is silently disabled or degraded, reducing CloudWatch-based visibility into pipeline behavior even though the workloads continue to run."
            },
            {
                "can_achieve": true,
                "technique_name": "Disable or Modify Cloud Logs",
                "technique_stix_id": "attack-pattern--cacc40da-4c9e-462c-80d5-fd70a178b12d",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Map the centralized logging architecture by reviewing Terraform modules to identify the CloudWatch Logs destination, the downstream Kinesis or Firehose destination_arn, the set of subscribed log groups, and the list of external accounts allowed to attach subscriptions.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "CloudWatch Logs groups and embedded metrics"
                        ],
                        "related_interfaces": [
                            "build/terraform/aws/cloudwatch/destination/main.tf (aws_cloudwatch_log_destination.destination, destination IAM role, destination policy)",
                            "build/terraform/aws/cloudwatch/subscription/main.tf (aws_cloudwatch_log_subscription_filter.subscription_filter, var.config.log_groups)",
                            "build/terraform/aws/kinesis_data_stream/main.tf (central Kinesis stream and access policy)"
                        ],
                        "related_data": [
                            "Destination ARN for centralized logs (Kinesis or Firehose)",
                            "List of log groups subscribed via var.config.log_groups",
                            "Account IDs in var.config.account_ids that may create subscription filters"
                        ],
                        "notes": "Similar to how tools like Pacu enumerate CloudTrail and flow log configurations before disabling them."
                    },
                    {
                        "step_id": 2,
                        "description": "Obtain permissions to modify CloudWatch Logs destinations and subscription filters, either by compromising Terraform/IaC pipelines or accounts with logs:PutSubscriptionFilter and access to the destination policy.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs API: logs:PutSubscriptionFilter, logs:DeleteSubscriptionFilter",
                            "Terraform plans applied against cloudwatch/destination and cloudwatch/subscription modules"
                        ],
                        "related_data": [
                            "CloudWatch Logs destination resource policy granting logs:PutSubscriptionFilter",
                            "IAM role substation-cloudwatch-dest-* assumed by logs.amazonaws.com"
                        ],
                        "notes": "In many real incidents, attackers achieve this via stolen cloud-admin credentials or control of the organization’s IaC tooling."
                    },
                    {
                        "step_id": 3,
                        "description": "Stop forwarding specific high-value log groups (for example, those for Substation Lambdas handling security telemetry) by removing them from var.config.log_groups or deleting/changing their subscription filters so their events no longer reach the central Kinesis/Firehose destination.",
                        "related_capabilities": [
                            "CloudWatch Logs subscription routing",
                            "CloudWatch Logs groups and embedded metrics"
                        ],
                        "related_interfaces": [
                            "aws_cloudwatch_log_subscription_filter.subscription_filter resources",
                            "var.config.log_groups Terraform variable"
                        ],
                        "related_data": [
                            "Source log group ARNs for Substation Lambdas and related services",
                            "Subscription filter configurations for those log groups"
                        ],
                        "notes": "This directly mirrors MITRE examples where attackers bypass centralized logging like CloudTrail by disabling its integrations."
                    },
                    {
                        "step_id": 4,
                        "description": "Optionally, modify the CloudWatch Logs destination policy or destination_arn so that logs from certain accounts or groups are written to an attacker-controlled or less-monitored Kinesis/Firehose stream, rather than to the security team’s primary monitoring account.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "aws_cloudwatch_log_destination.destination resource policy (allowed account_ids)",
                            "destination_arn variable in cloudwatch/destination Terraform module"
                        ],
                        "related_data": [
                            "Destination Kinesis stream or Firehose ARNs (potentially in another account)",
                            "KMS CMK configuration for encrypted log streams, if used"
                        ],
                        "notes": "This is analogous to tampering with log sinks (e.g., changing CloudTrail S3 buckets) so that defenders lose access while logs remain available to the attacker."
                    },
                    {
                        "step_id": 5,
                        "description": "Allow Substation pipelines and Lambdas to continue running normally, ensuring stdout/stderr still go to their original CloudWatch log groups but are no longer forwarded to the central destination, creating an appearance of normal operation in the application account while blinding centralized SIEM/monitoring environments.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "CloudWatch Logs groups and embedded metrics",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "AWSLambdaBasicExecutionRole on Lambda execution roles (logs:CreateLogGroup/CreateLogStream/PutLogEvents)",
                            "aws_cloudwatch_log_subscription_filter.subscription_filter (now removed or modified)"
                        ],
                        "related_data": [
                            "Application log streams in the source account that are no longer aggregated centrally",
                            "Central Kinesis/Firehose log streams that stop receiving events for certain workloads"
                        ],
                        "notes": "APT29 and other actors have done analogous moves in SaaS environments by disabling audit logging just for targeted mailboxes while leaving the rest intact."
                    }
                ],
                "capabilities_used": [
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "CloudWatch Logs groups and embedded metrics",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "AWS Lambda Substation event processors"
                ],
                "interfaces_used": [
                    "Terraform module build/terraform/aws/cloudwatch/destination/main.tf (CloudWatch Logs destination, role, and policy)",
                    "Terraform module build/terraform/aws/cloudwatch/subscription/main.tf (log group subscription filters)",
                    "Terraform module build/terraform/aws/kinesis_data_stream/main.tf (central Kinesis stream and IAM policy)",
                    "CloudWatch Logs APIs: logs:PutSubscriptionFilter, logs:DeleteSubscriptionFilter"
                ],
                "data_accessed": [
                    "CloudWatch Logs events from Substation Lambda log groups",
                    "Subscription filter definitions for log groups listed in var.config.log_groups",
                    "Kinesis or Firehose log streams used as centralized destinations",
                    "CloudWatch Logs destination resource policy listing allowed account_ids"
                ],
                "preconditions_required": [
                    "Attacker has permissions equivalent to controlling Terraform for logging modules, or direct AWS permissions to manage CloudWatch Logs destinations and subscription filters.",
                    "Centralized monitoring (SIEM, SOC dashboards) relies primarily on the centralized Kinesis/Firehose destination rather than querying each source account’s log groups directly.",
                    "Destination Kinesis/Firehose streams are within the scope of the Substation infrastructure or otherwise accessible with compromised credentials."
                ],
                "constraints_encountered": [
                    "Source account operators with direct access to CloudWatch Logs in those accounts may still see complete logs and notice the absence of centralized forwarding.",
                    "Other organization-wide controls (e.g., CloudTrail-based config monitoring, AWS Config rules) could flag changes to log destinations and subscriptions, though these are out of scope for this repo.",
                    "Misconfiguring subscriptions too aggressively can break legitimate observability workflows and prompt investigation if teams quickly notice sudden drops in log volume."
                ],
                "evasion_considerations": [
                    "Instead of removing subscriptions entirely, narrow filter patterns to exclude specific noisy or sensitive events while still forwarding enough data to appear normal.",
                    "Change destination_arn to a stream in another monitoring account controlled by the attacker, so defenders see an unexplained gap while the attacker retains a full copy.",
                    "Stagger modifications across log groups so there is no single dramatic drop in centralized log volume."
                ],
                "comments": "This vector leverages the fact that Substation deployments centralize logging through dedicated CloudWatch Logs destinations and Kinesis/Firehose streams. An attacker who controls those resources can effectively ‘turn off’ or reroute centralized visibility without touching the workloads themselves.",
                "evasion_achieved": "Centralized CloudWatch log forwarding and aggregation is selectively disabled or redirected, preventing security teams from seeing targeted Substation and related AWS logs in their primary monitoring environment."
            },
            {
                "can_achieve": true,
                "technique_name": "Impair Defenses",
                "technique_stix_id": "attack-pattern--3d333250-30e4-4a82-9edc-756c68afc529",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Profile which Kinesis Data Streams and CloudWatch metric alarms are used to carry and monitor high-value telemetry (for example, streams that receive centralized CloudWatch Logs via the destination/subscription modules or business-critical event streams).",
                        "related_capabilities": [
                            "Kinesis autoscaling controller",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "CloudWatch metric alarms for Kinesis auto-scaling",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "build/terraform/aws/kinesis_data_stream/main.tf (stream and autoscaling alarm definitions)",
                            "build/terraform/aws/cloudwatch/destination/main.tf (central log destination_arn)",
                            "build/terraform/aws/cloudwatch/subscription/main.tf (log groups forwarded into those streams)"
                        ],
                        "related_data": [
                            "Kinesis stream names and ARNs",
                            "Metric-math alarm definitions for IncomingRecords/IncomingBytes per shard",
                            "Stream tags such as MinimumShards, MaximumShards, LastScalingEvent"
                        ],
                        "notes": "This step mirrors attackers identifying which telemetry/control channels to degrade, similar to JumbledPath impairing logging across multiple devices."
                    },
                    {
                        "step_id": 2,
                        "description": "Compromise the Kinesis autoscaling controller Lambda role or its configuration channel (e.g., access to its environment variables and code, or the SNS topic it listens to) so you can influence how it updates shard counts and rewrites CloudWatch alarms.",
                        "related_capabilities": [
                            "Kinesis autoscaling controller",
                            "CloudWatch metric alarms for Kinesis auto-scaling"
                        ],
                        "related_interfaces": [
                            "cmd/aws/lambda/autoscale/main.go (autoscale Lambda handler and client initialization)",
                            "SNS topic for autoscaling alarms (var.config.autoscaling_topic)",
                            "Environment variables AUTOSCALE_KINESIS_* controlling thresholds and datapoints"
                        ],
                        "related_data": [
                            "CloudWatch alarm SNS notification payloads",
                            "Autoscaler environment variable values",
                            "Autoscaler Lambda execution role policies"
                        ],
                        "notes": "Real-world campaigns have abused privileged orchestrator roles in similar ways to modify security- or availability-related configuration across fleets."
                    },
                    {
                        "step_id": 3,
                        "description": "Lower shard counts or enforce small MaximumShards on logging/monitoring streams by calling Kinesis UpdateShardCount through the autoscale Lambda (or directly with the compromised role), ensuring those streams saturate at lower throughput and start dropping or delaying log and telemetry records under load.",
                        "related_capabilities": [
                            "Kinesis autoscaling controller",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "Kinesis API: UpdateShardCount",
                            "Stream tags MinimumShards and MaximumShards read and written by the autoscaler"
                        ],
                        "related_data": [
                            "Current and target shard counts per monitored stream",
                            "Autoscaler internal calculations of desired shard counts"
                        ],
                        "notes": "This is analogous to attackers misconfiguring capacity so that security telemetry pipelines choke when malicious activity generates high volume."
                    },
                    {
                        "step_id": 4,
                        "description": "Simultaneously weaken or rewrite the CloudWatch metric alarms associated with those streams (via CloudWatch PutMetricAlarm and SetAlarmState) by raising thresholds, shortening evaluation periods, or switching alarms to less sensitive metrics so that stream saturation does not trigger alerts.",
                        "related_capabilities": [
                            "Kinesis autoscaling controller",
                            "CloudWatch metric alarms for Kinesis auto-scaling"
                        ],
                        "related_interfaces": [
                            "CloudWatch API: PutMetricAlarm",
                            "CloudWatch API: SetAlarmState",
                            "Metric-math alarm expressions defined in build/terraform/aws/kinesis_data_stream/main.tf"
                        ],
                        "related_data": [
                            "Alarm threshold values, periods, and comparison operators",
                            "Alarm state transitions recorded in CloudWatch"
                        ],
                        "notes": "This parallels MITRE examples where malware modifies logging/monitoring artifacts (e.g., BOLDMOVE modifying Fortinet logs) to keep defenses from reacting."
                    },
                    {
                        "step_id": 5,
                        "description": "Drive or wait for high-volume ingestion on those impaired streams (for example, by exploiting public API Gateway → Kinesis or Lambda endpoints, or by generating large log volumes) so that centralized logging and telemetry pipelines experience backpressure or loss while alarms remain quiet.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API POST methods with authorization = NONE",
                            "CloudWatch Logs → Kinesis/Firehose subscription filters"
                        ],
                        "related_data": [
                            "Incoming Kinesis record rates compared to reduced shard capacity",
                            "Resulting delay or loss in log/telemetry processing downstream"
                        ],
                        "notes": "Rather than directly deleting logs, the attacker causes systemic telemetry loss by under-provisioning and then overloading logging streams."
                    }
                ],
                "capabilities_used": [
                    "Kinesis autoscaling controller",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "CloudWatch metric alarms for Kinesis auto-scaling",
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Public HTTP APIs via API Gateway (direct to Kinesis)"
                ],
                "interfaces_used": [
                    "Autoscale Lambda SNS handler (cmd/aws/lambda/autoscale/main.go)",
                    "Environment variables AUTOSCALE_KINESIS_*",
                    "Kinesis API: UpdateShardCount and AddTagsToStream",
                    "CloudWatch API: PutMetricAlarm and SetAlarmState",
                    "API Gateway POST / endpoints with authorization = NONE (Lambda proxy and Kinesis PutRecord)",
                    "Terraform modules: build/terraform/aws/kinesis_data_stream/main.tf, cloudwatch/destination, cloudwatch/subscription"
                ],
                "data_accessed": [
                    "Kinesis stream configuration (shard counts, tags)",
                    "CloudWatch alarm configurations and state for Kinesis utilization",
                    "SNS messages generated by CloudWatch alarms",
                    "Log and telemetry records flowing through affected Kinesis streams"
                ],
                "preconditions_required": [
                    "Attacker can assume or compromise the Kinesis autoscaling Lambda execution role or another role in var.access with kinesis:UpdateShardCount and cloudwatch:PutMetricAlarm/SetAlarmState permissions.",
                    "Targeted Kinesis streams are actually used for centralized logging or other security-relevant telemetry.",
                    "Defensive alerting on those streams relies on the CloudWatch alarms that the autoscaler can modify."
                ],
                "constraints_encountered": [
                    "Significant under-provisioning can cause noticeable operational impact (pipeline failures, backlog) that may prompt investigation irrespective of missing alarms.",
                    "Some organizations may have additional, out-of-band monitors on Kinesis error metrics or consumer lag that are not controlled by this autoscaler.",
                    "CloudTrail or similar audit logs (outside this repo) may record abnormal UpdateShardCount and alarm changes, giving defenders forensic visibility post hoc."
                ],
                "evasion_considerations": [
                    "Make modest, gradual changes to shard counts and thresholds so that telemetry degradation is subtle and attributed to ‘normal’ scaling adjustments.",
                    "Target only specific monitoring streams (e.g., central log streams) rather than all Kinesis streams to reduce the chance of broad outages drawing attention.",
                    "Time scaling changes to align with expected traffic spikes (e.g., business peaks) so poor stream performance appears to be an ordinary capacity issue."
                ],
                "comments": "This vector uses Substation’s own autoscaling controller and Kinesis/CloudWatch permissions to indirectly blind or degrade monitoring pipelines, rather than tampering with individual logs. It aligns with real intrusions where attackers impair log collection or EDR telemetry along the path to compromised systems.",
                "evasion_achieved": "Logging and telemetry streams that underpin monitoring are under-provisioned and poorly alarmed, causing silent loss or severe delay of security-relevant data under load."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Accounts",
                "technique_stix_id": "attack-pattern--f232fa7a-025c-4d43-abc7-318e81a73d65",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise valid cloud identities that Substation already uses, such as Lambda execution roles, roles in var.access, or CI/CD service principals that deploy configurations and Terraform, so subsequent activity appears to originate from legitimate Substation accounts.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms",
                            "Configuration management and validation CLI",
                            "Terraform IAM access policies for Kinesis streams and autoscaling",
                            "AWS Secrets Manager secrets"
                        ],
                        "related_interfaces": [
                            "Lambda execution roles defined in build/terraform/aws/lambda/main.tf",
                            "IAM policies granting data-plane and KMS access to roles in var.access",
                            "Secrets Manager access policy (build/terraform/aws/secret/main.tf)"
                        ],
                        "related_data": [
                            "Temporary AWS credentials issued to Lambda roles",
                            "Longer-lived credentials or tokens in CI/CD or admin contexts",
                            "Secrets (API keys, tokens) stored in Secrets Manager and environment variables"
                        ],
                        "notes": "This parallels APT groups using compromised global admin/service accounts in M365/Azure to perform malicious but ‘legitimate-looking’ operations."
                    },
                    {
                        "step_id": 2,
                        "description": "Inspect existing Substation configs (via compromised repos or S3/GCS/HTTP/AppConfig sources) to identify which pipelines handle sensitive data (logs, payments, PII) and what sinks and observability transforms they use, noting which IAM permissions and secrets are already available.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG location resolution and internal/file.Get",
                            "AppConfig configuration profiles",
                            "Transform configs for send_aws_*, send_gcp_storage, send_http_post, enrich_http_*",
                            "utility_secret transform and ${SECRET:ID} interpolation"
                        ],
                        "related_data": [
                            "Existing sink ARNs (S3, Kinesis, SQS, SNS, EventBridge, Lambda, GCS buckets)",
                            "Configured HTTP endpoints and headers/bodies used for enrich/send transforms",
                            "Logical secret IDs mapping to Secrets Manager ARNs or environment variables"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Modify targeted pipelines to add secondary, stealthy sinks—such as an extra send_http_post, send_aws_s3, send_aws_kinesis_data_stream, or send_gcp_storage transform—pointing to attacker-controlled or lightly monitored destinations, while keeping all existing sinks and metric transforms intact so dashboards and alerts continue to look normal.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "Transform types: send_http_post, send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_lambda, send_gcp_storage",
                            "Jsonnet/JSON pipeline configuration defining additional sink transforms",
                            "utility_secret transform and ${SECRET:ID} interpolation in sink configuration"
                        ],
                        "related_data": [
                            "New sink resource identifiers (cross-account S3 buckets, Kinesis streams, GCS buckets, HTTP endpoints)",
                            "Secrets or tokens used to authenticate to those sinks",
                            "Message payloads (crown-jewel data) now copied to additional destinations"
                        ],
                        "notes": "Because all sends use the same valid Substation IAM roles or derived cross-account roles, CloudTrail/CloudWatch will attribute activity to legitimate service identities."
                    },
                    {
                        "step_id": 4,
                        "description": "Leverage existing IAM roles and optional STS AssumeRoleARN configurations in internal/config.NewAWS so that the additional sinks can write into external or cross-account resources (for example, an S3 bucket or Kinesis stream in an attacker-controlled AWS account) using only permissions that appear normal for the Substation roles.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "internal/config (NewAWS)",
                            "AWS Secrets Manager secrets"
                        ],
                        "related_interfaces": [
                            "internal/config.NewAWS AssumeRoleARN support in sink transforms",
                            "IAM policies for roles in var.access that allow cross-account or broad data-plane access",
                            "Secrets Manager secrets containing ARNs and credentials for external resources"
                        ],
                        "related_data": [
                            "AssumeRoleARN values used by NewAWS clients",
                            "External account ARNs and resource identifiers used as sinks",
                            "STS-issued temporary credentials used under attacker-selected roles"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 5,
                        "description": "Deploy the modified configs through the same channels legitimate operators use (Git→CI→Terraform, S3/AppConfig updates, or CLI-managed configs) so that all changes come from expected pipelines and are associated with valid Substation accounts, minimizing anomaly signals in change management tooling.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS AppConfig application & environments"
                        ],
                        "related_interfaces": [
                            "CI/CD or operator workflows that call substation build/test/vet",
                            "AppConfig configuration deployment mechanisms",
                            "Config storage buckets or HTTP endpoints referenced by SUBSTATION_CONFIG"
                        ],
                        "related_data": [
                            "Version history of configuration artifacts",
                            "AppConfig configuration version metadata"
                        ],
                        "notes": "This follows real campaigns where adversaries stage changes through existing admin tools to blend into normal operations."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms",
                    "Secrets retrieval and interpolation",
                    "Configuration management and validation CLI",
                    "internal/config (AWS/GCP client helpers)",
                    "AWS Secrets Manager secrets",
                    "Terraform IAM access policies for Kinesis streams and autoscaling"
                ],
                "interfaces_used": [
                    "Jsonnet/JSON pipeline configs defining transform sequences",
                    "Transform types: send_http_post, send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_lambda, send_gcp_storage",
                    "Transform types: enrich_http_get, enrich_http_post for enrichment-based exfil paths",
                    "utility_secret transform and ${SECRET:ID} interpolation in URLs, headers, ARNs",
                    "internal/config.NewAWS AssumeRoleARN support",
                    "SUBSTATION_CONFIG and AppConfig-based configuration loading"
                ],
                "data_accessed": [
                    "Pipeline configuration files and hosted configs for sensitive data flows",
                    "Crown-jewel data carried in Substation messages (security logs, transactions, PII) before they are sent to sinks",
                    "AWS and GCP resource identifiers for sinks (buckets, streams, queues, topics, event buses, Lambdas)",
                    "Secrets used for authenticating to external APIs and cross-account AWS resources"
                ],
                "preconditions_required": [
                    "Attacker controls or can impersonate valid Substation-related cloud accounts (Lambda roles, roles in var.access, CI/CD or AppConfig administrators).",
                    "Those accounts already have data-plane access to the targeted sinks or to cross-account roles that can reach attacker-controlled sinks.",
                    "Substation is trusted to handle sensitive data flows whose exfiltration or duplication would be valuable to the attacker."
                ],
                "constraints_encountered": [
                    "Changing or adding sinks may be visible in configuration reviews or change management systems if defenders scrutinize sink ARNs and HTTP endpoints.",
                    "Additional cross-account or external traffic patterns could be detected by network or CloudTrail analytics if those are in place.",
                    "If IAM policies are tightly scoped (for example, to specific ARNs with no cross-account AssumeRole), it may be difficult to direct data to attacker-controlled destinations without further privilege escalation."
                ],
                "evasion_considerations": [
                    "Choose sink names and ARNs that look consistent with existing naming conventions (e.g., another analytics or archival bucket) to reduce suspicion.",
                    "Throttle or sample data sent to secondary sinks so outbound traffic volumes and costs remain similar to baseline.",
                    "Keep original sinks and metrics untouched so monitoring dashboards and alert counts remain stable while data quietly flows to additional locations."
                ],
                "comments": "This vector focuses on using valid Substation cloud accounts and permissions to perform malicious configuration changes and data duplication in a way that blends into expected operational behavior, mirroring how APT groups use compromised cloud admin accounts to remain stealthy.",
                "evasion_achieved": "Malicious data routing and duplication occur entirely under existing, legitimate Substation cloud identities, making it difficult for defenders to distinguish attacker activity from normal pipeline operations."
            },
            {
                "can_achieve": true,
                "technique_name": "Impair Defenses",
                "technique_stix_id": "attack-pattern--3d333250-30e4-4a82-9edc-756c68afc529",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Discover the public API Gateway endpoints fronting Substation Lambdas and Kinesis streams, noting that Terraform configures their POST methods with authorization = NONE and no resource policies, making them internet-reachable by default.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "AWS Lambda Substation event processors",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "build/terraform/aws/api_gateway/lambda/main.tf (Lambda proxy API with AWS_PROXY integration)",
                            "build/terraform/aws/api_gateway/kinesis_data_stream/main.tf (Kinesis PutRecord API)",
                            "API Gateway stages and invoke URLs exposed to external clients"
                        ],
                        "related_data": [
                            "API Gateway REST API IDs, stages, and invoke URLs",
                            "Mapping of methods to Lambda or Kinesis targets"
                        ],
                        "notes": "These endpoints provide an ideal noise-generation surface similar to how attackers abuse exposed services to flood SIEM pipelines."
                    },
                    {
                        "step_id": 2,
                        "description": "Program high-volume, mostly benign request traffic against these public endpoints (for example, large JSON payloads that still parse correctly) so that each request generates Lambda invocations, Kinesis records, and CloudWatch Logs events that are subsequently forwarded to centralized logging via the CloudWatch Logs destination and subscription filters.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "AWS Lambda Substation event processors",
                            "CloudWatch Logs groups and embedded metrics",
                            "CloudWatch Logs subscription routing",
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "API Gateway POST / methods with authorization = NONE",
                            "Lambda handler AWS_API_GATEWAY for Substation",
                            "CloudWatch Logs subscription filters feeding central Kinesis/Firehose"
                        ],
                        "related_data": [
                            "Lambda invocation logs and X-Ray traces per request",
                            "Kinesis records produced either by API Gateway→Kinesis or Lambda sinks",
                            "Central log stream contents in the destination Kinesis or Firehose"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "If the attacker has access to roles in var.access with Kinesis permissions, directly inject additional log-like records into the central Kinesis destination using kinesis:PutRecord/PutRecords, crafting them to resemble ordinary application logs and further inflating log volume.",
                        "related_capabilities": [
                            "Kinesis Data Streams for high-throughput ingestion",
                            "Terraform IAM access policies for Kinesis streams and autoscaling"
                        ],
                        "related_interfaces": [
                            "Kinesis API: PutRecord, PutRecords on the central stream",
                            "IAM roles in var.access that grant these actions"
                        ],
                        "related_data": [
                            "Centralized Kinesis stream contents used by downstream log consumers",
                            "Injected synthetic log records"
                        ],
                        "notes": "This is conceptually similar to attackers flooding log aggregation systems with junk events to obscure real indicators."
                    },
                    {
                        "step_id": 4,
                        "description": "Time the high-volume noise so it coincides with or slightly precedes more sensitive malicious actions (such as exfiltration via reconfigured sinks) so that SOC analysts, dashboards, and anomaly detectors are overwhelmed with non-malicious events and less able to spot subtle patterns.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs groups and embedded metrics",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "API Gateway client workloads generating bursts of requests",
                            "Central log analytics or SIEM tools consuming from Kinesis/Firehose (downstream of this repo)"
                        ],
                        "related_data": [
                            "Time-correlated spikes in log volume vs. malicious actions",
                            "Monitoring dashboards and alerts built over these log streams"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Public HTTP APIs via API Gateway (direct to Kinesis)",
                    "AWS Lambda Substation event processors",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "CloudWatch Logs groups and embedded metrics",
                    "CloudWatch Logs subscription routing",
                    "CloudWatch Logs destinations for centralized forwarding",
                    "Terraform IAM access policies for Kinesis streams and autoscaling"
                ],
                "interfaces_used": [
                    "API Gateway REST API POST / methods with authorization = NONE (Lambda proxy and Kinesis PutRecord)",
                    "Lambda AWS_API_GATEWAY handler (cmd/aws/lambda/substation/api_gateway.go)",
                    "Kinesis PutRecord/PutRecords APIs on streams defined in build/terraform/aws/kinesis_data_stream/main.tf",
                    "CloudWatch Logs subscription filters and destination configuration"
                ],
                "data_accessed": [
                    "CloudWatch Logs events and metrics generated by high-volume API traffic",
                    "Central Kinesis stream records carrying aggregated log events",
                    "Any downstream SIEM or analytics outputs (outside the repo) built on those logs"
                ],
                "preconditions_required": [
                    "API Gateway endpoints remain unauthenticated or weakly protected as defined (authorization = NONE, no restrictive resource policies).",
                    "Central logging is configured to forward these API- and Lambda-generated logs into shared Kinesis/Firehose destinations.",
                    "Attacker can generate sufficiently high request volume from one or more IPs or clients without being blocked by external rate-limiting, WAFs, or network controls."
                ],
                "constraints_encountered": [
                    "AWS service limits and throttling may restrict maximum sustained request and log rates without further privilege escalation.",
                    "High volumes of requests may increase cost and potentially trigger availability or cost-related alerts even if security alerts are drowned out.",
                    "Defenders who alert on anomalous traffic volume or source IP behavior at API Gateway or Kinesis may still detect the flood itself as malicious."
                ],
                "evasion_considerations": [
                    "Use distributed sources (many client IPs/accounts) to keep per-source request rates below typical rate-limit thresholds.",
                    "Craft payloads that resemble legitimate application traffic patterns (schemas, sizes) to avoid content-based anomaly detection.",
                    "Ramp noise up gradually and maintain it over time so operators normalize to higher baseline log volumes before sensitive actions occur."
                ],
                "comments": "Rather than disabling logging outright, this vector impairs defenses by overwhelming centralized logging and analytics with attacker-generated noise using Substation’s own public ingestion interfaces and logging pipeline.",
                "evasion_achieved": "Security-relevant events are buried in large volumes of benign-looking log data, making it harder for analysts and automated systems to detect anomalous behavior in Substation workloads."
            }
        ],
        "summary": "Substation’s defense evasion surface is dominated by its highly configurable, transform-driven design and its tightly integrated AWS observability stack. An attacker who compromises configuration sources, IAM roles, or the autoscaling/logging infrastructure can: (1) disable or starve Substation’s own metric transforms so CloudWatch loses application-level visibility; (2) modify or sever CloudWatch Logs destinations and subscription filters so that central SIEMs never receive critical Lambda and stream logs; (3) abuse the Kinesis autoscaling controller and its CloudWatch permissions to under-provision and de-alarm logging streams, causing silent telemetry loss under load; (4) use valid Substation cloud accounts and secrets to introduce secondary sinks that quietly copy crown-jewel data to alternate locations while normal sinks, metrics, and logs remain intact; and (5) flood public API Gateway endpoints and central Kinesis destinations with benign traffic to drown out malicious indicators. All of these vectors are achievable using documented capabilities and interfaces, assuming the attacker attains the corresponding configuration or IAM control, and they center on impairing the monitoring and logging infrastructure that defenders are likely to depend on for detecting misuse of Substation."
    },
    "persistence": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Event Triggered Execution",
                "technique_stix_id": "attack-pattern--b6301b64-ef57-4cce-bb0b-77026f14a8db",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Discover how the target Substation deployment loads its pipeline configuration by inspecting environment variables (SUBSTATION_CONFIG, SUBSTATION_LAMBDA_HANDLER / SUBSTATION_FUNCTION_HANDLER) and any IaC or deployment metadata that reference them, as well as AppConfig usage if present.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Core Substation transformation engine",
                            "Substation Lambda functions (container-image Lambdas)",
                            "AppConfig \u001a Lambda configuration consumption"
                        ],
                        "related_interfaces": [
                            "Environment variable SUBSTATION_CONFIG used by AWS Lambda Substation handlers and the GCP Function to locate configuration via internal/file.Get from local files, HTTP(S), S3, or GCS.",
                            "Environment variables SUBSTATION_LAMBDA_HANDLER and SUBSTATION_FUNCTION_HANDLER that permanently select which handler mode (e.g., AWS_API_GATEWAY, AWS_DYNAMODB_STREAM, AWS_S3, AWS_SQS, GCP_STORAGE) is invoked for each function.",
                            "internal/file.Get HTTP(S), S3, and GCS URLs used as configuration or data sources for SUBSTATION_CONFIG and CLI operations."
                        ],
                        "related_data": [
                            "Jsonnet and JSON Substation configuration files (substation.Config and config.Config lists of transforms and settings) that encode all pipeline logic, sinks, and external integrations.",
                            "Environment variables controlling Substation behavior and triggers, including SUBSTATION_CONFIG, SUBSTATION_LAMBDA_HANDLER, SUBSTATION_FUNCTION_HANDLER."
                        ],
                        "notes": "This mirrors how offensive tools like Pacu first enumerate buckets and notification configurations before wiring a malicious Lambda trigger for CloudFormation templates."
                    },
                    {
                        "step_id": 2,
                        "description": "Gain write control over the SUBSTATION_CONFIG source, e.g., by obtaining s3:PutObject on the S3 bucket or GCS bucket hosting the config file, control over an HTTP(S) endpoint used as SUBSTATION_CONFIG, or the ability to update the SUBSTATION_CONFIG environment variable used by the Lambda/Function.",
                        "related_capabilities": [
                            "S3 buckets for Substation data",
                            "GCP Storage and related GCP services",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "S3 objects and GCS objects used both as configuration files (remote SUBSTATION_CONFIG) and as repeatedly processed data sources for S3/GCS-triggered pipelines.",
                            "Lambda in private subnets \u001a external AWS services via NAT/IGW"
                        ],
                        "related_data": [
                            "S3 objects and GCS objects used as configuration files referenced by SUBSTATION_CONFIG.",
                            "Cloud provider metadata or CI/CD variables that define Lambda environment variables."
                        ],
                        "notes": "From the application’s perspective, this is typically done via an over-privileged role in var.access or compromise of the CI/deployment principal that owns the config bucket or Lambda configuration."
                    },
                    {
                        "step_id": 3,
                        "description": "Obtain the current legitimate Substation configuration (via S3/GCS/HTTP download or local file access) and analyze the existing transforms, sinks, and KV/secret usage to understand expected behavior and acceptable config shapes.",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Jsonnet and JSON configuration files built/tested by the 'substation build/fmt/test/vet' CLI and consumed by substation.New at runtime.",
                            "cmd/substation build, test, and vet commands"
                        ],
                        "related_data": [
                            "Jsonnet and JSON Substation configuration files (substation.Config and config.Config)."
                        ],
                        "notes": "Using 'substation test' and 'substation vet' locally against the stolen config helps ensure any malicious additions still pass validation and basic pipeline checks."
                    },
                    {
                        "step_id": 4,
                        "description": "Craft a malicious Substation config that preserves normal behavior but adds stealthy exfiltration or backdoor transforms, such as appending a send_http_post or send_aws_kinesis_data_stream transform that copies selected fields from each message to an attacker-controlled endpoint or cross-account stream.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_http_get, enrich_http_post, send_http_post",
                            "Transform types: send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_s3, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage",
                            "Interpolation syntax: ${SECRET:ID} via internal/secrets"
                        ],
                        "related_data": [
                            "Event payloads from API Gateway, Kinesis, Firehose, DynamoDB Streams, S3, SNS, SQS, and GCS that are wrapped into message.Message objects.",
                            "Secrets Manager secret values and environment variables used for HTTP headers or target ARNs.",
                            "Message metadata such as ARNs, object keys, timestamps, and partition keys."
                        ],
                        "notes": "The malicious config can be made to look like normal routing/observability by, for example, sending to an attacker-controlled Kinesis stream in another account or to an HTTP endpoint with a plausible hostname."
                    },
                    {
                        "step_id": 5,
                        "description": "Replace or point SUBSTATION_CONFIG at the malicious configuration file (e.g., overwrite the S3 object, update an HTTP-served config, or adjust the environment variable to reference an attacker-controlled S3/HTTP/GCS location).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "S3 buckets for Substation data",
                            "GCP Storage and related GCP services"
                        ],
                        "related_interfaces": [
                            "Environment variable SUBSTATION_CONFIG used by AWS Lambda Substation handlers and the GCP Function to locate configuration via internal/file.Get from local files, HTTP(S), S3, or GCS.",
                            "internal/file.Get HTTP(S), S3, and GCS URLs used as configuration or data sources for SUBSTATION_CONFIG and CLI operations."
                        ],
                        "related_data": [
                            "Remote configuration objects in S3/GCS or served over HTTP(S)."
                        ],
                        "notes": "Because handlers call getConfig() and internal/file.Get based on SUBSTATION_CONFIG, subsequent cold starts (and in some deployments every invocation) will load the modified pipeline without any code change."
                    },
                    {
                        "step_id": 6,
                        "description": "Allow existing event sources (API Gateway, S3 notifications, Kinesis/DynamoDB Streams, SNS/SQS, GCS events, EventBridge schedules) to continue invoking the Substation Lambda/Function so that every new event transparently executes the malicious pipeline logic.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "EventBridge rule triggering Lambda",
                            "CloudWatch Logs subscription routing",
                            "DynamoDB tables for state and streaming change data",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "SQS queues for buffered processing",
                            "SNS topics for notifications and autoscaling"
                        ],
                        "related_interfaces": [
                            "Public API Gateway REST API POST methods (authorization NONE) that proxy to Substation Lambdas using AWS_PROXY integration.",
                            "Public API Gateway REST API POST methods that directly call Kinesis PutRecord to write HTTP request bodies into Kinesis Data Streams.",
                            "S3 bucket notifications and S3→SNS/SQS fan-out that activate s3Handler/s3SnsHandler/s3SqsHandler.",
                            "GCP Cloud Storage event (CloudEvent) triggers that invoke the Substation Cloud Function.",
                            "EventBridge rules and targets that invoke Substation or autoscale Lambdas on a schedule or when event patterns match."
                        ],
                        "related_data": [
                            "Kinesis records, DynamoDB stream records, S3/GCS objects, SNS/SQS messages, and HTTP request bodies flowing through Substation.",
                            "CloudWatch Logs entries and EMF metrics that may reflect only high-level pipeline errors, not data exfiltration details."
                        ],
                        "notes": "This is analogous to Pacu’s use of S3 bucket notifications or IAM events to repeatedly trigger a malicious Lambda, except here the Lambda is legitimate and only its configuration has been subverted."
                    },
                    {
                        "step_id": 7,
                        "description": "Periodically update the remote configuration to evolve exfiltration logic or add new sinks while keeping existing IDs and structure similar to the legitimate config so that superficial reviews and automated tests still pass.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "substation build, test, and vet commands",
                            "Remote SUBSTATION_CONFIG S3/GCS/HTTP endpoint"
                        ],
                        "related_data": [
                            "Versioned or historical configuration files in source control or buckets.",
                            "Any additional secrets or KV-driven feature flags referenced by the evolving config."
                        ],
                        "notes": "By keeping transforms syntactically valid and error-free, the attacker avoids noisy Lambda failures that would alert operators."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Core Substation transformation engine",
                    "Local ingestion and transformation CLI",
                    "HTTP enrichment and sending transforms",
                    "AWS and GCP sink transforms",
                    "Configuration management and validation CLI",
                    "S3 buckets for Substation data",
                    "GCP Storage and related GCP services",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Public HTTP APIs via API Gateway (direct to Kinesis)",
                    "EventBridge rule triggering Lambda",
                    "CloudWatch Logs subscription routing",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "SQS queues for buffered processing",
                    "SNS topics for notifications and autoscaling"
                ],
                "interfaces_used": [
                    "Environment variable SUBSTATION_CONFIG used by AWS Lambda Substation handlers and the GCP Function to locate configuration via internal/file.Get from local files, HTTP(S), S3, or GCS.",
                    "Environment variables SUBSTATION_LAMBDA_HANDLER and SUBSTATION_FUNCTION_HANDLER that permanently select which handler mode (e.g., AWS_API_GATEWAY, AWS_DYNAMODB_STREAM, AWS_S3, AWS_SQS, GCP_STORAGE) is invoked for each function.",
                    "internal/file.Get HTTP(S), S3, and GCS URLs used as configuration or data sources for SUBSTATION_CONFIG and CLI operations.",
                    "Transform types: enrich_http_get, enrich_http_post, send_http_post",
                    "Transform types: send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_s3, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage",
                    "Jsonnet and JSON configuration files built/tested by the 'substation build/fmt/test/vet' CLI and consumed by substation.New at runtime.",
                    "Public API Gateway REST API POST methods (authorization NONE) that proxy to Substation Lambdas using AWS_PROXY integration.",
                    "Public API Gateway REST API POST methods that directly call Kinesis PutRecord to write HTTP request bodies into Kinesis Data Streams.",
                    "S3 bucket notifications and S3→SNS/SQS-fanout that activate s3Handler/s3SnsHandler/s3SqsHandler in the AWS Lambda Substation binary whenever objects are created or updated.",
                    "GCP Cloud Storage event (CloudEvent) triggers that invoke the Substation Cloud Function on object changes in monitored buckets.",
                    "EventBridge rules and targets that invoke Substation or autoscale Lambdas on a schedule or when event patterns match."
                ],
                "data_accessed": [
                    "Jsonnet and JSON Substation configuration files (substation.Config and config.Config).",
                    "Event payloads from API Gateway, generic Lambda invocations, Kinesis, Firehose, DynamoDB Streams, S3, SNS, and SQS.",
                    "CloudStorageEvent payloads and GCS object bytes.",
                    "Secrets Manager secret values and environment variables used by internal/secrets and utility_secret.",
                    "DynamoDB items written/read by KV transforms, which may carry enrichment state or feature flags.",
                    "S3/GCS objects processed and any derived message metadata (object keys, bucket names, timestamps, etc.)."
                ],
                "preconditions_required": [
                    "The deployment must use SUBSTATION_CONFIG to point at a remote configuration file (S3, GCS, or HTTP) rather than only a baked-in local file.",
                    "The attacker must gain write access to the remote configuration source (e.g., s3:PutObject on the config bucket, write access to the GCS bucket, or control of the HTTP(S) endpoint) or the ability to change the SUBSTATION_CONFIG environment variable for the Lambda/Function.",
                    "Operators must not enforce strong integrity controls over configs (e.g., code-signing, checksums, or tight approvals that would detect unexpected transform changes).",
                    "Network egress from the Lambda/Function’s VPC configuration must permit reaching any attacker-controlled HTTP endpoints or cross-account AWS resources used as exfiltration sinks."
                ],
                "constraints_encountered": [
                    "If SUBSTATION_CONFIG points to a local file baked into the container image and the Lambda has no network access to alternative config sources, the attacker cannot redirect configuration without also compromising the image or deployment pipeline.",
                    "Configuration may be validated via the 'validate' Lambda, 'substation test', or 'substation vet'; while these tools mainly check structure, an organization could add semantic checks that detect unexpected exfiltration transforms.",
                    "Least-privilege IAM on config buckets or AppConfig profiles can prevent Substation execution roles and most application principals from modifying configuration sources directly.",
                    "KMS-encrypted buckets and objects require the attacker to either operate as a principal with kms:Decrypt/GenerateDataKey on the relevant CMK or rely on the Lambda’s existing permissions for reads/writes."
                ],
                "evasion_considerations": [
                    "Preserve all existing sinks and metrics transforms so that data continues to flow to expected destinations and monitoring dashboards remain consistent.",
                    "Use transform names, IDs, and settings that match internal naming conventions so the malicious transforms look like routine routing or observability additions.",
                    "Favor AWS-native exfiltration paths such as writing to a cross-account Kinesis stream or S3 bucket instead of obvious external HTTP domains, to blend in with normal send_* transform activity.",
                    "Throttle exfiltration (e.g., only copy a sample of records or only specific tenants) to avoid noticeable cost or throughput changes.",
                    "Ensure the malicious config compiles and passes 'substation test' and 'substation vet' to avoid operational errors that might prompt deeper review."
                ],
                "comments": "This is the most central, Substation-specific persistence vector: compromise of configuration plus reliance on long-lived event triggers yields durable, low-noise control of how all future data is processed and routed.",
                "persistence_mechanism": "A malicious Substation configuration hosted at a stable SUBSTATION_CONFIG location (S3/GCS/HTTP) that the Lambda/Function reloads on cold starts (or each invocation), coupled with existing S3/Kinesis/API Gateway/EventBridge triggers that repeatedly execute the attacker-controlled pipeline."
            },
            {
                "can_achieve": true,
                "technique_name": "Event Triggered Execution",
                "technique_stix_id": "attack-pattern--b6301b64-ef57-4cce-bb0b-77026f14a8db",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify whether Substation-related Lambdas consume configuration from AWS AppConfig by reviewing Terraform (appconfig/main.tf), Lambda environment variables, and any internal configuration code paths that call appconfig:GetConfiguration*.",
                        "related_capabilities": [
                            "AWS AppConfig application & environments",
                            "AWS Lambda Substation event processors",
                            "AppConfig \u001a Lambda configuration consumption"
                        ],
                        "related_interfaces": [
                            "AppConfig application & environments that manage hosted configuration and optionally invoke a validator Lambda.",
                            "AppConfig configuration profiles and environments that Lambdas access via appconfig:GetConfiguration* in the \"AppConfig \u001a Lambda configuration consumption\" data flow.",
                            "Lambda resource-based policies (aws_lambda_permission resources) that explicitly trust appconfig.amazonaws.com with function invocation rights."
                        ],
                        "related_data": [
                            "AppConfig hosted configuration profiles and environments that store configuration retrieved by Lambdas at runtime.",
                            "Lambda environment variables or configuration parameters that reference AppConfig application IDs, environment IDs, and configuration profile names."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Compromise or obtain access to an AWS principal with administrative rights over the relevant AppConfig application and environment (for example, the deployment role used in CI/CD or a cloud administrator), allowing read and update of configuration profiles and deployment of new versions.",
                        "related_capabilities": [
                            "AWS AppConfig application & environments"
                        ],
                        "related_interfaces": [
                            "AppConfig APIs for retrieving and updating configuration profiles and starting deployments.",
                            "IAM roles or users with appconfig:* permissions over the Substation AppConfig application."
                        ],
                        "related_data": [
                            "Existing AppConfig configuration documents controlling Substation behavior (which may include or reference Substation pipeline configs or feature flags)."
                        ],
                        "notes": "This step parallels APT-style operations where a compromised cloud admin uses legitimate consoles or APIs to plant persistent backdoors in identity or configuration services."
                    },
                    {
                        "step_id": 3,
                        "description": "Download the current AppConfig configuration used by the Substation Lambda(s) and determine how it is consumed (e.g., whether it directly encodes Substation transforms, stores a SUBSTATION_CONFIG URI, or exposes feature flags and routing rules that the Substation pipeline reads at runtime).",
                        "related_capabilities": [
                            "AppConfig \u001a Lambda configuration consumption",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "AppConfig GetConfiguration* APIs invoked by the Lambda to retrieve configuration at runtime.",
                            "Jsonnet/JSON config parsing in substation.New if AppConfig data is used to construct substation.Config or config.Config."
                        ],
                        "related_data": [
                            "AppConfig configuration JSON (such as pipeline definitions, routing flags, or URIs to external configs).",
                            "Substation configuration structures constructed from AppConfig responses."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "Create and upload a modified AppConfig configuration version that preserves expected keys and structure but embeds malicious behavior, such as pointing SUBSTATION_CONFIG at an attacker-controlled S3/HTTP location or including exfiltration transforms and routing flags interpreted by the Substation pipeline.",
                        "related_capabilities": [
                            "AWS AppConfig application & environments",
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "AppConfig APIs for creating new configuration versions or updating configuration profiles.",
                            "AppConfig deployment mechanisms that roll out new configuration to Lambda consumers.",
                            "Transform types in the embedded or referenced Substation config, such as send_http_post and send_aws_kinesis_data_stream."
                        ],
                        "related_data": [
                            "New AppConfig configuration version that encodes the attacker’s modified pipeline or configuration references.",
                            "Remote configuration objects (if AppConfig is used to point at SUBSTATION_CONFIG URIs)."
                        ],
                        "notes": "The modified AppConfig data can either directly encode a full Substation pipeline or more subtly adjust feature flags and URIs that the pipeline uses to control sinks and routing."
                    },
                    {
                        "step_id": 5,
                        "description": "Deploy the malicious AppConfig configuration to the production environment, satisfying or bypassing any validator Lambda checks (for example, by preserving schema while only changing endpoints, ARNs, or feature flag values).",
                        "related_capabilities": [
                            "AWS AppConfig application & environments"
                        ],
                        "related_interfaces": [
                            "AppConfig deployment APIs that push configuration to environments and optionally invoke a validator Lambda.",
                            "aws_lambda_permission.allow_appconfig that lets appconfig.amazonaws.com invoke the validator Lambda."
                        ],
                        "related_data": [
                            "AppConfig deployment metadata (version numbers, deployment history) that now reference the malicious configuration."
                        ],
                        "notes": "If a validator Lambda is in place, the attacker ensures the new configuration passes validation, for example by only changing sink endpoints or adding ostensibly harmless dimensions."
                    },
                    {
                        "step_id": 6,
                        "description": "Rely on the fact that Substation Lambdas periodically or per-invocation call appconfig:GetConfiguration*; as new events arrive from API Gateway, Kinesis, S3, etc., the Lambdas continue to execute using the attacker-controlled configuration, resulting in persistent exfiltration or modified routing.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS AppConfig application & environments",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "S3 buckets for Substation data",
                            "DynamoDB tables for state and streaming change data"
                        ],
                        "related_interfaces": [
                            "AppConfig \u001a Lambda configuration consumption data flow.",
                            "EventBridge rule triggering Lambda",
                            "HTTP \u001a API Gateway \u001a Lambda",
                            "S3/SNS/SQS/Kinesis/DynamoDB Streams event sources configured for the Lambda."
                        ],
                        "related_data": [
                            "All data flowing through the Substation Lambda (events from API Gateway, Kinesis, S3, DynamoDB Streams, SNS/SQS).",
                            "AppConfig configuration versions subsequently fetched by the Lambda."
                        ],
                        "notes": "This is conceptually similar to backdooring a cloud identity provider or automation platform used by many assets: once AppConfig is tainted, every Lambda that trusts it inherits the malicious behavior."
                    }
                ],
                "capabilities_used": [
                    "AWS AppConfig application & environments",
                    "AppConfig \u001a Lambda configuration consumption",
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "HTTP enrichment and sending transforms",
                    "AWS and GCP sink transforms",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "S3 buckets for Substation data",
                    "DynamoDB tables for state and streaming change data"
                ],
                "interfaces_used": [
                    "AppConfig application & environments that manage hosted configuration and optionally invoke a validator Lambda.",
                    "AppConfig configuration profiles and environments that Lambdas access via appconfig:GetConfiguration* in the \"AppConfig \u001a Lambda configuration consumption\" data flow.",
                    "aws_lambda_permission resources that trust appconfig.amazonaws.com with function invocation rights.",
                    "HTTP \u001a API Gateway \u001a Lambda",
                    "EventBridge \u001a Lambda",
                    "S3/SNS/SQS/Kinesis/DynamoDB event source mappings to the Substation Lambda."
                ],
                "data_accessed": [
                    "AppConfig hosted configuration profiles and environments used by Substation Lambdas.",
                    "Substation configuration structures or feature flags derived from AppConfig data.",
                    "All message payloads and metadata processed by the affected Substation Lambda (API Gateway bodies, stream records, S3 object contents, DynamoDB change events, SNS/SQS messages)."
                ],
                "preconditions_required": [
                    "Substation Lambdas must be configured to fetch behavior-controlling configuration from AppConfig (directly or indirectly).",
                    "The attacker must compromise an AWS principal with permissions to read, modify, and deploy AppConfig configuration for the relevant application and environment.",
                    "Any validator Lambda or CI/CD checks around AppConfig deployments must accept the modified configuration (for example, they must not enforce strict allow-lists of sink endpoints or ARNs)."
                ],
                "constraints_encountered": [
                    "AppConfig deployments may be tightly governed with approval workflows and change management, increasing the chance that a malicious configuration is noticed.",
                    "If the Lambda only uses AppConfig for non-critical settings (e.g., thresholds) and not for routing or sink configuration, the attacker’s ability to induce exfiltration purely via AppConfig may be limited.",
                    "The validator Lambda may enforce strict schemas or even semantic checks, requiring the malicious configuration to be carefully crafted to avoid rejection."
                ],
                "evasion_considerations": [
                    "Change only values (endpoints, ARNs, feature flags) while preserving keys and overall structure so that diffs look like routine configuration tuning.",
                    "Stage changes gradually and monitor for alarms or operator reactions before enabling full exfiltration behavior.",
                    "If a validator Lambda logs details of configuration changes, keep modifications minimal and avoid adding obviously suspicious domains or account IDs."
                ],
                "comments": "This vector leverages AppConfig as a centralized, persistent control plane. Once compromised, every Lambda that trusts AppConfig inherits persistent, attacker-chosen behavior, driven by existing event triggers.",
                "persistence_mechanism": "A malicious configuration version deployed in AWS AppConfig and continuously fetched by Substation Lambdas, ensuring that all future event-triggered executions use attacker-controlled routing and sinks without modifying function code."
            },
            {
                "can_achieve": true,
                "technique_name": "Event Triggered Execution",
                "technique_stix_id": "attack-pattern--b6301b64-ef57-4cce-bb0b-77026f14a8db",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Enumerate Substation configs to find use of KV-backed transforms (enrich_kv_store_item_get, enrich_kv_store_item_set, enrich_kv_store_set_add, meta_kv_store_lock), paying particular attention to keys and prefixes that influence routing, deduplication, or sink selection.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_kv_store_item_get, enrich_kv_store_item_set, enrich_kv_store_set_add, meta_kv_store_lock",
                            "internal/kv.Get and KV store configuration in transform Settings"
                        ],
                        "related_data": [
                            "Transform configurations specifying KV prefixes, key source fields, TTL fields/offsets, and target fields.",
                            "Jsonnet/JSON pipeline configs where KV transforms appear."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "From the KV transform configuration, derive the underlying backend (typically a DynamoDB table) and the exact key schema (prefix + message field) that the pipeline uses to read or write control values, such as routing flags or dynamic endpoint URLs.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "DynamoDB tables for state and streaming change data"
                        ],
                        "related_interfaces": [
                            "internal/kv/aws_dynamodb backend selected via internal/kv.Get.",
                            "DynamoDB APIs (GetItem, PutItem, UpdateItem, BatchWriteItem) used by KV transforms."
                        ],
                        "related_data": [
                            "DynamoDB table items that store KV state for enrichment, set membership, and locks.",
                            "Key prefixes and TTL attributes used by the KV transforms."
                        ],
                        "notes": "The attacker may be able to infer key patterns from logs, metrics, or partially-controlled message fields as well as from configs."
                    },
                    {
                        "step_id": 3,
                        "description": "Using an IAM principal with write access to the KV backend (for example, a role in var.access or a compromised downstream processor), create or modify specific KV entries under the prefixes used by the target pipeline to encode attacker-controlled control data such as debug flags, routing decisions, or dynamic sink endpoints.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "DynamoDB tables for state and streaming change data"
                        ],
                        "related_interfaces": [
                            "substation-dynamodb-* IAM policy granting dynamodb:PutItem/UpdateItem/BatchWriteItem to roles in var.access.",
                            "DynamoDB data-plane APIs for writing KV items."
                        ],
                        "related_data": [
                            "DynamoDB items that represent KV keys used by the pipeline.",
                            "Control values such as Booleans, endpoint URLs, or ARNs stored in DynamoDB attributes."
                        ],
                        "notes": "Because KV keys may be prefixed for multi-tenancy, the attacker needs to match the correct prefix to affect the intended logical tenant or pipeline behavior."
                    },
                    {
                        "step_id": 4,
                        "description": "Set long-lived or effectively non-expiring TTL values on these KV entries (or omit TTL attributes if the transforms and table configuration allow) so that the attacker-controlled control data persists across Lambda/Function restarts and over long periods.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "DynamoDB tables for state and streaming change data"
                        ],
                        "related_interfaces": [
                            "enrich_kv_store_item_set and enrich_kv_store_set_add TTL calculations based on message fields or configured offsets.",
                            "DynamoDB table TTL configuration."
                        ],
                        "related_data": [
                            "TTL attributes on KV items that govern how long control values remain active.",
                            "Any KV items involved in meta_kv_store_lock semantics that might gate processing."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 5,
                        "description": "Leverage the existing event-driven execution of the pipeline (Kinesis, S3, DynamoDB Streams, API Gateway, etc.) so that each new event causes Substation to read from the KV store via enrich_kv_store_item_get and apply the attacker-crafted control values when evaluating conditions, routing messages, or building URLs/headers for HTTP and AWS/GCP sinks.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "KV store integration and distributed locking",
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "S3 buckets for Substation data",
                            "DynamoDB tables for state and streaming change data"
                        ],
                        "related_interfaces": [
                            "General message pipeline execution data flow (Substation.Transform over message batches plus a control message).",
                            "Transform types: enrich_kv_store_item_get feeding values into fields consumed by send_http_post or AWS/GCP sink transforms.",
                            "Event-driven entry points: API Gateway, Kinesis, S3, DynamoDB Streams, SNS, SQS."
                        ],
                        "related_data": [
                            "All message payloads processed by the pipeline whose behavior is altered due to KV-derived control values.",
                            "KV-derived fields added to messages and subsequently used in HTTP headers, URLs, or sink ARNs."
                        ],
                        "notes": "This is similar in spirit to backdooring a configuration database: the pipeline appears unchanged, but its runtime behavior is driven by attacker-controlled data in a stateful backend."
                    },
                    {
                        "step_id": 6,
                        "description": "Optionally, manipulate meta_kv_store_lock keys to influence concurrency or idempotency semantics (for example, forcing or preventing execution of certain child transforms) in ways that preserve the attacker’s exfiltration behavior while avoiding duplicate processing or noisy errors.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Transform type: meta_kv_store_lock and its use of Locker backends.",
                            "DynamoDB-based Locker implementation in internal/kv."
                        ],
                        "related_data": [
                            "Lock keys and TTLs stored in the KV backend that gate execution of nested transforms."
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "KV store integration and distributed locking",
                    "DynamoDB tables for state and streaming change data",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "HTTP enrichment and sending transforms",
                    "AWS and GCP sink transforms",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "S3 buckets for Substation data"
                ],
                "interfaces_used": [
                    "Transform types: enrich_kv_store_item_get, enrich_kv_store_item_set, enrich_kv_store_set_add, meta_kv_store_lock",
                    "internal/kv/kv.go DynamoDB Storer and Locker backends",
                    "DynamoDB table APIs for GetItem, PutItem, UpdateItem, BatchWriteItem",
                    "General message pipeline execution that applies transforms sequentially per message"
                ],
                "data_accessed": [
                    "DynamoDB KV items used by Substation for enrichment, set maintenance, and locks.",
                    "TTL metadata and key prefixes that determine the lifetime and scope of KV-driven behavior.",
                    "Message fields populated from KV that may include dynamic endpoints, flags, or attributes later consumed by downstream transforms."
                ],
                "preconditions_required": [
                    "Target pipelines must use KV-backed transforms for dynamic behavior such as routing, deduplication, or endpoint selection rather than purely static configuration.",
                    "The attacker must possess or obtain an IAM principal with write access to the DynamoDB table(s) backing the KV transforms (e.g., a role in var.access or a downstream processor role with dynamodb:PutItem/UpdateItem).",
                    "The KV keys and prefixes used by the pipeline must be discoverable (from configs, logs, or controlled messages) so the attacker can craft items that will actually be read."
                ],
                "constraints_encountered": [
                    "Some deployments may use KV only for idempotency or caching rather than routing or configuration, limiting the impact of malicious KV entries to performance characteristics rather than exfiltration.",
                    "Multi-tenant deployments may enforce strict key prefixes per tenant, requiring the attacker to correctly target the prefix associated with the victim tenant.",
                    "TTL cleanup or administrative KV housekeeping scripts could eventually remove attacker-planted keys if not carefully set with long-lived TTLs."
                ],
                "evasion_considerations": [
                    "Use KV keys and attribute shapes that are consistent with existing patterns so entries appear to be routine state rather than manual injections.",
                    "Store exfiltration-related data (such as custom endpoints) in fields that already exist for legitimate use, changing only values, not schema.",
                    "Throttle or scope the effect of KV modifications (for example, to a subset of tenants or records) to limit operational anomalies and avoid drawing attention."
                ],
                "comments": "This vector abuses DynamoDB-backed KV state as a hidden, long-lived configuration channel that operators may not inspect as closely as Jsonnet/JSON configs, enabling persistent behavioral control without touching static configuration files.",
                "persistence_mechanism": "Attacker-controlled DynamoDB KV entries with long-lived TTLs or no TTL that are repeatedly read by KV transforms on every event, steering routing and sink behavior over time even if static Substation configs remain unchanged."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Accounts",
                "technique_stix_id": "attack-pattern--f232fa7a-025c-4d43-abc7-318e81a73d65",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "During initial compromise of a Substation Lambda, downstream processor, or CI job, extract cloud credentials for high-value IAM roles such as the Substation Lambda execution role (substation-lambda-*) or roles listed in var.access that have broad permissions over S3, DynamoDB, Kinesis, SQS, SNS, Secrets Manager, and KMS.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms",
                            "Substation Lambda functions (container-image Lambdas)",
                            "AWS Secrets Manager secrets"
                        ],
                        "related_interfaces": [
                            "AWS SDK default credential chain used by Substation (environment variables, instance/Lambda metadata).",
                            "Lambda execution roles defined in build/terraform/aws/lambda/main.tf.",
                            "IAM roles listed in var.access with access to S3, DynamoDB, Kinesis, SQS, SNS, Secrets, and KMS."
                        ],
                        "related_data": [
                            "AWS access key IDs, secret access keys, and session tokens associated with Substation-related IAM roles.",
                            "Any STS AssumeRole targets that the compromised principal can use."
                        ],
                        "notes": "This aligns with MITRE examples where APT groups reuse stolen cloud credentials (e.g., M365, Azure AD) for long-term access; here the focus is on AWS IAM roles tied to Substation infrastructure."
                    },
                    {
                        "step_id": 2,
                        "description": "Validate the stolen credentials externally (from attacker-controlled infrastructure) by calling AWS STS GetCallerIdentity, enumerating allowed services, and confirming access to key Substation resources (buckets, streams, queues, tables, secrets).",
                        "related_capabilities": [
                            "Lambda \u001a encrypted data stores (S3, DynamoDB, Kinesis, SQS, SNS, Secrets)"
                        ],
                        "related_interfaces": [
                            "AWS STS GetCallerIdentity and IAM policy simulation (if available).",
                            "S3, DynamoDB, Kinesis, SQS, SNS, and Secrets Manager APIs as granted by substation-* access policies."
                        ],
                        "related_data": [
                            "ARNs and resource identifiers for S3 buckets, DynamoDB tables, Kinesis streams, SQS queues, SNS topics, and Secrets used by Substation.",
                            "Policy documents or effective permissions inferred from access attempts."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Use the valid cloud account (stolen role credentials) to directly access Substation-managed data stores over time, such as continuously reading from Kinesis streams, scanning DynamoDB tables, or listing and downloading S3 objects that hold ingested or transformed data.",
                        "related_capabilities": [
                            "Kinesis Data Streams for high-throughput ingestion",
                            "DynamoDB tables for state and streaming change data",
                            "S3 buckets for Substation data",
                            "SQS queues for buffered processing",
                            "SNS topics for notifications and autoscaling",
                            "AWS Secrets Manager secrets"
                        ],
                        "related_interfaces": [
                            "kinesis:ListShards, GetShardIterator, GetRecords using substation-kinesis-* access policies.",
                            "dynamodb:Scan/Query/GetItem using substation-dynamodb-* policies.",
                            "s3:ListBucket and s3:GetObject using substation-s3-* policies.",
                            "sqs:ReceiveMessage and sns:Subscribe/Receive via substation-sqs-* and substation-sns-* policies.",
                            "secretsmanager:GetSecretValue for secrets created by build/terraform/aws/secret/main.tf."
                        ],
                        "related_data": [
                            "All stream records, table items, queue messages, topics, and objects processed or produced by Substation.",
                            "Secrets containing API keys or other configuration used by Substation transforms."
                        ],
                        "notes": "This provides persistent collection capabilities that do not rely on maintaining any foothold inside a running Lambda function."
                    },
                    {
                        "step_id": 4,
                        "description": "Leverage lambda:InvokeFunction and lambda:GetFunctionConfiguration permissions (provided to roles in var.access by the substation-lambda-access-* policy) to repeatedly trigger Substation Lambdas with attacker-chosen payloads or to monitor configuration for defensive changes.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "EventBridge rule triggering Lambda"
                        ],
                        "related_interfaces": [
                            "lambda:InvokeFunction on aws_lambda_function.lambda_function and its versions.",
                            "lambda:GetFunctionConfiguration to read environment variables such as SUBSTATION_CONFIG."
                        ],
                        "related_data": [
                            "Lambda environment variables and configuration (e.g., SUBSTATION_CONFIG URIs, VPC settings).",
                            "Custom payloads sent via InvokeFunction that may be processed by Substation pipelines."
                        ],
                        "notes": "By invoking Lambdas directly, the attacker can test whether their other persistence mechanisms (e.g., malicious configs) remain active and can drive Substation to contact external C2 endpoints when necessary."
                    },
                    {
                        "step_id": 5,
                        "description": "Maintain long-term use of the stolen cloud account by securely storing the credentials, periodically refreshing them via STS AssumeRole (if allowed), and carefully mimicking legitimate usage patterns (service endpoints, regions, and access times) to avoid detection.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Lambda \u001a encrypted data stores (S3, DynamoDB, Kinesis, SQS, SNS, Secrets)",
                            "CloudWatch Logs groups and embedded metrics"
                        ],
                        "related_interfaces": [
                            "STS AssumeRole, if roles in var.access are configured for cross-account or delegated assumption.",
                            "CloudWatch Logs APIs for reading operational logs to tune stealth (if permitted outside this repo’s policies)."
                        ],
                        "related_data": [
                            "STS tokens derived from the original compromised role.",
                            "CloudWatch Logs entries for Substation Lambdas indicating normal workload patterns."
                        ],
                        "notes": "This mirrors real-world campaigns (e.g., APT29 in cloud tenants) where valid cloud accounts are used for months as the primary persistence mechanism."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "Substation Lambda functions (container-image Lambdas)",
                    "Lambda \u001a encrypted data stores (S3, DynamoDB, Kinesis, SQS, SNS, Secrets)",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "DynamoDB tables for state and streaming change data",
                    "S3 buckets for Substation data",
                    "SQS queues for buffered processing",
                    "SNS topics for notifications and autoscaling",
                    "AWS Secrets Manager secrets",
                    "CloudWatch Logs groups and embedded metrics"
                ],
                "interfaces_used": [
                    "AWS SDK default credential chain (environment variables, shared config files, Lambda execution role).",
                    "substation-kinesis-* IAM policies granting producer/consumer and autoscaling permissions.",
                    "substation-dynamodb-* IAM policies granting read/write and stream read access.",
                    "substation-s3-*, substation-sqs-*, substation-sns-* access policies.",
                    "substation-secret-* policy granting secretsmanager:GetSecretValue.",
                    "substation-lambda-access-* policy granting lambda:InvokeFunction and lambda:GetFunctionConfiguration to roles in var.access."
                ],
                "data_accessed": [
                    "All data stored in Substation-managed S3 buckets, DynamoDB tables, Kinesis streams, SQS queues, and SNS topics.",
                    "Secrets in AWS Secrets Manager used by Substation transforms.",
                    "Lambda configurations including environment variables and function metadata."
                ],
                "preconditions_required": [
                    "The attacker must successfully obtain long-lived or refreshable credentials for a Substation-related IAM role (e.g., via initial compromise of a Lambda execution environment, CI system, or developer workstation).",
                    "The compromised role must have meaningful data-plane permissions (as described in the substation-* access policies) that have not yet been revoked or heavily constrained by conditions (e.g., IP or device restrictions)."
                ],
                "constraints_encountered": [
                    "Short-lived credentials obtained from a running Lambda may expire within minutes to hours; persistence requires either repeated theft or access to a parent credential capable of calling STS AssumeRole.",
                    "Organization-wide controls such as AWS Organizations SCPs, IAM condition keys (e.g., aws:SourceIp), or strong CloudTrail monitoring can make anomalous use of these roles more detectable.",
                    "Key rotation and deactivation procedures, if consistently applied, can eventually invalidate the stolen credentials."
                ],
                "evasion_considerations": [
                    "Use the compromised roles only from IP ranges, regions, and times that align with expected workload patterns.",
                    "Throttle data access and avoid exhaustive enumeration or bulk downloads that might trigger anomaly detection.",
                    "If possible, interleave malicious operations with legitimate ones (for example, replaying or relaying some normal traffic) to further blend with baseline behavior."
                ],
                "comments": "This is a generic but powerful persistence vector: as long as attackers retain valid credentials for Substation-related IAM roles, they can continue to read data and invoke functions even if all application-layer backdoors are removed.",
                "persistence_mechanism": "Compromised IAM roles and access keys (Cloud Accounts) associated with Substation infrastructure that the attacker continues to use from outside the environment to access data stores and invoke Substation Lambdas over an extended period."
            },
            {
                "can_achieve": true,
                "technique_name": "Implant Internal Image",
                "technique_stix_id": "attack-pattern--4fd8a28b-4b3a-4cd6-a8cf-85ba5f824a7f",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify the ECR repository and image tags used by Substation Lambda functions by inspecting Terraform (build/terraform/aws/ecr/main.tf and build/terraform/aws/lambda/main.tf) and, if possible, querying AWS (e.g., aws lambda get-function and aws ecr describe-images).",
                        "related_capabilities": [
                            "ECR repositories storing Lambda container images",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "aws_ecr_repository.repository defined in build/terraform/aws/ecr/main.tf.",
                            "aws_lambda_function.lambda_function resources that reference image_uri values.",
                            "ECR DescribeImages and Lambda GetFunction APIs."
                        ],
                        "related_data": [
                            "Repository URIs and image tags/digests for Substation Lambda images."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Compromise the CI/CD pipeline, build system, or AWS account that has permissions to push images to the ECR repository and to update the Lambda function configuration (image_uri), effectively gaining control over what code the Lambda executes.",
                        "related_capabilities": [
                            "ECR repositories storing Lambda container images",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "ECR PushImage / BatchGetImage / PutImage operations available to CI/deployment roles.",
                            "Lambda UpdateFunctionCode or infrastructure-as-code pipelines that manage aws_lambda_function.lambda_function image_uri."
                        ],
                        "related_data": [
                            "Build artifacts and Dockerfiles for the Substation Lambda container.",
                            "IAM policies attached to CI/CD or deployment roles."
                        ],
                        "notes": "This follows the pattern documented by Rhino Labs for backdooring internal cloud/container images to achieve persistence via infrastructure-as-code."
                    },
                    {
                        "step_id": 3,
                        "description": "Create a trojanized Substation container image by modifying the source or build process to embed additional malicious logic, such as an extra HTTP server, covert C2 channel, or hard-coded exfiltration on every Transform call, while preserving all expected functionality.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "Dockerfile and build scripts used to construct the Substation Lambda image.",
                            "Substation’s main entrypoint (cmd/aws/lambda/substation/main.go) where additional code can be hooked."
                        ],
                        "related_data": [
                            "Modified source code or binaries included in the container image.",
                            "Embedded configuration or secrets that the malicious code may use."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "Push the malicious image to the ECR repository under a new tag (due to immutable tags) and update the Lambda function configuration (directly or via Terraform/CI) so that image_uri points to the trojanized image.",
                        "related_capabilities": [
                            "ECR repositories storing Lambda container images",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "ECR PutImage API for new tags in the repository.",
                            "Lambda UpdateFunctionCode / UpdateFunctionConfiguration APIs or terraform apply that updates image_uri.",
                            "ECR repository policy allowing the Lambda service principal to pull images."
                        ],
                        "related_data": [
                            "New container image tag and digest for the malicious Substation image.",
                            "Updated Lambda function configuration referencing the new image_uri."
                        ],
                        "notes": "Immutable tags prevent overwriting existing tags, but the attacker can still introduce a new tag and update Lambda to use it."
                    },
                    {
                        "step_id": 5,
                        "description": "Allow existing event sources (API Gateway, S3, Kinesis, DynamoDB Streams, SNS/SQS, EventBridge) to continue invoking the Lambda, now running the attacker-modified image, which can exfiltrate data or accept out-of-band commands on every execution.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "S3 buckets for Substation data",
                            "DynamoDB tables for state and streaming change data",
                            "EventBridge rule triggering Lambda"
                        ],
                        "related_interfaces": [
                            "HTTP \u001a API Gateway \u001a Lambda",
                            "API Gateway \u001a Kinesis Data Stream ingestion endpoint",
                            "EventBridge \u001a Lambda",
                            "S3/SNS/SQS/Kinesis/DynamoDB event sources configured for the Lambda."
                        ],
                        "related_data": [
                            "All message payloads and metadata processed by the trojanized Substation Lambda.",
                            "Any additional telemetry or C2 data emitted by the malicious code over HTTP or secondary AWS resources."
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "ECR repositories storing Lambda container images",
                    "Substation Lambda functions (container-image Lambdas)",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "S3 buckets for Substation data",
                    "DynamoDB tables for state and streaming change data",
                    "EventBridge rule triggering Lambda"
                ],
                "interfaces_used": [
                    "aws_ecr_repository.repository with immutable tags and scan-on-push enabled.",
                    "aws_lambda_function.lambda_function referencing image_uri values from ECR.",
                    "ECR Push/PutImage APIs used by CI/CD or deployment roles.",
                    "Lambda UpdateFunctionCode/UpdateFunctionConfiguration APIs or equivalent IaC mechanisms.",
                    "Existing event source mappings and API Gateway integrations that trigger the Lambda."
                ],
                "data_accessed": [
                    "All data that the compromised Lambda processes (events from API Gateway, Kinesis, S3, DynamoDB Streams, SNS, SQS).",
                    "Container image contents and build inputs that define Substation behavior.",
                    "ECR repository metadata and image tags."
                ],
                "preconditions_required": [
                    "The environment must deploy Substation Lambdas via container images stored in the ECR repository defined in build/terraform/aws/ecr/main.tf.",
                    "The attacker must compromise a principal with permissions both to push images to that ECR repository and to change the Lambda’s image_uri (for example, a CI/CD or infrastructure admin role).",
                    "Security controls such as ECR image scanning and deployment reviews must either be weak or must not detect the trojanized but functionally correct image."
                ],
                "constraints_encountered": [
                    "Immutable ECR tags prevent silently replacing an existing image tag; the attacker must introduce a new tag and ensure Lambda is updated to use it, an action that may be visible in change logs.",
                    "If Lambda functions are deployed from a strictly controlled, reproducible build process with strong integrity checks, deviations in image digests or tags may be detected.",
                    "Organizations may restrict which principals can update Lambda code/configuration, limiting the set of accounts that, if compromised, enable this vector."
                ],
                "evasion_considerations": [
                    "Keep the malicious changes small and preserve the image size, dependencies, and startup behavior to reduce the chance of detection via image scanning or performance anomalies.",
                    "Reuse existing network libraries and telemetry paths (e.g., send_aws_* transforms) to avoid introducing new dependencies that might be flagged.",
                    "Time image and Lambda updates to coincide with legitimate release cycles to blend into normal operational changes."
                ],
                "comments": "While this vector depends on compromising build or deployment infrastructure rather than Substation runtime roles, it yields deep, code-level persistence: every future invocation of the affected Lambda executes attacker-supplied logic, regardless of configuration hardening.",
                "persistence_mechanism": "A backdoored Substation Lambda container image stored in ECR and referenced by aws_lambda_function.lambda_function so that all future event-triggered executions of the function run attacker-controlled code."
            }
        ],
        "summary": "Within the Substation environment, realistic persistence for an attacker centers on three main themes: (1) subverting the configuration and state that drive the config-only Substation engine, (2) abusing long-lived IAM roles (Cloud Accounts) tied to the data plane, and (3) implanting code in the Lambda container image.\n\nBecause Substation’s behavior is entirely config-driven and executed in long-lived, event-triggered Lambdas and Cloud Functions, compromising configuration sources (remote SUBSTATION_CONFIG locations or AppConfig profiles) provides powerful, durable control over how all future data is processed and routed. This supports classic Event Triggered Execution persistence, akin to the Pacu pattern of wiring S3 events to malicious Lambdas, but here effected by malicious transforms in otherwise legitimate pipelines.\n\nKV-backed state in DynamoDB offers an additional, subtler control channel: attacker-planted KV entries with long TTLs can act as hidden feature flags, dynamic endpoint selectors, or routing switches that persist beyond code and static config changes. This can maintain exfiltration or modified routing as long as KV entries remain.\n\nSeparately, theft of Substation-related IAM role credentials (Lambda execution roles and roles in var.access) maps cleanly to the Cloud Accounts technique: these roles have broad data-plane and limited Lambda invocation rights, so compromised credentials give long-term API-level access to high-value data and the ability to drive Substation execution, even if application-layer backdoors are removed.\n\nFinally, the presence of an ECR-hosted container image for Substation Lambdas enables an Implant Internal Image vector if the attacker compromises CI/CD or deployment roles: a trojanized image referenced by aws_lambda_function.lambda_function will be executed on every trigger, independent of configuration integrity. Other MITRE persistence techniques that rely on IAM administration (creating new cloud accounts, adding credentials/roles, manipulating MFA or conditional access) are not directly supported by the documented Substation roles and permissions, so the most realistic persistence methods in this environment are those that leverage configuration, KV state, existing cloud accounts, and container images rather than control-plane IAM administration."
    },
    "initial-access": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Exploit Public-Facing Application",
                "technique_stix_id": "attack-pattern--3f886f2a-874f-4333-b794-aa6075009b1c",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Discover the public API Gateway endpoint that proxies HTTP POST requests to the Substation Lambda (for example from documentation, DNS enumeration, or traffic observation).",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "API Gateway \u001a Lambda ingestion endpoint",
                            "VPC with public and private subnets, NAT, and Internet gateway"
                        ],
                        "related_interfaces": [
                            "aws_api_gateway_rest_api.api (Lambda proxy API): public HTTPS endpoint with POST /, authorization = NONE, integrated via AWS_PROXY to Substation Lambda [build/terraform/aws/api_gateway/lambda/main.tf].",
                            "API Gateway REST API (Lambda proxy): Public POST method with authorization = NONE and AWS_PROXY integration pointing at a Substation Lambda; request body and context become APIGatewayProxyRequest events consumed by the AWS_API_GATEWAY handler and transformed into Messages (HTTP \u001a API Gateway \u001a Lambda \u001a Substation pipeline)."
                        ],
                        "related_data": [
                            "HTTP request bodies, headers, and query parameters sent by external clients to API Gateway Lambda-proxy ingestion endpoints, which become APIGatewayProxyRequest payloads and then Substation Messages."
                        ],
                        "notes": "Terraform explicitly configures authorization = NONE and no resource policy, making this a true internet-facing endpoint unless separately fronted by a WAF or private integration."
                    },
                    {
                        "step_id": 2,
                        "description": "Send crafted HTTP POST requests with arbitrary JSON or binary payloads to the API Gateway Lambda-proxy endpoint from the internet, relying on the lack of authentication to reach the Substation Lambda.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "AWS Lambda Substation event processors",
                            "Substation Lambda functions (container-image Lambdas)"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API (Lambda proxy): Public POST method with authorization = NONE and AWS_PROXY integration pointing at a Substation Lambda; request body and context become APIGatewayProxyRequest events consumed by the AWS_API_GATEWAY handler and transformed into Messages (HTTP \u001a API Gateway \u001a Lambda \u001a Substation pipeline).",
                            "aws_lambda_function.lambda_function (Substation Lambda): backend compute invoked by the public API and by internal roles in var.access; runs under execution role substation-lambda-${random_uuid} [build/terraform/aws/lambda/main.tf]."
                        ],
                        "related_data": [
                            "HTTP request bodies, headers, and query parameters sent by external clients to API Gateway Lambda-proxy ingestion endpoints, which become APIGatewayProxyRequest payloads and then Substation Messages.",
                            "Event payloads from API Gateway, generic Lambda invocations, Kinesis, Firehose, DynamoDB Streams, S3, SNS, SQS."
                        ],
                        "notes": "There is no caller authentication at API Gateway, so any internet host can reach the Lambda as long as the DNS name is known and the method/stage is deployed."
                    },
                    {
                        "step_id": 3,
                        "description": "Allow the Substation Lambda AWS_API_GATEWAY handler to wrap each APIGatewayProxyRequest into a message.Message and execute the configured Substation pipeline, running under the Lambda execution role’s IAM permissions.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Core Substation transformation engine",
                            "substation (root package)"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API (Lambda proxy): Public POST method with authorization = NONE and AWS_PROXY integration pointing at a Substation Lambda; request body and context become APIGatewayProxyRequest events consumed by the AWS_API_GATEWAY handler and transformed into Messages (HTTP \u001a API Gateway \u001a Lambda \u001a Substation pipeline)."
                        ],
                        "related_data": [
                            "substation.Config (list of transform configs)",
                            "config.Config {Type, Settings}",
                            "message.Message {data, metadata, control flag}"
                        ],
                        "notes": "From this point onward the attacker-controlled data is treated as normal pipeline input and can drive downstream side effects (writes to S3, DynamoDB, Kinesis, SNS/SQS, HTTP, etc.) according to the deployed configuration."
                    },
                    {
                        "step_id": 4,
                        "description": "Observe JSON responses (if the pipeline returns messages) and error codes to iteratively shape payloads that keep the pipeline healthy while exercising desired side effects (for example, generating specific downstream records).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API (Lambda proxy): Public POST method with authorization = NONE and AWS_PROXY integration pointing at a Substation Lambda; request body and context become APIGatewayProxyRequest events consumed by the AWS_API_GATEWAY handler and transformed into Messages (HTTP \u001a API Gateway \u001a Lambda \u001a Substation pipeline)."
                        ],
                        "related_data": [
                            "JSON array responses returned by the API Gateway handler containing transformed messages (when configured to return non-control outputs).",
                            "Lambda error messages and HTTP 5xx responses surfaced via API Gateway."
                        ],
                        "notes": "The handler validates that outputs are valid JSON; malformed responses manifest as 5xx errors, which an attacker can use as an oracle to tune inputs."
                    }
                ],
                "capabilities_used": [
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "API Gateway \u001a Lambda ingestion endpoint",
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "Substation Lambda functions (container-image Lambdas)",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "aws_api_gateway_rest_api.api (Lambda proxy API): public HTTPS endpoint with POST /, authorization = NONE, integrated via AWS_PROXY to Substation Lambda [build/terraform/aws/api_gateway/lambda/main.tf].",
                    "API Gateway REST API (Lambda proxy): Public POST method with authorization = NONE and AWS_PROXY integration pointing at a Substation Lambda; request body and context become APIGatewayProxyRequest events consumed by the AWS_API_GATEWAY handler and transformed into Messages (HTTP \u001a API Gateway \u001a Lambda \u001a Substation pipeline)."
                ],
                "data_accessed": [
                    "Ability to inject arbitrary HTTP request bodies that become message.Message instances inside Substation pipelines executed by the public Lambda.",
                    "Potential visibility into transformed pipeline outputs returned as JSON arrays from the API Gateway handler, depending on configuration.",
                    "Indirect influence over downstream data written by the Lambda’s IAM role to S3, DynamoDB, Kinesis, SQS, SNS, EventBridge, and other sinks configured in the pipeline."
                ],
                "preconditions_required": [
                    "The API Gateway Lambda-proxy REST API must be deployed and reachable over the internet (DNS and routing in place).",
                    "Terraform-style configuration for the Lambda-proxy API remains with authorization = NONE and no restrictive resource policy or WAF in front.",
                    "The Substation Lambda is configured with an AWS_API_GATEWAY handler and a valid SUBSTATION_CONFIG so that requests are successfully processed rather than failing early.",
                    "Attacker is able to discover or guess the API’s hostname and path (for example via documentation, DNS, or reconnaissance)."
                ],
                "constraints_encountered": [
                    "API Gateway request size and rate limits constrain how much data can be sent per call and how quickly calls can be made.",
                    "The Lambda handler enforces that responses are valid JSON; if the configured pipeline produces invalid JSON for attacker-crafted inputs, the request results in an error instead of a successful response.",
                    "Downstream IAM permissions on the Lambda execution role may limit which AWS resources can actually be affected by attacker-supplied input, though this does not prevent initial access to the Lambda and pipeline itself.",
                    "Additional controls such as an external WAF, private API Gateway endpoints, or VPC-only access (if layered outside this repo) could restrict who can reach the API; these are not present in the Terraform analyzed here."
                ],
                "evasion_considerations": [
                    "Shape request bodies to resemble expected application payloads (for example, log records or events) so that anomalies are less obvious in logs and metrics.",
                    "Throttle request rates to stay below any operational alarms, Lambda concurrency limits, or API Gateway throttling that defenders may have configured.",
                    "Vary source IPs and user-agents to blend with legitimate client traffic if the API is multi-tenant."
                ],
                "resulting_access": "Unauthenticated, remote ability from the public internet to invoke a Substation Lambda via API Gateway and supply arbitrary payloads that become pipeline input under the Lambda’s IAM permissions, with potential visibility into transformed outputs.",
                "comments": "This is the clearest initial access vector for an external attacker with no credentials. The crown jewels exposed via this path are whatever high-value data and side effects the public-facing Substation pipeline has been configured for—for example centralized logs, customer telemetry, or writes into sensitive downstream stores. Even without further exploitation, an attacker can use this as a powerful data injection and potential data poisoning channel."
            },
            {
                "can_achieve": true,
                "technique_name": "Exploit Public-Facing Application",
                "technique_stix_id": "attack-pattern--3f886f2a-874f-4333-b794-aa6075009b1c",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify the public API Gateway REST API that front-ends Kinesis PutRecord for ingestion into a Substation-connected Kinesis Data Stream.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "API Gateway \u001a Kinesis Data Stream ingestion endpoint",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "VPC with public and private subnets, NAT, and Internet gateway"
                        ],
                        "related_interfaces": [
                            "aws_api_gateway_rest_api.api (Kinesis PutRecord API): public HTTPS endpoint with POST /, authorization = NONE, integrated to Kinesis PutRecord via IAM role substation-api-kinesis-${random_uuid} [build/terraform/aws/api_gateway/kinesis_data_stream/main.tf].",
                            "API Gateway REST API (direct to Kinesis): Public POST method with authorization = NONE integrated to Kinesis PutRecord via an IAM role assumed by apigateway.amazonaws.com; HTTP request bodies are base64-encoded into Kinesis Data fields and typically keyed by a request identifier (HTTP \u001a API Gateway \u001a Kinesis stream \u001a Substation consumer)."
                        ],
                        "related_data": [
                            "HTTP request bodies sent to API Gateway Kinesis ingestion endpoints, which are encoded as Kinesis Data payloads.",
                            "Kinesis records (Data, PartitionKey, sequence/partition metadata) produced by API Gateway ingestion APIs."
                        ],
                        "notes": "The Terraform module configures authorization = NONE for this REST API, making it an unauthenticated ingestion path from the internet into a Kinesis stream when the IAM role has Kinesis permissions attached."
                    },
                    {
                        "step_id": 2,
                        "description": "Send arbitrary HTTP POST requests to the Kinesis ingestion API, letting API Gateway base64-encode the body and call Kinesis PutRecord using its integration IAM role.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API (direct to Kinesis): Public POST method with authorization = NONE integrated to Kinesis PutRecord via an IAM role assumed by apigateway.amazonaws.com; HTTP request bodies are base64-encoded into Kinesis Data fields and typically keyed by a request identifier (HTTP \u001a API Gateway \u001a Kinesis stream \u001a Substation consumer)."
                        ],
                        "related_data": [
                            "HTTP request bodies sent to API Gateway Kinesis ingestion endpoints, which are encoded as Kinesis Data payloads.",
                            "Kinesis records (Data, PartitionKey, sequence/partition metadata) produced by API Gateway ingestion APIs."
                        ],
                        "notes": "From the attacker’s perspective this behaves like a public, unauthenticated streaming ingestion endpoint. Successful PutRecord responses confirm that data has entered the target stream."
                    },
                    {
                        "step_id": 3,
                        "description": "Rely on downstream Substation Kinesis consumers (Lambdas or CLI tap) to treat these Kinesis records as normal input, wrapping them into Messages and executing the configured pipelines.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Kinesis streams as ingestion sources: Substation's Kinesis handlers and CLI 'tap' consume records from configured streams; records may originate from API Gateway ingestion APIs, CloudWatch Logs destinations, or any principal with kinesis:PutRecord/PutRecords on the stream."
                        ],
                        "related_data": [
                            "Event payloads from Kinesis Data Streams mapped into Substation Messages.",
                            "message.Message {data, metadata, control flag}"
                        ],
                        "notes": "Once in the stream, attacker-controlled data is indistinguishable from legitimate records to Substation, giving the attacker an ongoing foothold in any analytics, transformation, or forwarding the pipeline performs."
                    },
                    {
                        "step_id": 4,
                        "description": "Iteratively adjust payload formats and rates based on any observable side effects (downstream logs, metrics, or out-of-band responses) to maximize impact while avoiding obvious operational failures.",
                        "related_capabilities": [
                            "Kinesis Data Streams for high-throughput ingestion",
                            "Metrics and observability transforms"
                        ],
                        "related_interfaces": [
                            "Kinesis streams as ingestion sources: Substation's Kinesis handlers and CLI 'tap' consume records from configured streams; records may originate from API Gateway ingestion APIs, CloudWatch Logs destinations, or any principal with kinesis:PutRecord/PutRecords on the stream."
                        ],
                        "related_data": [
                            "CloudWatch log events and metrics emitted by Substation Lambdas processing the stream.",
                            "Aggregated counts and sizes per control window from metric transforms."
                        ],
                        "notes": "This mirrors real-world abuse of public ingestion APIs seen in log- and telemetry-processing environments, where attackers inject poisoned or maliciously structured records via misconfigured front doors."
                    }
                ],
                "capabilities_used": [
                    "Public HTTP APIs via API Gateway (direct to Kinesis)",
                    "API Gateway \u001a Kinesis Data Stream ingestion endpoint",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "CloudWatch Logs subscription routing",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "aws_api_gateway_rest_api.api (Kinesis PutRecord API): public HTTPS endpoint with POST /, authorization = NONE, integrated to Kinesis PutRecord via IAM role substation-api-kinesis-${random_uuid} [build/terraform/aws/api_gateway/kinesis_data_stream/main.tf].",
                    "API Gateway REST API (direct to Kinesis): Public POST method with authorization = NONE integrated to Kinesis PutRecord via an IAM role assumed by apigateway.amazonaws.com; HTTP request bodies are base64-encoded into Kinesis Data fields and typically keyed by a request identifier (HTTP \u001a API Gateway \u001a Kinesis stream \u001a Substation consumer).",
                    "Kinesis streams as ingestion sources: Substation's Kinesis handlers and CLI 'tap' consume records from configured streams; records may originate from API Gateway ingestion APIs, CloudWatch Logs destinations, or any principal with kinesis:PutRecord/PutRecords on the stream."
                ],
                "data_accessed": [
                    "Kinesis Data records into which attacker-supplied HTTP bodies are encoded.",
                    "Any downstream derivatives of those records produced by Substation pipelines (for example, items written into S3 buckets for Substation data, DynamoDB tables for state, or further Kinesis/SNS/SQS streams)."
                ],
                "preconditions_required": [
                    "The Kinesis ingestion API Gateway REST API must be deployed and internet-reachable.",
                    "Its integration IAM role (substation-api-kinesis-...) must have kinesis:PutRecord (and related) permissions on a Kinesis stream actually consumed by Substation.",
                    "Substation Kinesis consumers (Lambda handlers or CLI tap processes) must be configured on that stream.",
                    "Attacker can discover the API hostname and path."
                ],
                "constraints_encountered": [
                    "API Gateway and Kinesis impose per-record and per-stream size and throughput limits, which bound how much data the attacker can inject per unit time.",
                    "If the IAM role backing the API has not been given Kinesis permissions, PutRecord calls will fail, preventing this vector; however the intended usage pattern is to attach such permissions.",
                    "Downstream Substation configuration may validate payload schemas and drop malformed messages, limiting the attacker’s ability to influence certain pipelines—but not blocking initial injection into the stream."
                ],
                "evasion_considerations": [
                    "Mimic expected record formats (for example, JSON log lines) so that validation and anomaly detection rules are less likely to drop or flag attacker-supplied data.",
                    "Distribute traffic over time to avoid triggering Kinesis or CloudWatch alarms on sudden throughput spikes.",
                    "Use partition keys that align with normal workload patterns to avoid creating conspicuous hot shards."
                ],
                "resulting_access": "Unauthenticated capability to inject arbitrary records into a Kinesis Data Stream that Substation consumes, effectively gaining an ongoing foothold in streaming pipelines without needing AWS credentials.",
                "comments": "This vector is especially valuable where the Kinesis stream carries high-value telemetry or customer data. By controlling records on ingress, an attacker can poison analytics, hide activity in noisy streams, or create covert channels into downstream systems reached by Substation."
            },
            {
                "can_achieve": true,
                "technique_name": "Exploit Public-Facing Application",
                "technique_stix_id": "attack-pattern--3f886f2a-874f-4333-b794-aa6075009b1c",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Locate a running instance of the Substation CLI playground HTTP server (for example, via port scanning, internal service discovery, or exposed developer endpoints).",
                        "related_capabilities": [
                            "cmd/substation CLI",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Playground HTTP endpoints (cmd/substation/playground.go): HTTP server started by 'substation play' exposing '/', '/run', '/test', '/demo', '/fmt', and '/share'; '/run' and '/test' accept configs, tests, sample events, and environment-variable overrides over HTTP and execute them through Substation without any documented authentication controls."
                        ],
                        "related_data": [
                            "Jsonnet and JSON configuration files submitted via HTTP to the playground.",
                            "Sample events and environment-variable overrides provided by the HTTP client."
                        ],
                        "notes": "The repository does not define authentication or network restrictions for the playground; by default it is a generic HTTP server and may be accidentally exposed beyond localhost or development environments."
                    },
                    {
                        "step_id": 2,
                        "description": "Query the root or documentation endpoints (such as '/') to confirm the service is Substation’s playground and to understand expected payload formats for /run and /test.",
                        "related_capabilities": [
                            "cmd/substation CLI"
                        ],
                        "related_interfaces": [
                            "Playground HTTP endpoints (cmd/substation/playground.go): HTTP server started by 'substation play' exposing '/', '/run', '/test', '/demo', '/fmt', and '/share'; '/run' and '/test' accept configs, tests, sample events, and environment-variable overrides over HTTP and execute them through Substation without any documented authentication controls."
                        ],
                        "related_data": [
                            "HTTP responses from the playground server describing available endpoints and example payloads."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Craft a malicious Substation configuration and sample event that, when executed, causes the process to perform attacker-chosen side effects using local AWS/GCP credentials (for example, send_http_post to an attacker-controlled URL or send_aws_s3 to write data into an attacker-readable bucket).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "Playground HTTP endpoints (cmd/substation/playground.go): HTTP server started by 'substation play' exposing '/', '/run', '/test', '/demo', '/fmt', and '/share'; '/run' and '/test' accept configs, tests, sample events, and environment-variable overrides over HTTP and execute them through Substation without any documented authentication controls."
                        ],
                        "related_data": [
                            "substation.Config (list of transform configs) submitted over HTTP.",
                            "Transformed message payloads used by send_* transforms.",
                            "Secret identifiers and values used via ${SECRET:ID} interpolation."
                        ],
                        "notes": "Because the playground executes arbitrary user-supplied configs, an attacker can select any available transforms, including HTTP exfiltration and AWS/GCP sinks bound to powerful IAM roles in the environment where the playground runs."
                    },
                    {
                        "step_id": 4,
                        "description": "POST the crafted config, sample event, and environment-variable overrides to the /run (or /test) endpoint, causing the playground to temporarily set process environment variables, build the pipeline, and execute it with the host’s credentials.",
                        "related_capabilities": [
                            "cmd/substation CLI",
                            "Core Substation transformation engine",
                            "internal/secrets",
                            "internal/config"
                        ],
                        "related_interfaces": [
                            "Playground HTTP endpoints (cmd/substation/playground.go): HTTP server started by 'substation play' exposing '/', '/run', '/test', '/demo', '/fmt', and '/share'; '/run' and '/test' accept configs, tests, sample events, and environment-variable overrides over HTTP and execute them through Substation without any documented authentication controls."
                        ],
                        "related_data": [
                            "Environment variable values (for example, AWS_REGION, SUBSTATION_CONFIG, or custom variables) set based on attacker input for the duration of the request.",
                            "Any data the host’s IAM role can read and that the attacker’s config chooses to forward or exfiltrate."
                        ],
                        "notes": "The playground explicitly allows overriding environment variables per request, which can influence how internal/config.NewAWS resolves regions and roles, or how other transforms behave."
                    }
                ],
                "capabilities_used": [
                    "cmd/substation CLI",
                    "Core Substation transformation engine",
                    "HTTP enrichment and sending transforms",
                    "AWS and GCP sink transforms",
                    "Secrets retrieval and interpolation"
                ],
                "interfaces_used": [
                    "Playground HTTP endpoints (cmd/substation/playground.go): HTTP server started by 'substation play' exposing '/', '/run', '/test', '/demo', '/fmt', and '/share'; '/run' and '/test' accept configs, tests, sample events, and environment-variable overrides over HTTP and execute them through Substation without any documented authentication controls."
                ],
                "data_accessed": [
                    "Arbitrary pipeline configs, test definitions, and sample events submitted by the attacker and executed on the host.",
                    "Any data reachable using the host’s AWS/GCP credentials if the attacker’s config uses send_* or enrich_* transforms to interact with those services.",
                    "Environment variables temporarily overridden via the playground, which may include sensitive configuration such as SUBSTATION_CONFIG or credential-related variables."
                ],
                "preconditions_required": [
                    "An operator has started the 'substation play' command and bound it on an interface reachable by the attacker (for example, 0.0.0.0 on a development or shared host).",
                    "No additional network ACLs, reverse proxies, or auth mechanisms block access to the playground HTTP port.",
                    "The host’s IAM or cloud credentials grant access to data or services the attacker wants to reach through malicious transforms."
                ],
                "constraints_encountered": [
                    "In many deployments the playground may be used only on local developer machines or non-production environments, limiting direct impact—but accidental exposure (for example, on a shared bastion or container host) is realistic.",
                    "The playground restores environment variables after each request, so persistent environment changes require repeated calls rather than a one-time modification.",
                    "Any outgoing network access still depends on the host’s firewall/VPC configuration; if the host cannot reach the attacker’s endpoints or external AWS/GCP services, some malicious transforms may fail."
                ],
                "evasion_considerations": [
                    "Blend malicious configs and test events with legitimate-looking ones (for example, using plausible metric or log processing pipelines) to avoid suspicion if playground usage is monitored.",
                    "Use subtle side effects, such as low-volume exfiltration or targeted reads/writes, rather than noisy bulk operations that could be noticed by operators watching the playground or cloud audit logs."
                ],
                "resulting_access": "Remote, unauthenticated ability (if exposed) to run arbitrary Substation pipelines and temporary environment-variable overrides on a host using its local cloud credentials, effectively turning the playground into an on-demand execution environment for pipeline logic.",
                "comments": "While primarily a developer tool, the playground is extremely powerful if inadvertently exposed. The attacker’s immediate prize is whatever the host’s IAM role or credentials can reach—typically the same data stores and secrets used by production-like Substation workloads."
            },
            {
                "can_achieve": true,
                "technique_name": "Trusted Relationship",
                "technique_stix_id": "attack-pattern--9fa07bef-9c81-421e-a8e5-ad4366c5a925",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise or legitimately obtain access to an AWS account that is allowed to send logs into the central CloudWatch Logs destination (its account ID is included in var.config.account_ids or is the hosting account itself).",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "aws_cloudwatch_log_destination.destination and associated aws_iam_role.destination (substation-cloudwatch-dest-${random_uuid}): cross-account log sink accepting subscriptions and write operations from multiple accounts into Kinesis/Firehose [build/terraform/aws/cloudwatch/destination/main.tf].",
                            "CloudWatch Logs subscription filters: logs:PutSubscriptionFilter API from external AWS accounts (var.config.account_ids) to a shared destination_arn; events are delivered by logs.amazonaws.com into a Kinesis Data Stream or Firehose that may back a Substation pipeline (cross-account untrusted log ingestion)."
                        ],
                        "related_data": [
                            "CloudWatch log events (log messages, timestamps, logGroup/logStream identifiers) generated in the compromised account.",
                            "Kinesis records carrying forwarded log events into the central stream processed by Substation."
                        ],
                        "notes": "This mirrors real-world campaigns where adversaries abuse managed service providers or partner environments to pivot into centralized logging or monitoring infrastructure."
                    },
                    {
                        "step_id": 2,
                        "description": "In the compromised account, create or identify a CloudWatch Logs log group and configure a subscription filter that targets the shared CloudWatch Logs destination_arn in the Substation environment.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs subscription filters: logs:PutSubscriptionFilter API from external AWS accounts (var.config.account_ids) to a shared destination_arn; events are delivered by logs.amazonaws.com into a Kinesis Data Stream or Firehose that may back a Substation pipeline (cross-account untrusted log ingestion)."
                        ],
                        "related_data": [
                            "CloudWatch Logs subscription configuration linking the attacker-controlled log group to the central destination.",
                            "CloudWatch log events enqueued for forwarding to the shared Kinesis or Firehose destination."
                        ],
                        "notes": "The destination policy explicitly allows logs:PutSubscriptionFilter from the configured accounts plus the current account, so this operation is expected and normally trusted."
                    },
                    {
                        "step_id": 3,
                        "description": "Generate arbitrary log events in the compromised account’s log group (for example, using application logs, lambda logs, or synthetic log writers) such that the attacker controls the content of messages forwarded through the subscription.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs groups and embedded metrics",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs subscription filters: logs:PutSubscriptionFilter API from external AWS accounts (var.config.account_ids) to a shared destination_arn; events are delivered by logs.amazonaws.com into a Kinesis Data Stream or Firehose that may back a Substation pipeline (cross-account untrusted log ingestion)."
                        ],
                        "related_data": [
                            "CloudWatch log event payloads that are forwarded cross-account into the central Kinesis or Firehose stream.",
                            "Kinesis records containing serialized log events from multiple accounts."
                        ],
                        "notes": "From the Substation environment’s perspective, these are indistinguishable from legitimate logs from a trusted external account."
                    },
                    {
                        "step_id": 4,
                        "description": "Rely on Substation pipelines subscribed to the central Kinesis or Firehose destination to treat these attacker-controlled log events as normal input, gaining an ongoing ability to inject structured data into whatever downstream systems those pipelines write to.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Kinesis streams as ingestion sources: Substation's Kinesis handlers and CLI 'tap' consume records from configured streams; records may originate from API Gateway ingestion APIs, CloudWatch Logs destinations, or any principal with kinesis:PutRecord/PutRecords on the stream."
                        ],
                        "related_data": [
                            "Event payloads from Kinesis Data Streams mapped into Substation Messages.",
                            "Downstream records written into S3 buckets for Substation data, DynamoDB tables, or other sinks as defined by the pipelines."
                        ],
                        "notes": "This gives the attacker a durable, low-friction foothold into log-processing or analytics pipelines under the guise of a legitimate, trusted log source."
                    }
                ],
                "capabilities_used": [
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "CloudWatch Logs groups and embedded metrics",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine"
                ],
                "interfaces_used": [
                    "aws_cloudwatch_log_destination.destination and associated aws_iam_role.destination (substation-cloudwatch-dest-${random_uuid}): cross-account log sink accepting subscriptions and write operations from multiple accounts into Kinesis/Firehose [build/terraform/aws/cloudwatch/destination/main.tf].",
                    "CloudWatch Logs subscription filters: logs:PutSubscriptionFilter API from external AWS accounts (var.config.account_ids) to a shared destination_arn; events are delivered by logs.amazonaws.com into a Kinesis Data Stream or Firehose that may back a Substation pipeline (cross-account untrusted log ingestion).",
                    "Kinesis streams as ingestion sources: Substation's Kinesis handlers and CLI 'tap' consume records from configured streams; records may originate from API Gateway ingestion APIs, CloudWatch Logs destinations, or any principal with kinesis:PutRecord/PutRecords on the stream."
                ],
                "data_accessed": [
                    "Centralized Kinesis or Firehose streams aggregating log events from multiple AWS accounts.",
                    "Whatever downstream analytics or storage systems Substation pipelines write those logs into (for example, archival S3 buckets, SIEM indices, or alerting topics)."
                ],
                "preconditions_required": [
                    "The attacker controls or has compromised an AWS account whose ID appears in var.config.account_ids (or is the hosting account).",
                    "The central CloudWatch Logs destination and subscription routing modules are deployed and wired into Substation-consuming Kinesis or Firehose streams.",
                    "The attacker’s principal in the external account has permissions to create log groups and call logs:PutSubscriptionFilter on them.",
                    "Substation pipelines exist that consume the central stream and process these logs."
                ],
                "constraints_encountered": [
                    "CloudWatch Logs subscription filters apply pattern matching; if configured narrowly, some attacker-crafted events may not be forwarded unless they mimic expected formats.",
                    "Destination policies could be further restricted by log-group ARNs or conditions, though in the analyzed Terraform they primarily constrain by account ID.",
                    "Kinesis or Firehose throughput and retention settings may limit how much malicious log traffic can be sustained without causing operational issues that defenders may notice."
                ],
                "evasion_considerations": [
                    "Craft log messages that closely resemble legitimate logs from the compromised account to avoid manual or automated anomaly detection.",
                    "Use realistic log volumes and event timing patterns so that central streams are not obviously flooded by malicious data.",
                    "If multiple trusted external accounts exist, prefer one with high baseline log volume to blend in."
                ],
                "resulting_access": "Stealthy, persistent ability to inject arbitrary log-derived data into centralized Substation pipelines by abusing cross-account CloudWatch Logs subscriptions from a compromised or maliciously controlled trusted AWS account.",
                "comments": "Here the trusted relationship is the cross-account logging arrangement. The attacker’s prize is influence over central log processing and any downstream systems those logs feed—useful for hiding activity, poisoning security analytics, or exfiltrating data through logs."
            },
            {
                "can_achieve": true,
                "technique_name": "Trusted Relationship",
                "technique_stix_id": "attack-pattern--9fa07bef-9c81-421e-a8e5-ad4366c5a925",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Operate or compromise an external HTTP(S) service that Substation pipelines already use for enrichment via enrich_http_get or enrich_http_post transforms (for example, a third-party enrichment API or internal microservice).",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "HTTP endpoints used by enrich_http_get/enrich_http_post: Config-driven URL templates (often including ${DATA} and ${SECRET:ID} interpolation) invoked via internal/http.Get/Post; responses are parsed and merged into message fields, making these endpoints effective untrusted data providers."
                        ],
                        "related_data": [
                            "HTTP responses (status, headers, and bodies) from arbitrary external servers contacted by enrich_http_get and enrich_http_post, which are parsed and merged into message JSON structures."
                        ],
                        "notes": "This models a supplier, partner, or internal service turning malicious or being compromised, similar to supply-chain abuse seen in other environments."
                    },
                    {
                        "step_id": 2,
                        "description": "Observe or infer the expected request patterns from Substation (for example, based on logs, documentation, or direct visibility) so responses can be crafted to fit the expected schema while embedding attacker-controlled values.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "internal/http"
                        ],
                        "related_interfaces": [
                            "HTTP endpoints used by enrich_http_get/enrich_http_post: Config-driven URL templates (often including ${DATA} and ${SECRET:ID} interpolation) invoked via internal/http.Get/Post; responses are parsed and merged into message fields, making these endpoints effective untrusted data providers."
                        ],
                        "related_data": [
                            "URL templates and headers (potentially including secrets) used by the enrich transforms.",
                            "Message fields into which enrichment data is written or over which it can overwrite existing data."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Return maliciously crafted HTTP responses to Substation’s enrichment calls, embedding data that manipulates downstream routing, metrics, or sinks (for example, changing destination ARNs, toggling feature flags, or injecting large or malformed structures).",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "HTTP endpoints used by enrich_http_get/enrich_http_post: Config-driven URL templates (often including ${DATA} and ${SECRET:ID} interpolation) invoked via internal/http.Get/Post; responses are parsed and merged into message fields, making these endpoints effective untrusted data providers."
                        ],
                        "related_data": [
                            "Enriched JSON objects merged into message.data or specific target fields.",
                            "Downstream configuration-like fields (destination identifiers, flags, keys) whose values can be influenced by enrichment results."
                        ],
                        "notes": "Because enrichment responses are treated as data, they can subtly steer later transforms without changing the static pipeline config."
                    },
                    {
                        "step_id": 4,
                        "description": "Allow the rest of the pipeline to run using the attacker-supplied enriched fields, gaining an implicit foothold in decision logic and data paths across all workloads that rely on this enrichment service.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "Metrics and observability transforms"
                        ],
                        "related_interfaces": [
                            "HTTP endpoints used by enrich_http_get/enrich_http_post: Config-driven URL templates (often including ${DATA} and ${SECRET:ID} interpolation) invoked via internal/http.Get/Post; responses are parsed and merged into message fields, making these endpoints effective untrusted data providers."
                        ],
                        "related_data": [
                            "Messages whose routing or sink selection is influenced by enrichment results.",
                            "Metrics and logs that may now reflect attacker-controlled labels, values, or routing outcomes."
                        ],
                        "notes": "This is analogous to compromising a third-party provider to pivot into customer environments by manipulating data rather than code."
                    }
                ],
                "capabilities_used": [
                    "HTTP enrichment and sending transforms",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms",
                    "internal/http"
                ],
                "interfaces_used": [
                    "HTTP endpoints used by enrich_http_get/enrich_http_post: Config-driven URL templates (often including ${DATA} and ${SECRET:ID} interpolation) invoked via internal/http.Get/Post; responses are parsed and merged into message fields, making these endpoints effective untrusted data providers."
                ],
                "data_accessed": [
                    "All enrichment responses merged into pipeline messages for tenants that call the attacker-controlled service.",
                    "Indirect influence over routing keys, destination identifiers, and other derived values used later in send_* transforms."
                ],
                "preconditions_required": [
                    "Substation pipelines must be configured with enrich_http_get or enrich_http_post transforms pointing at the attacker-controlled or compromised HTTP endpoint.",
                    "Network paths from Substation execution environments (Lambdas, Cloud Functions, CLI runtimes) to the HTTP service must be open (via VPC/NAT or public internet).",
                    "Pipeline authors do not strictly validate or sanitize enrichment responses before using them in routing or sink selection."
                ],
                "constraints_encountered": [
                    "If pipelines apply strict schema validation or bounding on enrichment data, some malicious manipulations may be rejected or truncated.",
                    "Outbound HTTP traffic may be restricted by egress filters or private VPC endpoints limiting which hosts can be reached.",
                    "Substation treats enrichment failures as transform errors; overly disruptive responses that cause errors may break pipelines and draw attention rather than granting subtle influence."
                ],
                "evasion_considerations": [
                    "Return syntactically valid, plausibly correct JSON while subtly tweaking fields that influence behavior (for example, low-frequency changes to routing keys or thresholds).",
                    "Maintain high availability and low latency so enrichment calls do not time out or cause obvious instability.",
                    "Only manipulate a subset of tenants or message types to avoid broad, easily correlated anomalies."
                ],
                "resulting_access": "Influence over the content and control fields of messages inside Substation pipelines for any workloads that depend on the attacker-controlled enrichment service, effectively providing a data-plane foothold via a trusted external dependency.",
                "comments": "For data-processing systems, controlling a trusted enrichment provider can be nearly as powerful as owning configuration: it lets an attacker steer where data goes and how it is interpreted without touching Substation code or configs directly."
            },
            {
                "can_achieve": true,
                "technique_name": "Trusted Relationship",
                "technique_stix_id": "attack-pattern--9fa07bef-9c81-421e-a8e5-ad4366c5a925",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain control over the storage location or service that hosts the SUBSTATION_CONFIG used by Substation runtimes (for example, an S3 object, GCS object, or HTTP endpoint selected by operations as the config source).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Core Substation transformation engine",
                            "internal/file",
                            "AWS AppConfig application & environments"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable: Used by AWS Lambda Substation handlers and the GCP Cloud Function to locate configuration via internal/file.Get; accepts local paths as well as http://, https://, s3://, and gs:// URIs, so remote HTTP servers and S3/GCS buckets can be configuration sources."
                        ],
                        "related_data": [
                            "Jsonnet and JSON Substation configuration documents loaded from SUBSTATION_CONFIG locations over HTTP, S3, or GCS, including full transform graphs, sink definitions, secret references, and batching behavior."
                        ],
                        "notes": "Control may come from being a trusted configuration service provider, from compromise of the account or bucket hosting configs, or from misconfigured cross-account access."
                    },
                    {
                        "step_id": 2,
                        "description": "Replace or modify the configuration at that location with attacker-crafted Jsonnet/JSON that defines pipelines using exfiltration or manipulation transforms (for example, send_http_post to attacker-controlled URLs or send_aws_* pointing at attacker-accessible resources).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable: Used by AWS Lambda Substation handlers and the GCP Cloud Function to locate configuration via internal/file.Get; accepts local paths as well as http://, https://, s3://, and gs:// URIs, so remote HTTP servers and S3/GCS buckets can be configuration sources."
                        ],
                        "related_data": [
                            "substation.Config (list of transform configs) containing attacker-defined transform Type and Settings.",
                            "Secret identifiers embedded into config strings via ${SECRET:ID} that the attacker’s pipeline may misuse or forward."
                        ],
                        "notes": "Because transforms are entirely config-driven, malicious configuration effectively gives the attacker control over pipeline behavior without altering Substation binaries."
                    },
                    {
                        "step_id": 3,
                        "description": "Wait for Substation runtimes (Lambdas, Cloud Functions, CLI jobs) to load or reload SUBSTATION_CONFIG via internal/file.Get and substation.New, causing the attacker’s configuration to be instantiated as the active pipeline.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Core Substation transformation engine",
                            "internal/file"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable: Used by AWS Lambda Substation handlers and the GCP Cloud Function to locate configuration via internal/file.Get; accepts local paths as well as http://, https://, s3://, and gs:// URIs, so remote HTTP servers and S3/GCS buckets can be configuration sources."
                        ],
                        "related_data": [
                            "Configuration bytes fetched from HTTP, S3, or GCS and unmarshaled into substation.Config.",
                            "Runtime metadata such as config URIs and object locations used by internal/file.Get."
                        ],
                        "notes": "In many deployments, configs are read at Lambda cold start or function initialization, so changes may take effect as functions scale or are redeployed."
                    },
                    {
                        "step_id": 4,
                        "description": "Allow normal event sources (API Gateway, Kinesis, S3, GCS, SNS/SQS, CloudWatch Logs) to trigger the now-compromised pipelines, effectively granting the attacker initial execution control within the Substation environment tied to the runtimes’ IAM roles.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "HTTP \u001a API Gateway \u001a Lambda",
                            "HTTP \u001a API Gateway \u001a Kinesis Data Stream",
                            "GCP Cloud Function HTTP/CloudEvent endpoint '/': CloudEvent handler registered via funcframework at path '/' for SUBSTATION_FUNCTION_HANDLER=GCP_STORAGE; it receives CloudStorageEvent metadata, then downloads the referenced GCS object and streams its contents into a Substation pipeline, so any writer to those buckets can indirectly inject data."
                        ],
                        "related_data": [
                            "Event payloads from all configured sources now processed by attacker-defined transforms.",
                            "Downstream data written to attacker-controlled or attacker-readable destinations."
                        ],
                        "notes": "At this point the attacker has effectively gained initial access equivalent to deploying their own data-processing code under the victim’s cloud identities."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Core Substation transformation engine",
                    "internal/file",
                    "AWS AppConfig application & environments",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms",
                    "Secrets retrieval and interpolation"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG environment variable: Used by AWS Lambda Substation handlers and the GCP Cloud Function to locate configuration via internal/file.Get; accepts local paths as well as http://, https://, s3://, and gs:// URIs, so remote HTTP servers and S3/GCS buckets can be configuration sources.",
                    "GCP Cloud Function HTTP/CloudEvent endpoint '/': CloudEvent handler registered via funcframework at path '/' for SUBSTATION_FUNCTION_HANDLER=GCP_STORAGE; it receives CloudStorageEvent metadata, then downloads the referenced GCS object and streams its contents into a Substation pipeline, so any writer to those buckets can indirectly inject data."
                ],
                "data_accessed": [
                    "Complete Substation configuration documents controlling which data sources are read and which sinks are written to.",
                    "All data processed by Substation under the compromised configuration, including sensitive logs, telemetry, or state changes.",
                    "Secrets retrieved from AWS Secrets Manager or environment variables via utility_secret and interpolation, which can be embedded into outbound requests or cross-account writes."
                ],
                "preconditions_required": [
                    "Operations have chosen HTTP, S3, GCS, or AppConfig-hosted configuration sources for SUBSTATION_CONFIG rather than strictly local, immutable configs.",
                    "The attacker controls or has compromised the account, bucket, or HTTP service that hosts those configs, or can modify AppConfig profiles used by the Lambdas.",
                    "There is no strong integrity control over configs (for example, signatures enforced at runtime) beyond optional validation Lambdas, or the attacker can craft configs that pass validation."
                ],
                "constraints_encountered": [
                    "If runtime validation Lambda functions are configured via AppConfig and rigorously check configurations, attackers must craft configs that satisfy those checks, limiting the most egregious payloads.",
                    "Configs may be cached in warm Lambda environments, so changes might not take effect immediately; initial access may be delayed until cold starts or redeployments occur.",
                    "Strict change-management around config buckets or AppConfig environments (for example, limited write IAM roles, approval workflows) can reduce the likelihood of compromise but do not remove the technical possibility once those controls are bypassed."
                ],
                "evasion_considerations": [
                    "Introduce malicious behavior gradually (for example, adding small exfiltration steps alongside existing sinks) to avoid obvious behavior changes.",
                    "Preserve existing pipeline functionality so that operators do not immediately notice breakage or missing data.",
                    "If validation Lambdas exist, mirror the structure and naming patterns of prior configs while subtly changing sink destinations or adding auxiliary transforms."
                ],
                "resulting_access": "Execution-level control over Substation pipelines via compromised remote configuration sources, allowing an attacker to run arbitrary transform chains under the permissions of the associated Lambdas or Cloud Functions.",
                "comments": "Because Substation is entirely config-driven, controlling SUBSTATION_CONFIG is equivalent to deploying arbitrary workloads. The attacker’s crown jewels here are the full breadth of data flowing through the system and any AWS/GCP resources reachable from those runtimes’ IAM roles."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Accounts",
                "technique_stix_id": "attack-pattern--f232fa7a-025c-4d43-abc7-318e81a73d65",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Obtain valid cloud credentials (access keys, session tokens, or service account keys) for principals that have Substation-related data-plane or control-plane permissions, especially roles included in var.access or GCP service accounts used by Substation components.",
                        "related_capabilities": [
                            "S3 buckets for Substation data",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "SQS queues for buffered processing",
                            "SNS topics for notifications and autoscaling",
                            "DynamoDB tables for state and streaming change data",
                            "AWS Secrets Manager secrets",
                            "Substation Lambda functions (container-image Lambdas)",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "S3/Kinesis/DynamoDB/SQS/SNS/Secrets/Lambda/EventBridge access policies attached to roles in var.access, which define the effective interfaces for authenticated access to Substation data and operations [build/terraform/aws/s3/main.tf, build/terraform/aws/kinesis_data_stream/main.tf, build/terraform/aws/dynamodb/main.tf, build/terraform/aws/sqs/main.tf, build/terraform/aws/sns/main.tf, build/terraform/aws/secret/main.tf, build/terraform/aws/lambda/main.tf, build/terraform/aws/eventbridge/lambda/main.tf]."
                        ],
                        "related_data": [
                            "Access keys and tokens for IAM roles in var.access or equivalent GCP service accounts.",
                            "Policy documents granting read/write actions on Substation S3 buckets, Kinesis streams, DynamoDB tables, SQS queues, SNS topics, Secrets, and Lambda functions."
                        ],
                        "notes": "The credential theft or abuse step itself is outside this analysis; once obtained, these cloud accounts become the vector for initial access into Substation workloads."
                    },
                    {
                        "step_id": 2,
                        "description": "Enumerate accessible AWS and GCP resources using these credentials to identify which S3 buckets, Kinesis streams, SNS topics, SQS queues, DynamoDB tables, CloudWatch log groups, and Lambda functions participate in Substation pipelines.",
                        "related_capabilities": [
                            "S3 buckets for Substation data",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "SQS queues for buffered processing",
                            "SNS topics for notifications and autoscaling",
                            "DynamoDB tables for state and streaming change data",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "S3/Kinesis/DynamoDB/SQS/SNS/Secrets/Lambda/EventBridge access policies attached to roles in var.access, which define the effective interfaces for authenticated access to Substation data and operations [build/terraform/aws/s3/main.tf, build/terraform/aws/kinesis_data_stream/main.tf, build/terraform/aws/dynamodb/main.tf, build/terraform/aws/sqs/main.tf, build/terraform/aws/sns/main.tf, build/terraform/aws/secret/main.tf, build/terraform/aws/lambda/main.tf, build/terraform/aws/eventbridge/lambda/main.tf]."
                        ],
                        "related_data": [
                            "Resource ARNs for Substation S3 buckets, Kinesis streams, queues, topics, tables, and Lambdas.",
                            "Configuration metadata that links these resources into pipelines (for example, event source mappings, bucket notifications, or stream consumers)."
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Inject data into Substation by writing to ingestion surfaces the compromised account can access—for example, PutObject into S3 buckets that trigger Substation Lambdas, PutRecord/PutRecords into Kinesis streams, Publish to SNS topics, or SendMessage to SQS queues wired to Substation handlers.",
                        "related_capabilities": [
                            "S3 buckets for Substation data",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "SNS topics for notifications and autoscaling",
                            "SQS queues for buffered processing",
                            "DynamoDB tables for state and streaming change data",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "substation read --aws s3://bucket/key: CLI interface that reads objects from S3 over AWS credentials and feeds them into pipelines; any principal with PutObject on the referenced bucket/key can influence Substation input when this source is used.",
                            "Kinesis streams as ingestion sources: Substation's Kinesis handlers and CLI 'tap' consume records from configured streams; records may originate from API Gateway ingestion APIs, CloudWatch Logs destinations, or any principal with kinesis:PutRecord/PutRecords on the stream.",
                            "SNS topics and SQS queues as Lambda event sources: Substation Lambda handlers for SNS and SQS consume messages published by other AWS principals; any producer with sns:Publish or sqs:SendMessage on those resources can inject content into pipelines.",
                            "GCP Cloud Function HTTP/CloudEvent endpoint '/': CloudEvent handler registered via funcframework at path '/' for SUBSTATION_FUNCTION_HANDLER=GCP_STORAGE; it receives CloudStorageEvent metadata, then downloads the referenced GCS object and streams its contents into a Substation pipeline, so any writer to those buckets can indirectly inject data."
                        ],
                        "related_data": [
                            "S3 object contents and metadata in buckets used as ingestion sources for Substation Lambdas or CLI jobs.",
                            "Kinesis Data records written with attacker-controlled payloads and partition keys.",
                            "SNS/SQS message bodies and attributes delivered to Substation handlers.",
                            "GCS object contents in buckets that trigger the GCP Substation Function."
                        ],
                        "notes": "These actions use only the legitimate capabilities of the compromised cloud accounts; to Substation they appear as normal producer workloads."
                    },
                    {
                        "step_id": 4,
                        "description": "Optionally, directly invoke Substation Lambda functions using lambda:InvokeFunction or similar permissions granted to roles in var.access, bypassing API Gateway and any HTTP-layer controls.",
                        "related_capabilities": [
                            "Substation Lambda functions (container-image Lambdas)",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "S3/Kinesis/DynamoDB/SQS/SNS/Secrets/Lambda/EventBridge access policies attached to roles in var.access, which define the effective interfaces for authenticated access to Substation data and operations [build/terraform/aws/s3/main.tf, build/terraform/aws/kinesis_data_stream/main.tf, build/terraform/aws/dynamodb/main.tf, build/terraform/aws/sqs/main.tf, build/terraform/aws/sns/main.tf, build/terraform/aws/secret/main.tf, build/terraform/aws/lambda/main.tf, build/terraform/aws/eventbridge/lambda/main.tf]."
                        ],
                        "related_data": [
                            "Lambda invocation payloads crafted by the attacker to be processed by generic AWS_LAMBDA or API Gateway-style handlers."
                        ],
                        "notes": "This path is especially valuable if external HTTP entry points are locked down but IAM-based invocation is broadly granted to internal roles."
                    }
                ],
                "capabilities_used": [
                    "S3 buckets for Substation data",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "SNS topics for notifications and autoscaling",
                    "SQS queues for buffered processing",
                    "DynamoDB tables for state and streaming change data",
                    "AWS Secrets Manager secrets",
                    "AWS Lambda Substation event processors",
                    "Substation Lambda functions (container-image Lambdas)",
                    "GCP Cloud Storage Substation Function"
                ],
                "interfaces_used": [
                    "S3/Kinesis/DynamoDB/SQS/SNS/Secrets/Lambda/EventBridge access policies attached to roles in var.access, which define the effective interfaces for authenticated access to Substation data and operations [build/terraform/aws/s3/main.tf, build/terraform/aws/kinesis_data_stream/main.tf, build/terraform/aws/dynamodb/main.tf, build/terraform/aws/sqs/main.tf, build/terraform/aws/sns/main.tf, build/terraform/aws/secret/main.tf, build/terraform/aws/lambda/main.tf, build/terraform/aws/eventbridge/lambda/main.tf].",
                    "substation read --aws s3://bucket/key: CLI interface that reads objects from S3 over AWS credentials and feeds them into pipelines; any principal with PutObject on the referenced bucket/key can influence Substation input when this source is used.",
                    "Kinesis streams as ingestion sources: Substation's Kinesis handlers and CLI 'tap' consume records from configured streams; records may originate from API Gateway ingestion APIs, CloudWatch Logs destinations, or any principal with kinesis:PutRecord/PutRecords on the stream.",
                    "SNS topics and SQS queues as Lambda event sources: Substation Lambda handlers for SNS and SQS consume messages published by other AWS principals; any producer with sns:Publish or sqs:SendMessage on those resources can inject content into pipelines.",
                    "GCP Cloud Function HTTP/CloudEvent endpoint '/': CloudEvent handler registered via funcframework at path '/' for SUBSTATION_FUNCTION_HANDLER=GCP_STORAGE; it receives CloudStorageEvent metadata, then downloads the referenced GCS object and streams its contents into a Substation pipeline, so any writer to those buckets can indirectly inject data."
                ],
                "data_accessed": [
                    "All data written into Substation-managed S3 buckets, Kinesis streams, SQS queues, SNS topics, and DynamoDB tables using the compromised accounts.",
                    "Pipeline outputs and side effects resulting from attacker-supplied inputs on these ingestion surfaces.",
                    "Potentially, secrets or encrypted data if the compromised roles also have secretsmanager:GetSecretValue or kms:Decrypt on relevant KMS keys."
                ],
                "preconditions_required": [
                    "The attacker has valid AWS or GCP credentials for an account or role granted permissions via var.access or equivalent IAM bindings.",
                    "Those principals have data-plane permissions on resources actually wired into Substation pipelines (buckets, streams, queues, topics, tables) or lambda:InvokeFunction on Substation Lambdas.",
                    "Network connectivity from the attacker’s environment to the relevant cloud APIs (typically over the public internet)."
                ],
                "constraints_encountered": [
                    "IAM and KMS policies may limit which specific resources each compromised principal can access, constraining which pipelines can be influenced.",
                    "CloudTrail and equivalent audit logs will record these API calls; while not preventing access, they increase the chance of post-hoc detection.",
                    "Service quotas (for example, Kinesis throughput, S3 request limits, SQS/SNS rate limits) bound how much malicious or probing traffic can be generated before operational impact becomes obvious."
                ],
                "evasion_considerations": [
                    "Reuse existing producer identities and patterns (for example, from compromised microservices) so write activity appears consistent with prior behavior.",
                    "Keep injection volumes and schemas similar to legitimate data to avoid triggering schema validation failures or anomaly detectors.",
                    "Prefer ingestion paths that already aggregate data from many sources (for example, shared Kinesis streams) to blend in with background noise."
                ],
                "resulting_access": "Authenticated but unauthorized-from-a-business-perspective access to Substation’s data plane via compromised AWS or GCP accounts, enabling controlled injection of data into pipelines and direct invocation of Substation Lambdas under their configured IAM roles.",
                "comments": "These cloud accounts are high-value initial access points: they let an attacker behave exactly like a legitimate producer or internal caller, often with powerful access to sensitive telemetry and downstream stores. The crown jewels exposed are both the ingested data itself and any systems that Substation writes to using these roles."
            }
        ],
        "summary": "Substation’s primary initial access surfaces are its unauthenticated public HTTP APIs and its deep integration with cloud-native messaging and configuration services. The most direct external vector is the API Gateway \u001a Lambda proxy endpoint, which is configured with authorization = NONE and no resource policy, allowing any internet client to invoke a Substation Lambda and feed arbitrary payloads into its pipelines. A second public API Gateway fronts Kinesis PutRecord, providing a credential-less streaming ingestion path into Kinesis streams consumed by Substation. A powerful but often-overlooked vector is the CLI playground HTTP server: if exposed beyond localhost, it lets remote users execute arbitrary Substation configs and temporary environment-variable overrides using the host’s cloud credentials. Beyond these public-facing entry points, Substation environments rely heavily on trusted relationships and cloud accounts: cross-account CloudWatch Logs destinations allow external AWS accounts to inject log events into central Kinesis or Firehose streams; HTTP enrichment transforms trust external APIs whose responses can steer pipeline behavior; and SUBSTATION_CONFIG may be fetched from remote HTTP/S3/GCS/AppConfig sources, so compromise of those configuration hosts yields effective execution control over pipelines. Finally, any compromise of AWS or GCP accounts with Substation-related data-plane permissions (var.access roles, producer roles, or service accounts) enables authenticated injection into S3, Kinesis, SNS/SQS, DynamoDB, or direct Lambda invocation. Collectively, these vectors mean that initial access is most realistically achieved either via misconfigured public ingestion APIs or via abuse of trusted cloud identities and configuration supply chains."
    },
    "exfiltration": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Exfiltration Over Alternative Protocol",
                "technique_stix_id": "attack-pattern--a19e86f8-1c0a-4fea-8407-23b73d615776",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify a Substation pipeline that processes high-value data (for example, an AWS Lambda handler for Kinesis/DynamoDB/S3 events, the GCP Storage Function, or a long‑running CLI job) and determine where its SUBSTATION_CONFIG is loaded from (local file, S3, HTTP, or GCS).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "AWS Lambda Substation event processors (handlers for API Gateway, Kinesis, Firehose, DynamoDB Streams, S3, SNS, SQS, generic Lambda)",
                            "GCP Cloud Storage Substation Function (CloudEvent handler for SUBSTATION_FUNCTION_HANDLER=GCP_STORAGE)",
                            "CLI command: substation read [config] --file/--http/--aws s3://...",
                            "Configuration loading via SUBSTATION_CONFIG and internal/file.Get (local file, HTTP(S), S3, GCS)"
                        ],
                        "related_data": [
                            "Kinesis stream records",
                            "DynamoDB Streams change records",
                            "S3 and GCS object contents",
                            "SNS/SQS message bodies",
                            "Generic Lambda/API Gateway event payloads"
                        ],
                        "notes": "This step scopes which execution contexts and data types will be available for HTTP-based exfiltration."
                    },
                    {
                        "step_id": 2,
                        "description": "Gain the ability to modify or replace the Substation configuration used by that runtime (for example, editing the Jsonnet/JSON config in S3/GCS, changing SUBSTATION_CONFIG to point at an attacker-controlled HTTP URL, or updating hosted config in AppConfig).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "Configuration artifacts (Jsonnet/JSON Substation configs)",
                            "SUBSTATION_CONFIG environment variable",
                            "internal/file.Get for HTTP/S3/GCS-hosted configs",
                            "AppConfig \u001a Lambda configuration consumption"
                        ],
                        "related_data": [
                            "substation.Config (list of transform configs)",
                            "config.Config {Type, Settings}"
                        ],
                        "notes": "Substation behavior is entirely config-driven, so exfiltration is achieved by changing configuration rather than code."
                    },
                    {
                        "step_id": 3,
                        "description": "Modify the pipeline config to add HTTP transforms that send message content to an attacker-controlled HTTPS endpoint, for example by appending a send_http_post transform that batches messages and posts their full JSON bodies.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type: send_http_post (HTTP POST sink with batching and secret-interpolated URL/headers)",
                            "Optional transform types: enrich_http_get, enrich_http_post (can also send data in URLs/bodies during enrichment)",
                            "internal/http.Post (retryable HTTP client wrapper)"
                        ],
                        "related_data": [
                            "message.Message.data JSON payloads (full records from all upstream sources)",
                            "message metadata (bucket/key names, timestamps, ARNs, partition keys)",
                            "Any enriched fields populated earlier in the pipeline"
                        ],
                        "notes": "send_http_post is the most direct exfil sink; enrich_http_* can also leak data since request URLs/bodies may embed message fields."
                    },
                    {
                        "step_id": 4,
                        "description": "Optionally include a utility_secret transform and ${SECRET:ID} interpolation in the send_http_post URL or headers so that AWS Secrets Manager or environment-variable secrets are sent to the attacker endpoint as well.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Transform type: utility_secret",
                            "internal/secrets.Interpolate() with ${SECRET:ID} syntax",
                            "send_http_post headers and URL templates"
                        ],
                        "related_data": [
                            "Secret values from AWS Secrets Manager",
                            "Environment-variable secrets cached by internal/secrets",
                            "HTTP headers and URLs carrying embedded secrets"
                        ],
                        "notes": "This step turns the HTTP sink into a direct secret-exfiltration channel as well as a data exfil channel."
                    },
                    {
                        "step_id": 5,
                        "description": "Deploy or trigger the runtime so that it reloads the modified configuration (for example, by updating the S3 object backing SUBSTATION_CONFIG, publishing a new AppConfig version, or starting the CLI with the altered config).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Lambda cold start / config load via internal/file.Get",
                            "Cloud Function init and config load",
                            "CLI invocation: substation read ..."
                        ],
                        "related_data": [
                            "Runtime-resolved configuration (compiled Jsonnet/JSON)",
                            "Environment variables controlling handler selection"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 6,
                        "description": "As normal events arrive (from Kinesis, DynamoDB Streams, S3, GCS, SNS/SQS, API Gateway, or CLI sources), allow the pipeline to process them; the HTTP transforms will batch and send selected fields or entire messages over HTTPS to the attacker-controlled endpoint via the NAT gateway.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI",
                            "HTTP enrichment and sending transforms",
                            "VPC with public and private subnets, NAT, and Internet gateway"
                        ],
                        "related_interfaces": [
                            "Data flows: AWS Lambda event-based processing pipeline",
                            "Data flows: GCS ingestion pipeline",
                            "Data flows: CLI 'read' file/HTTP/S3 \u001a pipeline \u001a sink",
                            "VPC private subnets routed via NAT gateway to Internet gateway",
                            "internal/http client used by HTTP transforms"
                        ],
                        "related_data": [
                            "All message payloads handled by the targeted pipelines (potentially including PII, logs, transactions, or other business data)",
                            "Any secrets or KV-enriched fields previously injected into messages"
                        ],
                        "notes": "From the platform’s perspective this looks like a legitimate outbound HTTP call from a Lambda/Function/CLI process."
                    },
                    {
                        "step_id": 7,
                        "description": "Collect and store the exfiltrated data on the attacker-controlled HTTP service, optionally re-encrypting or forwarding it to other infrastructure.",
                        "related_capabilities": [],
                        "related_interfaces": [],
                        "related_data": [
                            "Batched JSON payloads and headers received from send_http_post/enrich_http_*"
                        ],
                        "notes": "This step is outside Substation but completes the exfiltration path."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "HTTP enrichment and sending transforms",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "Secrets retrieval and interpolation",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "Transform types: enrich_http_get, enrich_http_post, send_http_post",
                    "internal/http.Get and internal/http.Post HTTP client wrapper",
                    "SUBSTATION_CONFIG-driven configuration loading via internal/file.Get (local, HTTP, S3, GCS)",
                    "AWS Lambda handlers for API Gateway, Kinesis, Firehose, DynamoDB Streams, S3, SNS, SQS, generic Lambda",
                    "GCP Cloud Storage CloudEvent handler (SUBSTATION_FUNCTION_HANDLER=GCP_STORAGE)",
                    "CLI command: substation read [config] --file/--http/--aws s3://..."
                ],
                "data_accessed": [
                    "Message payloads and metadata derived from Kinesis streams, DynamoDB Streams, S3/GCS objects, SNS/SQS messages, Firehose records, and API Gateway/Lambda events",
                    "Secrets retrieved from AWS Secrets Manager or environment variables via utility_secret/internal/secrets",
                    "Any KV-enriched or HTTP-enriched fields added earlier in the pipeline"
                ],
                "preconditions_required": [
                    "Attacker can author, modify, or replace the Substation configuration used by at least one high-value pipeline (for example, control over Jsonnet/JSON configs in S3/GCS/HTTP or over AppConfig-hosted configuration).",
                    "The execution environment (Lambda, Cloud Function, CLI host) has outbound HTTPS connectivity; in AWS this is provided by private subnets with routes to a NAT gateway and Internet gateway.",
                    "The IAM role or credentials under which the pipeline runs have read access to the data sources whose contents are to be exfiltrated (e.g., S3, DynamoDB Streams, Kinesis, SNS/SQS).",
                    "DNS and TLS resolution for the attacker-controlled domain are not blocked by network egress controls or proxy configurations."
                ],
                "constraints_encountered": [
                    "AWS Organizations SCPs, VPC egress filters, or restrictive security groups (not visible in this repo) could block outbound connections to unknown domains, preventing HTTP-based exfiltration.",
                    "CloudTrail/VPC Flow Logs and Lambda/Cloud Function logs may reveal unusual external endpoints or traffic volumes; aggressive or high-volume exfiltration increases detection risk.",
                    "HTTP transforms use retryablehttp with sensible timeouts and size limits; extremely large payloads may be rejected or cause backpressure that shows up as errors/latency."
                ],
                "evasion_considerations": [
                    "Use HTTPS to common cloud or SaaS-looking domains and paths (e.g., analytics or logging service patterns) to blend with expected outbound traffic.",
                    "Throttle exfiltration by batching and rate-limiting send_http_post so traffic volume resembles normal enrichment or webhook patterns.",
                    "Embed exfiltration into existing HTTP enrichment transforms (enrich_http_get/enrich_http_post) that are expected in the pipeline, instead of adding obvious new sinks.",
                    "Avoid exfiltrating entire records; selectively send only high-value fields to reduce volume and anomaly scores."
                ],
                "comments": "This is the most straightforward and flexible exfiltration path: any data that reaches a Substation pipeline can be copied to an attacker-controlled HTTP(S) endpoint by configuration alone.",
                "data_exfiltrated": "Streaming copies of messages and optionally secrets from AWS/GCP-based Substation pipelines (events, files, logs, KV-enriched data) sent as HTTPS requests to attacker-controlled web services."
            },
            {
                "can_achieve": true,
                "technique_name": "Transfer Data to Cloud Account",
                "technique_stix_id": "attack-pattern--d4bdbdea-eaec-4071-b4f9-5105e12ea4b6",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Choose a pipeline that processes sensitive data (for example, Lambda pipelines consuming Kinesis/DynamoDB Streams/S3, the GCP Storage Function, or CLI-based batch jobs) and confirm it already runs under IAM/service-account credentials with broad AWS/GCP data-plane access.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI",
                            "Lambda \u001a encrypted data stores (S3, DynamoDB, Kinesis, SQS, SNS, Secrets)"
                        ],
                        "related_interfaces": [
                            "AWS Lambda event-based processing pipeline",
                            "GCS ingestion pipeline",
                            "CLI 'read' data flow (file/HTTP/S3 \u001a pipeline \u001a sink)"
                        ],
                        "related_data": [
                            "Records and objects from S3, DynamoDB, Kinesis, SQS/SNS, GCS, and other ingest sources"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "In an attacker-controlled AWS or GCP account, provision exfiltration targets such as S3 buckets, Kinesis or Firehose streams, or GCS buckets, and configure their resource policies or IAM roles to allow writes from the victim account (directly or via a dedicated cross-account role).",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "Amazon S3 bucket and bucket policy in attacker account",
                            "Amazon Kinesis Data Stream or Firehose delivery stream in attacker account",
                            "Google Cloud Storage bucket in attacker GCP project",
                            "AWS STS AssumeRole trust relationships"
                        ],
                        "related_data": [
                            "Cloud-resident exfil sinks (objects, stream records) in attacker-controlled accounts"
                        ],
                        "notes": "This uses standard cross-account access patterns (bucket policies, AssumeRole) outside of Substation itself."
                    },
                    {
                        "step_id": 3,
                        "description": "Modify the Substation configuration so that the targeted pipeline appends or replaces its final sinks with send_* transforms that point to these attacker-controlled resources (for example, set send_aws_s3.bucket to an S3 bucket ARN in the attacker account, or configure send_gcp_storage to write to an attacker GCS bucket).",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type: send_aws_s3",
                            "Transform type: send_aws_kinesis_data_stream",
                            "Transform type: send_aws_data_firehose",
                            "Transform type: send_gcp_storage",
                            "Transform type: send_aws_dynamodb_put/send_aws_sns/send_aws_sqs/send_aws_eventbridge/send_aws_lambda (as auxiliary exfil sinks)",
                            "substation.Config / config.Config settings for sink ARNs and bucket names"
                        ],
                        "related_data": [
                            "Per-message JSON payloads and metadata being written to attacker-controlled S3 objects, Kinesis/Firehose records, or GCS objects"
                        ],
                        "notes": "internal/config.NewAWS supports STS AssumeRole, enabling send_aws_* transforms to assume a cross-account role when necessary."
                    },
                    {
                        "step_id": 4,
                        "description": "If necessary, configure the AWS client settings in the Substation AWS config (e.g., AssumeRoleARN) so that sink transforms assume a role in the attacker account rather than using the default execution role.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "internal/config.NewAWS (AWS configuration helper with optional sts:AssumeRoleARN)",
                            "AWS STS AssumeRole APIs"
                        ],
                        "related_data": [
                            "Temporary AWS credentials for the attacker-account role used by sink transforms"
                        ],
                        "notes": "This step enables writing directly into resources that are not otherwise reachable from the victim’s default role."
                    },
                    {
                        "step_id": 5,
                        "description": "Deploy the updated configuration so that the Lambda/Function/CLI instances use the modified pipeline and continue to process production data normally while duplicating or redirecting it into the attacker-owned cloud resources.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Config reload via SUBSTATION_CONFIG/AppConfig/internal/file.Get",
                            "Runtime Substation.Transform execution over event batches"
                        ],
                        "related_data": [
                            "All future messages processed by the compromised pipelines"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 6,
                        "description": "In the attacker-controlled AWS/GCP account, consume the exfiltrated data from the configured S3/GCS buckets or Kinesis/Firehose streams using standard tools (SDKs, CLIs, analytics jobs).",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "Amazon S3 API: GetObject/ListObjects",
                            "Kinesis Data Streams/Firehose consumer APIs",
                            "GCS object read APIs"
                        ],
                        "related_data": [
                            "Full copies of streamed records and files originally processed inside the victim environment"
                        ],
                        "notes": "Because the exfil target is a normal cloud resource, defenders may only see cross-account writes in CloudTrail and billing."
                    }
                ],
                "capabilities_used": [
                    "AWS and GCP sink transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "Lambda \u001a encrypted data stores (S3, DynamoDB, Kinesis, SQS, SNS, Secrets)",
                    "internal/config.NewAWS (AWS configuration helper)",
                    "CloudWatch Logs destinations for centralized forwarding (for log-stream variants)"
                ],
                "interfaces_used": [
                    "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage",
                    "AWS SDK v2 data-plane APIs for S3, Kinesis, Firehose, DynamoDB, SNS, SQS, EventBridge, Lambda",
                    "GCP Storage client APIs for GCS buckets",
                    "internal/config.NewAWS with optional sts:AssumeRole support",
                    "Terraform IAM policies granting broad S3/Kinesis/DynamoDB access to roles in var.access"
                ],
                "data_accessed": [
                    "All message payloads handled by Substation pipelines attached to AWS/GCP sinks (ingested from S3, DynamoDB Streams, Kinesis, SQS/SNS, GCS, API Gateway, etc.)",
                    "Any additional enriched data (KV lookups, HTTP enrichment responses, derived metrics) included in messages before they reach the sink transforms",
                    "Potentially secrets or tokens that have been injected into messages earlier in the pipeline"
                ],
                "preconditions_required": [
                    "Attacker can modify or control the Substation configuration for at least one pipeline that processes sensitive data.",
                    "The execution role/service account used by the pipeline has sufficient rights to read the sensitive data to be exfiltrated.",
                    "Attacker controls or can create cloud resources (S3/GCS buckets, Kinesis/Firehose streams) in another account/project and configure resource policies or cross-account roles to accept writes from the victim account.",
                    "If KMS is used for encryption in the victim account, the attacker only needs decrypt rights to read existing data; writing new exfiltrated copies into their own account uses their own KMS keys."
                ],
                "constraints_encountered": [
                    "Cross-account writes require explicit trust: destination S3/Kinesis/Firehose/GCS resources must grant write access to the victim account or an assumable role; misconfigured or locked-down policies can block this path.",
                    "AWS Organizations SCPs or GCP organization policies may prohibit certain cross-account or cross-project roles or deny assumptions that would otherwise be possible.",
                    "High-volume or cross-region transfers may create noticeable CloudTrail, CloudWatch, and billing artifacts (unusual data transfer and storage growth) that can trigger detection.",
                    "Service-imposed limits (record size, batch size, request rates) restrict the maximum throughput and may require throttling or sharding of exfiltration jobs."
                ],
                "evasion_considerations": [
                    "Name attacker-controlled buckets/streams/projects to resemble legitimate backup, analytics, or DR destinations to blend into existing replication patterns.",
                    "Mirror existing object key or partitioning patterns (e.g., date-based prefixes, tenant IDs) so that exfiltrated data appears to be normal operational output.",
                    "Throttle exfiltration to stay within typical traffic and cost baselines for existing data pipelines.",
                    "Blend exfil with legitimate multi-account aggregation patterns (e.g., reuse the same Kinesis/Firehose destinations that already aggregate logs) to make detection harder."
                ],
                "comments": "This vector covers using Substation’s cloud sink transforms plus cross-account IAM to quietly stream or bulk-export data into attacker-controlled AWS/GCP accounts.",
                "data_exfiltrated": "Bulk and streaming data from Substation pipelines (records, files, events) continuously written into S3/GCS buckets and Kinesis/Firehose streams in attacker-controlled cloud accounts."
            },
            {
                "can_achieve": true,
                "technique_name": "Exfiltration Over Alternative Protocol",
                "technique_stix_id": "attack-pattern--a19e86f8-1c0a-4fea-8407-23b73d615776",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Target the public API Gateway REST API that proxies POST requests to a Substation Lambda using AWS_PROXY integration, noting that Terraform configures authorization as NONE and no resource policies by default, making it internet-accessible.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "HTTP \u001a API Gateway \u001a Lambda data flow",
                            "AWS Lambda handler mode AWS_API_GATEWAY"
                        ],
                        "related_data": [
                            "APIGatewayProxyRequest payloads (body, headers, path/query parameters)"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Obtain control over the Substation configuration used by the API Gateway-backed Lambda (for example by modifying the Jsonnet/JSON config in S3/HTTP referenced by SUBSTATION_CONFIG or updating an AppConfig profile).",
                        "related_capabilities": [
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable and internal/file.Get",
                            "AppConfig \u001a Lambda configuration consumption"
                        ],
                        "related_data": [
                            "Pipeline configuration describing transforms for AWS_API_GATEWAY handler"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Extend the pipeline so that, for each API invocation, it enriches message data with internal information (for example, DynamoDB KV lookups, HTTP calls to internal services, and secrets from Secrets Manager) and then shapes the final message.data so that it contains only the data the attacker wants to exfiltrate.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine",
                            "Lambda \u001a encrypted data stores (S3, DynamoDB, Kinesis, SQS, SNS, Secrets)"
                        ],
                        "related_interfaces": [
                            "Transform type: enrich_kv_store_item_get (DynamoDB-backed KV reads)",
                            "Transform types: enrich_http_get/enrich_http_post (HTTP calls to internal services)",
                            "Transform type: utility_secret + internal/secrets (Secrets Manager/environment-variable retrieval)",
                            "AWS DynamoDB Streams / KV table used as a repository",
                            "Any internal HTTP(S) APIs accessible from the Lambda VPC"
                        ],
                        "related_data": [
                            "Records from DynamoDB KV tables (e.g., user profiles, tokens, configuration entries)",
                            "Secrets from AWS Secrets Manager and environment variables",
                            "Responses from internal HTTP services (e.g., account data, internal APIs)"
                        ],
                        "notes": "The attacker can use request parameters/body as keys to dynamically select which internal records to fetch."
                    },
                    {
                        "step_id": 4,
                        "description": "Ensure the final transform chain leaves message.data as a JSON object that contains the enriched internal data and/or secrets (and optionally minimal echoes of the request), which the AWS_API_GATEWAY handler will serialize into the HTTP response body.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "cmd/aws/lambda/substation/api_gateway.go (handler that returns transformed messages as JSON array)",
                            "message.Message.data field used as response content"
                        ],
                        "related_data": [
                            "Aggregated JSON object containing selected internal fields and secrets"
                        ],
                        "notes": "By default the handler returns a JSON array of non-control messages; the attacker can design the pipeline to emit exactly one record per request if desired."
                    },
                    {
                        "step_id": 5,
                        "description": "From an external machine, send crafted HTTP POST requests to the public API Gateway endpoint, choosing body/parameters so that the pipeline’s KV and HTTP enrichments retrieve specific target records or secrets, and capture the JSON responses that contain the exfiltrated data.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)"
                        ],
                        "related_interfaces": [
                            "Internet-facing API Gateway POST method with authorization NONE",
                            "Lambda resource-based permissions allowing apigateway.amazonaws.com to invoke the function"
                        ],
                        "related_data": [
                            "HTTP responses containing transformed messages (with internal data/secrets embedded)"
                        ],
                        "notes": "Each API call acts as an interactive exfiltration query, returning selected internal data over HTTPS."
                    }
                ],
                "capabilities_used": [
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "KV store integration and distributed locking",
                    "HTTP enrichment and sending transforms",
                    "Secrets retrieval and interpolation",
                    "Lambda \u001a encrypted data stores (S3, DynamoDB, Kinesis, SQS, SNS, Secrets)"
                ],
                "interfaces_used": [
                    "Public HTTP APIs via API Gateway (Lambda proxy) with authorization NONE",
                    "AWS Lambda handler mode AWS_API_GATEWAY (cmd/aws/lambda/substation/api_gateway.go)",
                    "Transform types: enrich_kv_store_item_get, enrich_http_get, enrich_http_post, utility_secret",
                    "internal/secrets and internal/kv backends (DynamoDB and others)"
                ],
                "data_accessed": [
                    "KV data from DynamoDB or other KV backends (e.g., per-tenant state, configuration, cached user data)",
                    "Secrets from AWS Secrets Manager or environment variables exposed via utility_secret/internal/secrets",
                    "Data from internal HTTP(S) services queried via enrichment transforms",
                    "Original request payloads and headers (can be echoed back or used as selectors)"
                ],
                "preconditions_required": [
                    "API Gateway REST API remains reachable from the internet and is not protected by additional auth/WAF rules beyond what Terraform specifies (authorization = NONE).",
                    "Attacker can modify the Substation configuration for the Lambda that backs the API Gateway (e.g., control over the SUBSTATION_CONFIG S3 object/HTTP URL or AppConfig profile).",
                    "The Lambda execution role has the necessary read permissions for the internal data sources being targeted (DynamoDB, Secrets Manager, internal HTTP services, etc.).",
                    "The pipeline is allowed to return arbitrary JSON content to the client (no additional output filtering layer outside Substation)."
                ],
                "constraints_encountered": [
                    "API Gateway imposes payload size limits (e.g., 10 MB response), so each call cannot exfiltrate arbitrarily large datasets.",
                    "High-volume or systematic enumeration via the public API is visible in API Gateway metrics and logs and may be rate-limited or alerted on.",
                    "If operators later attach authorizers, WAF, or IP allow-lists to the API Gateway stage, unauthenticated or off-net callers may be blocked from invoking the exfiltration logic."
                ],
                "evasion_considerations": [
                    "Design the API pipeline to still provide plausible, business-looking responses so that casual inspection does not reveal that extra fields are being returned.",
                    "Throttle and randomize exfiltration requests to mimic normal client traffic patterns instead of performing rapid enumeration.",
                    "Exfiltrate narrow slices of data per call (e.g., one account or record) instead of bulk dumps to stay within normal response size and latency profiles."
                ],
                "comments": "Here the exfiltration channel is the legitimate API Gateway → Lambda response path: sensitive internal data pulled into messages by transforms is reflected directly to unauthenticated HTTP clients.",
                "data_exfiltrated": "Selected internal records (e.g., DynamoDB KV entries, secrets, internal HTTP API responses) returned as JSON in responses from public API Gateway endpoints."
            },
            {
                "can_achieve": true,
                "technique_name": "Exfiltration Over Alternative Protocol",
                "technique_stix_id": "attack-pattern--a19e86f8-1c0a-4fea-8407-23b73d615776",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain shell or job-execution access on a host where the Substation CLI is installed and configured with AWS/GCP credentials that can read high-value data sources (e.g., production Kinesis streams or S3 buckets).",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "cmd/substation CLI"
                        ],
                        "related_interfaces": [
                            "CLI command: substation read [config] --file/--http/--aws s3://bucket/key",
                            "CLI command: substation tap ... (Kinesis stream consumer)"
                        ],
                        "related_data": [
                            "Local files, HTTP(S) sources, and S3 objects accessible from the host",
                            "Kinesis stream records accessible via the host’s AWS credentials"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Author or obtain a Substation configuration that uses the CLI as an ingestion front-end (substation read or substation tap) and appends HTTP or cloud sink transforms to send ingested records to attacker-controlled destinations.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "Local ingestion and transformation CLI",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "CLI arguments selecting config path and source (file/HTTP/S3/Kinesis)",
                            "Transform types: send_http_post, send_aws_s3, send_aws_kinesis_data_stream, send_gcp_storage, etc."
                        ],
                        "related_data": [
                            "Configuration files specifying both ingestion source and sink transforms",
                            "All records read from the specified sources (Kinesis, S3, files, HTTP)"
                        ],
                        "notes": "The same config model used in serverless deployments applies to CLI runs."
                    },
                    {
                        "step_id": 3,
                        "description": "If desired, include utility_secret and secret interpolation so that environment-variable or Secrets Manager credentials on the CLI host are injected into outbound HTTP headers or messages and thereby exfiltrated along with the data.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Transform type: utility_secret",
                            "Interpolation syntax: ${SECRET:ID} used in HTTP headers/URLs or message fields"
                        ],
                        "related_data": [
                            "Secrets Manager values reachable from the CLI host’s IAM identity",
                            "Environment variables containing credentials on the host"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "Run substation read or substation tap with the malicious configuration. The CLI will continuously read from the specified sources (e.g., drain a Kinesis stream or S3 objects) and feed messages through the configured transforms, which forward content to the attacker’s HTTP endpoint or cloud storage/streams.",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "substation read pipeline from file/HTTP/S3 into configured transforms",
                            "substation tap pipeline from Kinesis into configured transforms"
                        ],
                        "related_data": [
                            "Full contents of targeted Kinesis streams",
                            "S3 objects and HTTP resources read by the CLI",
                            "Any attached metadata (e.g., S3 bucket/key, shard IDs, timestamps)"
                        ],
                        "notes": "This can be run interactively or as a scheduled/batch job from the compromised host."
                    },
                    {
                        "step_id": 5,
                        "description": "Receive and process the exfiltrated data from the attacker-controlled HTTP endpoint or cloud resources created specifically for this CLI-driven channel.",
                        "related_capabilities": [],
                        "related_interfaces": [],
                        "related_data": [
                            "Batched payloads or objects in attacker-controlled infrastructure containing copies of production data read via the CLI"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "Local ingestion and transformation CLI",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms",
                    "Secrets retrieval and interpolation"
                ],
                "interfaces_used": [
                    "CLI command: substation read [config] --file/--http/--aws s3://...",
                    "CLI command: substation tap ... (Kinesis consumer)",
                    "Transform types: send_http_post, send_aws_s3, send_aws_kinesis_data_stream, send_gcp_storage and related sinks",
                    "internal/file.Get for retrieving configs and input files"
                ],
                "data_accessed": [
                    "Any S3 objects, Kinesis streams, or other AWS resources accessible via the CLI host’s IAM identity as used by substation read/tap",
                    "Local files and HTTP(S) resources reachable from the host",
                    "Secrets available to utility_secret on that host (Secrets Manager + environment variables)"
                ],
                "preconditions_required": [
                    "Attacker has the ability to run the Substation CLI on a host with network egress and with credentials that can read the desired AWS/GCP resources.",
                    "The host is permitted to connect to attacker-controlled IPs/domains or to the attacker’s cloud accounts for sink writes.",
                    "Operational controls do not strictly limit or monitor use of substation read/tap for production data."
                ],
                "constraints_encountered": [
                    "Host-based monitoring (EDR, shell auditing) or IAM usage analytics may flag unusual use of substation tap or large bulk reads from Kinesis/S3.",
                    "Corporate egress proxies or firewalls may restrict outbound connections to unknown domains, limiting HTTP-based exfil from developer or CI environments.",
                    "The CLI’s performance, and thus exfil speed, is bounded by local CPU/IO and AWS service rate limits."
                ],
                "evasion_considerations": [
                    "Run CLI-based exfiltration from machines and accounts that are expected to perform bulk data processing (e.g., analytics or ETL hosts) to blend with normal patterns.",
                    "Throttle reads and writes, and avoid draining entire streams in one operation to reduce anomalies in CloudWatch metrics.",
                    "Use cloud sinks (e.g., an apparently legitimate S3 bucket or Kinesis stream) instead of direct HTTP exfil to blend into normal cloud operations."
                ],
                "comments": "This vector is especially relevant for insider threats or compromised developer/ops machines where the Substation CLI is routinely used against production data.",
                "data_exfiltrated": "Bulk copies of stream data, S3 objects, and other ingested content read via the Substation CLI and forwarded to attacker-controlled HTTP endpoints or cloud storage/streams."
            },
            {
                "can_achieve": true,
                "technique_name": "Transfer Data to Cloud Account",
                "technique_stix_id": "attack-pattern--d4bdbdea-eaec-4071-b4f9-5105e12ea4b6",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify which CloudWatch log groups in the environment contain sensitive Substation-related data (e.g., Lambda logs that include message contents, metrics, or debug output) and how they are subscribed to the CloudWatch Logs destination.",
                        "related_capabilities": [
                            "CloudWatch Logs groups and embedded metrics",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "aws_cloudwatch_log_subscription_filter.subscription_filter",
                            "aws_cloudwatch_log_destination.destination"
                        ],
                        "related_data": [
                            "Log events from Substation Lambda functions and other components forwarded via subscription filters"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Gain control over Terraform variables or AWS configuration that determine the CloudWatch Logs destination_arn so that it can be set to a Kinesis Data Stream or Firehose delivery stream in an attacker-controlled AWS account.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "Terraform module: build/terraform/aws/cloudwatch/destination/main.tf (destination_arn, account_ids, role/policy)",
                            "Logs destination IAM role assumed by logs.amazonaws.com"
                        ],
                        "related_data": [
                            "destination_arn referencing attacker-controlled Kinesis/Firehose",
                            "IAM role/policy permitting cross-account writes"
                        ],
                        "notes": "This requires administrative control over IaC or equivalent AWS permissions."
                    },
                    {
                        "step_id": 3,
                        "description": "Ensure or configure subscription filters so that target log groups (including Substation Lambda log groups) forward their events to the modified destination_arn, causing CloudWatch Logs to stream all selected log traffic into the attacker’s Kinesis/Firehose stream.",
                        "related_capabilities": [
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "aws_cloudwatch_log_subscription_filter.subscription_filter (var.config.log_groups, destination_arn)",
                            "logs:PutSubscriptionFilter permissions for relevant principals"
                        ],
                        "related_data": [
                            "All log events from subscribed log groups, including any embedded message contents and metrics"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "From the attacker-controlled AWS account, consume the forwarded log data from the Kinesis/Firehose destination, extracting any sensitive message payloads, secrets, or operational details that have been logged.",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "Kinesis Data Streams or Firehose consumer APIs in attacker account"
                        ],
                        "related_data": [
                            "Continuous stream of log events from victim account log groups"
                        ],
                        "notes": "This effectively turns the central log forwarding mechanism into a cross-account exfiltration pipeline."
                    }
                ],
                "capabilities_used": [
                    "CloudWatch Logs groups and embedded metrics",
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing"
                ],
                "interfaces_used": [
                    "aws_cloudwatch_log_destination.destination (log destination backed by Kinesis/Firehose)",
                    "aws_iam_role.destination assumed by logs.amazonaws.com",
                    "aws_cloudwatch_log_subscription_filter.subscription_filter for var.config.log_groups",
                    "Kinesis or Firehose stream referenced by destination_arn"
                ],
                "data_accessed": [
                    "Lambda stdout/stderr and EMF metrics emitted by Substation components, including any message data or configuration fragments logged at Info/Debug level",
                    "Any other application/system logs from log groups subscribed to the destination"
                ],
                "preconditions_required": [
                    "Attacker can change Terraform variables or AWS configuration to point destination_arn at a Kinesis/Firehose stream they control, or can compromise an existing cross-account destination account.",
                    "Substation or surrounding applications log sensitive information (e.g., portions of message payloads, IDs, configuration) to CloudWatch Logs.",
                    "CloudWatch Logs subscriptions are broad enough (or can be modified) to include the relevant log groups."
                ],
                "constraints_encountered": [
                    "If logging hygiene is strong (no sensitive payloads logged), this vector primarily reveals metadata rather than full records.",
                    "CloudWatch destination policies can be locked down to trusted accounts; if they do not permit the attacker’s account, reconfiguration may be blocked by governance.",
                    "Changes to log destinations and subscriptions are themselves visible in CloudTrail and may trigger change-management alerts."
                ],
                "evasion_considerations": [
                    "Preserve existing destinations and add an additional cross-account destination to avoid breaking monitoring, making changes less obvious.",
                    "Scope subscription filters narrowly to specific log groups or patterns to reduce volume and avoid immediate suspicion.",
                    "Time changes to log destinations to coincide with other legitimate maintenance events."
                ],
                "comments": "This vector leverages the built-in centralized logging and cross-account CloudWatch Logs forwarding to siphon any sensitive information that ends up in logs into an attacker-controlled AWS account.",
                "data_exfiltrated": "Substation and related application logs (including any embedded message content, IDs, and debugging information) continuously streamed into Kinesis/Firehose in an attacker-controlled AWS account."
            },
            {
                "can_achieve": false,
                "technique_name": "Traffic Duplication",
                "technique_stix_id": "attack-pattern--7c46b364-8496-4234-8a56-f7e6727e21e1",
                "method_steps": [],
                "capabilities_used": [],
                "interfaces_used": [],
                "data_accessed": [],
                "preconditions_required": [],
                "constraints_encountered": [],
                "evasion_considerations": [],
                "comments": "The Traffic Duplication technique in MITRE ATT&CK relies on network-level mirroring features such as AWS VPC Traffic Mirroring, GCP Packet Mirroring, or equivalent switch/router capabilities. The provided Terraform and application code for Substation do not define or assume any such traffic mirroring resources or hooks. All data movement is at the application/service layer (HTTP, AWS/GCP SDKs, CloudWatch Logs, etc.), not via network taps. Therefore, pure traffic-duplication-based exfiltration (e.g., passive packet capture of Substation traffic via mirroring) is out of scope for this application’s documented capabilities and would require separate infrastructure changes or compromises.",
                "data_exfiltrated": ""
            }
        ],
        "summary": "Exfiltration from Substation is realistically achievable along multiple paths, driven almost entirely by configuration:\n\n1) HTTP-based exfiltration via enrich_http_get/enrich_http_post/send_http_post allows any data that reaches a Substation pipeline (from AWS Lambdas, the GCP Function, or the CLI) to be POSTed to arbitrary external HTTPS endpoints, optionally including Secrets Manager or environment-variable secrets. This is the most flexible and lowest-friction vector.\n\n2) Cloud sink transforms (send_aws_s3, send_gcp_storage, send_aws_kinesis_data_stream, send_aws_data_firehose, and related send_aws_* sinks) can silently stream or bulk-export data into attacker-controlled AWS or GCP accounts by pointing them at cross-account buckets/streams or by using STS AssumeRole. This enables durable, high-volume transfer of data to external cloud accounts.\n\n3) Public API Gateway → Lambda proxy endpoints, configured with no authentication, can be turned into interactive exfiltration APIs. By altering the API Gateway Lambda’s Substation configuration to pull secrets, KV data, or internal HTTP responses into message payloads, those values can be reflected directly to any internet client as JSON responses.\n\n4) The Substation CLI (substation read/tap) can be abused from any host with suitable AWS/GCP credentials to drain S3 objects, Kinesis streams, and other sources, then forward them to external HTTP or cloud sinks. This is a powerful insider or developer/ops compromise vector.\n\n5) CloudWatch Logs destinations and subscription filters can be reconfigured so that Substation-related log groups stream their contents into attacker-controlled Kinesis or Firehose streams in another AWS account, leaking any sensitive data that is logged.\n\nNetwork-level traffic mirroring (Traffic Duplication) is not implemented in this codebase or Terraform, so that particular MITRE exfiltration technique is not achievable with the documented Substation capabilities. The main practical defenses against the feasible vectors are strict governance over who can modify Substation configs and Terraform, tight IAM and KMS scoping (especially for cross-account roles), disciplined logging that avoids embedding sensitive payloads, and outbound network controls/monitoring for unusual HTTP and cross-account cloud traffic."
    },
    "impact": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Data Destruction",
                "technique_stix_id": "attack-pattern--d45a3d09-b3cf-48f4-9f0f-f521ee5cb05c",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain the ability to modify or replace the SUBSTATION_CONFIG used by high‑value Substation Lambdas/Functions (for example, write access to the S3/GCS object or HTTP endpoint referenced by SUBSTATION_CONFIG, or control over the AppConfig configuration profile that stores the pipeline).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG loading via internal/file.Get (local disk, HTTP(S), S3, GCS) in AWS Lambda handlers, the GCP Function, and CLI",
                            "AppConfig → Lambda configuration consumption",
                            "CLI commands 'substation build', 'substation fmt', 'substation test', 'substation read' that operate on Jsonnet/JSON configs"
                        ],
                        "related_data": [
                            "Substation configuration artifacts (Jsonnet/JSON substation.Config and nested config.Config entries) stored in S3/GCS/HTTP or AppConfig",
                            "IAM roles and environment variables that point to these config locations"
                        ],
                        "notes": "This step assumes the attacker is already past initial access and has obtained credentials or control over a configuration distribution point."
                    },
                    {
                        "step_id": 2,
                        "description": "Edit the pipeline configuration to insert or modify HTTP enrichment transforms (enrich_http_get or enrich_http_post) so that for targeted messages they overwrite the entire message data with the HTTP response from an attacker‑controlled endpoint.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_http_get, enrich_http_post",
                            "Secrets interpolation syntax ${SECRET:ID} used in URLs/headers"
                        ],
                        "related_data": [
                            "Message payloads and metadata processed by the pipeline",
                            "HTTP URLs and headers (including secrets) configured for enrichment transforms"
                        ],
                        "notes": "The transforms explicitly support overwriting message data with the HTTP response; the attacker’s service can return arbitrary JSON that becomes the canonical message body."
                    },
                    {
                        "step_id": 3,
                        "description": "Host an external HTTP(S) service that returns attacker‑chosen but syntactically valid JSON for each enrichment request (for example, zeroing out financial amounts, rewriting identifiers, or injecting fabricated events) while maintaining the expected schema so downstream transforms do not fail.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Arbitrary external HTTP services called by Substation via internal/http"
                        ],
                        "related_data": [
                            "HTTP request bodies, query strings, and headers built from message fields and secrets",
                            "Responses returned by the attacker‑controlled HTTP service"
                        ],
                        "notes": "Keeping the schema and types valid avoids transform errors and makes corruption harder to detect in metrics/logs."
                    },
                    {
                        "step_id": 4,
                        "description": "Ensure that sink transforms (for example, send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_s3, send_gcp_storage) still run after the enrichment step so that corrupted messages are durably written into the organization’s data stores and log streams.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "Transform types: send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_s3, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage",
                            "AWS Lambda handlers for Kinesis, S3, DynamoDB Streams, SNS, SQS, API Gateway",
                            "GCP Cloud Storage Substation Function handler"
                        ],
                        "related_data": [
                            "DynamoDB table items written via send_aws_dynamodb_put",
                            "Kinesis and Firehose records written via send_aws_kinesis_data_stream/send_aws_data_firehose",
                            "S3 and GCS objects written via send_aws_s3/send_gcp_storage",
                            "SNS/SQS messages and EventBridge events carrying corrupted payloads"
                        ],
                        "notes": "From the perspective of downstream consumers, the corrupted payloads look like legitimate data because they flow through the normal sinks."
                    },
                    {
                        "step_id": 5,
                        "description": "Drive the corrupted pipeline on as much of the organization’s traffic as possible (for example, by letting normal API Gateway/Kinesis/S3/GCS events flow, or replaying historical data via 'substation read' or 'substation tap' using production credentials) so that existing data sets and logs are progressively overwritten or polluted with attacker‑supplied content.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "HTTP → API Gateway → Lambda ingestion endpoint",
                            "HTTP → API Gateway → Kinesis Data Stream ingestion endpoint",
                            "S3/SNS/SQS → Lambda S3 handlers",
                            "DynamoDB Streams → Lambda handler",
                            "GCS Storage events → GCP Cloud Function handler",
                            "CLI 'substation read' and 'substation tap' commands"
                        ],
                        "related_data": [
                            "Existing event streams in Kinesis and DynamoDB Streams",
                            "Historical files in S3/GCS reprocessed via CLI or storage‑triggered Lambdas",
                            "Centralized log streams in Kinesis/Firehose fed from CloudWatch Logs"
                        ],
                        "notes": "Over time, this can make forensic reconstruction or analytics impossible because the canonical stores contain attacker‑defined rather than original data."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "HTTP enrichment and sending transforms",
                    "AWS and GCP sink transforms",
                    "Secrets retrieval and interpolation",
                    "Configuration management and validation CLI"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG loading via internal/file.Get (local, HTTP, S3, GCS)",
                    "AppConfig → Lambda configuration consumption",
                    "Transform types: enrich_http_get, enrich_http_post",
                    "Transform types: send_aws_dynamodb_put, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_s3, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage",
                    "AWS Lambda handlers for API Gateway, Kinesis, S3, DynamoDB, SNS, SQS, Firehose, generic Lambda",
                    "GCP Cloud Storage Substation Function handler",
                    "CLI commands: substation read, substation test, substation tap",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Public HTTP APIs via API Gateway (direct to Kinesis)"
                ],
                "data_accessed": [
                    "message.Message payloads and metadata from all integrated sources (API Gateway, Kinesis, Firehose, DynamoDB Streams, S3, SNS, SQS, GCS)",
                    "DynamoDB tables for state and streaming change data",
                    "Kinesis Data Streams for high‑throughput ingestion",
                    "S3 buckets for Substation data",
                    "GCP Storage buckets used as inputs or sinks",
                    "SNS topics and SQS queues hosting notifications and events"
                ],
                "preconditions_required": [
                    "Attacker controls or can modify the configuration source referenced by SUBSTATION_CONFIG (for example, S3/GCS path, HTTP URL, or AppConfig profile) for one or more production pipelines.",
                    "Lambda/Function execution roles (or CLI credentials) have existing permissions to write to the targeted sinks (DynamoDB, Kinesis, S3, SQS, SNS, GCS); this is true for roles listed in var.access and for Substation Lambda roles defined in Terraform.",
                    "Network egress from the Lambda VPC/private subnets to the attacker‑controlled HTTP endpoint is allowed via NAT/Internet Gateway.",
                    "Operations or change management processes do not validate pipeline configs or restrict transform types (e.g., no code review or allow‑list preventing arbitrary HTTP enrichment."
                ],
                "constraints_encountered": [
                    "S3 buckets may optionally enforce COMPLIANCE object‑lock retention, which prevents modification or deletion of locked objects; corruption is then limited to new objects or unlocked prefixes.",
                    "DynamoDB tables must allow updates to the attributes being manipulated; if fine‑grained IAM is in place, some attributes could be write‑protected, limiting corruption to others.",
                    "If external HTTP endpoints are allow‑listed or egress‑restricted at the VPC or organization level (for example, via VPC endpoints and no Internet egress), the attacker’s HTTP enrichment endpoint must be reachable within those constraints.",
                    "Strong configuration governance (e.g., CI validation, code review, checksum validation for SUBSTATION_CONFIG) could detect or block obviously malicious transform changes, requiring the attacker to craft subtler, plausibly legitimate transformations."
                ],
                "evasion_considerations": [
                    "Keep the transformed payloads structurally valid and business‑plausible so that downstream systems continue functioning and monitoring based on error rates or schema validation does not immediately trigger alerts.",
                    "Stage changes gradually—start by corrupting low‑visibility fields or a subset of pipelines, then expand once it is clear that monitoring is weak.",
                    "Host the malicious HTTP enrichment endpoint on infrastructure that resembles legitimate internal services (naming, TLS certificates) to avoid suspicion in DNS/proxy logs.",
                    "Leverage existing utility_secret/Secrets Manager integration so that HTTP headers/URLs look like ordinary authenticated enrichment calls rather than hard‑coded attacker infrastructure in config files."
                ],
                "comments": "This vector is most dangerous when Substation sits directly on top of \"source of truth\" data stores or centralized log/analytics pipelines, since corruption propagates outward to many consumers and may be hard to roll back without good historical backups.",
                "impact_achieved": "Canonical streaming data, state, and logs stored in DynamoDB, Kinesis/Firehose, S3, GCS, SQS, and SNS can be silently and persistently overwritten with attacker‑controlled values, destroying data integrity and making accurate recovery or forensic analysis extremely difficult."
            },
            {
                "can_achieve": true,
                "technique_name": "Data Destruction",
                "technique_stix_id": "attack-pattern--d45a3d09-b3cf-48f4-9f0f-f521ee5cb05c",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify DynamoDB tables that act as KV backends or primary data sinks for Substation (from Terraform, config, or CloudWatch metrics) and confirm that TTL is enabled on the relevant attribute.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "AWS and GCP sink transforms",
                            "AWS Lambda Substation event processors",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_kv_store_item_set, enrich_kv_store_set_add, meta_kv_store_lock",
                            "Transform type: send_aws_dynamodb_put",
                            "DynamoDB table module in Terraform with optional TTL and streams"
                        ],
                        "related_data": [
                            "DynamoDB tables for state and streaming change data",
                            "KV keys and TTL attributes used for deduplication, locks, or application state"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Use control over SUBSTATION_CONFIG (or over a test config executed with production credentials via 'substation test' or 'substation read') to add or modify KV and/or DynamoDB sink transforms so they overwrite targeted items and set TTLs to very near the current time (or even in the past).",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_kv_store_item_set, enrich_kv_store_set_add",
                            "Transform type: send_aws_dynamodb_put",
                            "CLI commands 'substation read' and 'substation test'"
                        ],
                        "related_data": [
                            "TTL attributes on DynamoDB items",
                            "Values in state tables (e.g., dedup keys, workflow state, configuration-like KV entries)"
                        ],
                        "notes": "enrich_kv_store_item_set can derive TTL directly from message fields; the attacker can craft messages or transforms so this field is always in the near past/future, causing rapid expiry."
                    },
                    {
                        "step_id": 3,
                        "description": "Drive the destructive pipeline across all relevant keys—for example, by replaying historical input (files, Kinesis streams, or S3/GCS objects) through the modified pipeline or by waiting for normal traffic to touch each item and update its TTL and content.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Kinesis, DynamoDB Streams, S3, SNS, SQS, and GCS ingestion handlers",
                            "CLI 'substation tap' to read from Kinesis and 'substation read' to process stored data"
                        ],
                        "related_data": [
                            "Historical and live event streams feeding into the DynamoDB‑backed state tables",
                            "Existing DynamoDB items gradually overwritten or re‑TTL’d"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "Allow DynamoDB’s TTL process to asynchronously delete the now‑expired items, silently removing application state, dedup records, or log entries relied on for correctness or auditability.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "DynamoDB TTL mechanism configured via the table module"
                        ],
                        "related_data": [
                            "DynamoDB items whose TTL attribute has passed",
                            "Downstream consumers that rely on these items (e.g., via Streams or direct reads)"
                        ],
                        "notes": "The deletion is performed by DynamoDB itself; from the application’s perspective items simply disappear after some delay."
                    },
                    {
                        "step_id": 5,
                        "description": "Optionally, use enrich_kv_store_item_get or other reads to confirm that items (or their critical attributes) are gone or contain corrupted values, and adjust the destructive transforms to target additional key ranges or tables if needed.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Transform type: enrich_kv_store_item_get"
                        ],
                        "related_data": [
                            "Remaining KV state and items after TTL deletion",
                            "Verification reads of critical keys"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "KV store integration and distributed locking",
                    "AWS and GCP sink transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "Configuration management and validation CLI"
                ],
                "interfaces_used": [
                    "Transform types: enrich_kv_store_item_set, enrich_kv_store_set_add, enrich_kv_store_item_get, meta_kv_store_lock",
                    "Transform type: send_aws_dynamodb_put",
                    "AWS Lambda handlers for Kinesis, DynamoDB Streams, S3, SNS, SQS",
                    "GCP Cloud Storage Substation Function handler",
                    "CLI commands: substation read, substation test, substation tap",
                    "DynamoDB table module with TTL configuration"
                ],
                "data_accessed": [
                    "DynamoDB tables used as KV backends and as primary data stores",
                    "TTL attributes on items in those tables",
                    "Event streams and files that determine which keys are updated"
                ],
                "preconditions_required": [
                    "DynamoDB tables targeted for destruction must have TTL enabled on a known attribute; otherwise TTL‑based deletion will not occur.",
                    "The Substation execution role or CLI credentials must have dynamodb:BatchWriteItem/PutItem/UpdateItem permissions on the target tables (granted via var.access in Terraform).",
                    "The attacker must control pipeline configuration or be able to execute arbitrary configs with production credentials (e.g., via CI/CD, misused 'substation test', or compromised Lambda config)."
                ],
                "constraints_encountered": [
                    "TTL deletions in DynamoDB are asynchronous and may take hours to complete; operators with strong monitoring may notice anomalies in counts or state before all data is removed.",
                    "Point‑in‑time recovery and backups, if enabled on the DynamoDB tables, can allow restoration, though this is operationally expensive and may be delayed if the attack also affects observability.",
                    "Fine‑grained IAM on DynamoDB tables (deny updates to TTL or critical attributes) would prevent this technique from affecting protected keys."
                ],
                "evasion_considerations": [
                    "Set TTLs to a moderate offset (for example, days instead of immediate expiry) so that items disappear gradually and the change looks like an aggressive retention policy rather than an obvious attack.",
                    "Modify only specific partitions or key prefixes at first to test operator visibility, then widen scope if no alarms trigger.",
                    "Keep transform and config changes small and embedded within otherwise legitimate pipelines to avoid standing out in config reviews."
                ],
                "comments": "Because KV and TTL semantics are used for idempotency, deduplication, and workflow state, destroying this data can cause subtle but severe application‑level inconsistencies and permanently remove evidence of past operations.",
                "impact_achieved": "Critical DynamoDB‑backed state and log‑like records can be overwritten and given very short TTLs so that DynamoDB’s own expiry mechanism deletes them, resulting in permanent loss of state, broken idempotency, and gaps in audit trails."
            },
            {
                "can_achieve": true,
                "technique_name": "Endpoint Denial of Service",
                "technique_stix_id": "attack-pattern--c675646d-e204-4aa8-978d-e3d6d65885c4",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Control or compromise an AWS account ID that is included in var.config.account_ids for the central CloudWatch Logs destination, or wait until such an account is onboarded with broad log publishing rights.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "aws_cloudwatch_log_destination.destination (central destination_arn)",
                            "Destination policy allowing logs:PutSubscriptionFilter from accounts in var.config.account_ids"
                        ],
                        "related_data": [
                            "List of allowed external AWS account IDs (var.config.account_ids)",
                            "CloudWatch log groups within the attacker‑controlled account"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "In the attacker‑controlled account, create or select one or more very noisy log groups (for example, attach the log group to a Lambda or application that emits large log volumes, or deliberately log at a very high rate).",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs APIs: logs:CreateLogGroup, logs:CreateLogStream, logs:PutLogEvents"
                        ],
                        "related_data": [
                            "High‑volume log events generated in the attacker account"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Use logs:PutSubscriptionFilter in the attacker account to attach the noisy log groups to the victim’s central CloudWatch Logs destination ARN, causing all log events to be streamed into the victim’s Kinesis or Firehose destination via the destination role.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs API: logs:PutSubscriptionFilter targeting aws_cloudwatch_log_destination.destination",
                            "STS:AssumeRole for logs.amazonaws.com into the destination role substation-cloudwatch-dest-*"
                        ],
                        "related_data": [
                            "Subscription filter configurations in the attacker account",
                            "Log events forwarded into the victim’s Kinesis/Firehose destination_arn"
                        ],
                        "notes": "The destination policy is intentionally broad to support cross‑account log aggregation; abused here it becomes an untrusted ingestion path."
                    },
                    {
                        "step_id": 4,
                        "description": "Sustain or increase the log emission rate so that the central Kinesis stream or Firehose delivery stream (destination_arn) becomes saturated, causing increased latency, throttling, or failures for downstream Substation consumers and log analytics pipelines.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs → Destination → Kinesis/Firehose data flow",
                            "Kinesis consumer Lambdas or Firehose delivery to downstream systems"
                        ],
                        "related_data": [
                            "Central logging Kinesis stream or Firehose delivery stream",
                            "Downstream Substation pipelines that treat this stream as input"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 5,
                        "description": "Optionally, interleave high‑volume log flooding with crafted log contents that look syntactically similar to legitimate logs, making it harder for defenders to distinguish attack traffic from normal high‑volume workloads.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "Same as previous steps"
                        ],
                        "related_data": [
                            "Mixture of legitimate‑looking and clearly malicious log lines"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "AWS Lambda Substation event processors"
                ],
                "interfaces_used": [
                    "aws_cloudwatch_log_destination.destination and its resource policy",
                    "aws_cloudwatch_log_subscription_filter.subscription_filter",
                    "CloudWatch Logs APIs: logs:PutSubscriptionFilter, logs:PutLogEvents",
                    "Kinesis Data Stream or Firehose destination_arn used for central logging",
                    "Substation Lambdas or other consumers reading from the logging stream"
                ],
                "data_accessed": [
                    "Central Kinesis Data Streams or Firehose delivery streams that aggregate logs",
                    "CloudWatch log events from both internal and external accounts",
                    "Substation message payloads derived from centralized log streams (when they are used as pipeline inputs)"
                ],
                "preconditions_required": [
                    "The attacker’s AWS account ID must be included in var.config.account_ids for the CloudWatch Logs destination, and principals in that account must have permission to create log groups and PutSubscriptionFilter to the destination.",
                    "The destination_arn must be a Kinesis stream or Firehose delivery stream whose capacity can be impacted by high write volume.",
                    "Downstream consumers (including any Substation pipelines) rely on this stream for timely log processing or analytics."
                ],
                "constraints_encountered": [
                    "CloudWatch Logs and Kinesis/Firehose impose service limits and throttling, which may cap the maximum flood rate but still significantly degrade performance for legitimate traffic.",
                    "Operators can disable or modify the destination policy or individual subscription filters to cut off a noisy external account once the abuse is detected.",
                    "If the destination is Firehose configured with robust buffering and scalable targets (e.g., S3), it may absorb more flooding before visible degradation, partially mitigating impact."
                ],
                "evasion_considerations": [
                    "Shape log traffic to resemble a legitimate but high‑traffic workload (e.g., microservice access logs) to reduce suspicion.",
                    "Use multiple log groups and varied filter patterns in the attacker account to distribute the flood and make incident response harder.",
                    "Ramp up volume gradually to test thresholds and monitoring before pushing the stream into a degraded state."
                ],
                "comments": "This vector leverages an explicitly supported cross‑account logging feature to turn many external accounts into untrusted producers that can overwhelm the victim’s central logging stream, impacting observability and any pipelines that depend on that stream.",
                "impact_achieved": "The central Kinesis/Firehose logging stream and any downstream Substation or analytics pipelines become overloaded, causing delays, throttling, or failures in log ingestion and processing, and effectively denying timely logging services to legitimate workloads."
            },
            {
                "can_achieve": true,
                "technique_name": "Application Exhaustion Flood",
                "technique_stix_id": "attack-pattern--18cffc21-3260-437e-80e4-4ab8bf2ba5e9",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Discover the public API Gateway endpoints fronting Substation, using documentation, DNS enumeration, or scanning, focusing on POST methods configured with authorization = NONE for Lambda proxy and Kinesis PutRecord integrations.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)"
                        ],
                        "related_interfaces": [
                            "API Gateway REST API (Lambda proxy) POST method with AWS_PROXY integration",
                            "API Gateway REST API (direct Kinesis) POST method with Kinesis PutRecord integration"
                        ],
                        "related_data": [
                            "API Gateway invoke URLs and stage names",
                            "Method configuration showing authorization = NONE"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "For the Lambda‑proxy API, send a high rate of large, complex HTTP POST requests whose bodies are valid JSON but designed to be computationally expensive to process (for example, deeply nested structures, many records per request) so that the Substation Lambda does more work per invocation.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "HTTP → API Gateway → Lambda data flow",
                            "AWS_API_GATEWAY Lambda handler in cmd/aws/lambda/substation/api_gateway.go"
                        ],
                        "related_data": [
                            "APIGatewayProxyRequest events",
                            "message.Message batches created from HTTP bodies"
                        ],
                        "notes": "The attacker does not need to know the exact transforms; simply increasing volume and per‑request size is enough to stress the pipeline."
                    },
                    {
                        "step_id": 3,
                        "description": "If the configured pipeline includes heavy transforms (HTTP enrichments, KV store access, send_* sinks), the attacker’s high‑volume requests cause a fan‑out of downstream AWS and HTTP calls, consuming Lambda CPU time, memory, and I/O, and increasing CloudWatch Logs and metrics volume.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms",
                            "Metrics and observability transforms"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_http_get, enrich_http_post, send_http_post",
                            "Transform types: send_aws_kinesis_data_stream, send_aws_s3, send_aws_dynamodb_put, send_aws_sqs, send_aws_sns, send_aws_eventbridge, send_aws_lambda",
                            "internal/http HTTP client wrapper",
                            "internal/metrics/aws_cloudwatch_embedded_metrics"
                        ],
                        "related_data": [
                            "Downstream Kinesis records, S3 objects, DynamoDB writes, SQS/SNS messages generated as side effects",
                            "CloudWatch Logs events and EMF metrics from the overloaded Lambdas"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "In parallel, send high‑volume POST requests to the Kinesis‑integrated API so that API Gateway repeatedly invokes PutRecord and injects attacker‑chosen records into the target Kinesis stream, consuming shard throughput and increasing work for any Substation consumers processing that stream.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "API Gateway → Kinesis PutRecord integration",
                            "Kinesis Data Streams module used for ingestion"
                        ],
                        "related_data": [
                            "Kinesis records derived from HTTP POST bodies",
                            "Shard throughput and iterator backlogs"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 5,
                        "description": "Sustain or burst these request patterns until Lambda concurrency limits, API Gateway rate limits, or Kinesis shard capacity are reached, causing throttling, elevated error rates, and significant latency for legitimate clients and downstream processors.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "CloudWatch Logs groups and embedded metrics"
                        ],
                        "related_interfaces": [
                            "Lambda concurrency management (implicit)",
                            "Kinesis PutRecord/PutRecords APIs and stream limits",
                            "CloudWatch Logs subscription to central destinations"
                        ],
                        "related_data": [
                            "5xx/429 responses from API Gateway",
                            "ProvisionedThroughputExceeded metrics on Kinesis",
                            "Increased Lambda error and duration metrics"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Public HTTP APIs via API Gateway (direct to Kinesis)",
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "HTTP enrichment and sending transforms",
                    "AWS and GCP sink transforms",
                    "Metrics and observability transforms",
                    "Kinesis Data Streams for high-throughput ingestion"
                ],
                "interfaces_used": [
                    "API Gateway REST API (Lambda proxy) POST method with authorization = NONE",
                    "API Gateway REST API (direct Kinesis) POST method with authorization = NONE",
                    "AWS Lambda AWS_API_GATEWAY handler",
                    "Kinesis PutRecord integration from API Gateway",
                    "Transform types: enrich_http_get, enrich_http_post, send_http_post, send_aws_kinesis_data_stream, send_aws_s3, send_aws_dynamodb_put, send_aws_sqs, send_aws_sns, send_aws_eventbridge, send_aws_lambda",
                    "CloudWatch Logs groups and EMF metrics for Substation Lambdas"
                ],
                "data_accessed": [
                    "HTTP request bodies and headers from arbitrary external clients",
                    "Kinesis Data Streams used for ingestion",
                    "CloudWatch Logs and metrics generated by high‑volume Lambda executions"
                ],
                "preconditions_required": [
                    "The API Gateway methods remain configured with authorization = NONE and without WAF/authorizers or strict throttling/usage plans at the edge.",
                    "The Lambda proxy and Kinesis ingestion APIs are reachable from the internet (no private integrations or IP‑restricted resource policies).",
                    "Substation Lambdas have pipelines that perform non‑trivial work (transforms and sink writes) so that each request consumes meaningful compute resources."
                ],
                "constraints_encountered": [
                    "API Gateway and Lambda impose account‑level and per‑resource throttling which eventually limit the peak attack rate, but still allow substantial impact before limits are reached.",
                    "If operators have layered on WAF, IP allow‑lists, or authentication outside this Terraform, the attacker must first bypass or defeat those controls.",
                    "Kinesis shards have fixed throughput; once saturated, PutRecord will be throttled, constraining further amplification via that path but still denying service to legitimate producers."
                ],
                "evasion_considerations": [
                    "Mimic legitimate client behavior (user agents, request patterns, payload shapes) to make the attack blend in with normal traffic bursts.",
                    "Use many distributed source IPs and moderate per‑IP rates to avoid simple IP‑based blocking or per‑client throttling.",
                    "Slow‑roll the attack, gradually increasing volume to identify thresholds and operator response, then maintain a level that keeps the service degraded but not obviously down."
                ],
                "comments": "This vector is particularly potent because Terraform explicitly configures the APIs as unauthenticated, making Substation Lambdas and Kinesis streams directly reachable from the internet without additional protections in this codebase.",
                "impact_achieved": "High request and data volumes driven through public API Gateway endpoints exhaust Lambda, Kinesis, and downstream service capacity, causing elevated error rates, timeouts, and throttling for legitimate clients and degrading the availability of data ingestion and processing pipelines."
            },
            {
                "can_achieve": true,
                "technique_name": "Endpoint Denial of Service",
                "technique_stix_id": "attack-pattern--c675646d-e204-4aa8-978d-e3d6d65885c4",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise or obtain credentials for a role in var.access that has the substation-kinesis-* policy, or compromise the dedicated Kinesis autoscaling Lambda execution role, which carries Kinesis UpdateShardCount and CloudWatch alarm permissions.",
                        "related_capabilities": [
                            "Kinesis autoscaling controller",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "IAM access policy attached to roles in var.access for Kinesis and CloudWatch",
                            "Autoscale Lambda handler for events.SNSEvent"
                        ],
                        "related_data": [
                            "IAM policies granting kinesis:UpdateShardCount and cloudwatch:PutMetricAlarm/SetAlarmState",
                            "Names and ARNs of Kinesis streams used by Substation"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Use Kinesis APIs (UpdateShardCount) via the compromised role to aggressively scale down shard counts for critical streams feeding Substation, staying within tag‑configured bounds (MinimumShards/MaximumShards) to appear semi‑legitimate but significantly reducing throughput.",
                        "related_capabilities": [
                            "Kinesis autoscaling controller",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "Kinesis API: UpdateShardCount on aws_kinesis_stream.stream",
                            "Kinesis Describe* APIs to discover current shard layout"
                        ],
                        "related_data": [
                            "Shard counts and shard IDs for ingestion streams",
                            "Stream tags including MinimumShards and MaximumShards"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 3,
                        "description": "Modify or overwrite the CloudWatch autoscaling alarms on those streams using cloudwatch:PutMetricAlarm so that thresholds are set too high, actions are removed or changed, or treat_missing_data is altered, effectively disabling automatic correction and masking abnormal utilization.",
                        "related_capabilities": [
                            "Kinesis autoscaling controller",
                            "CloudWatch metric alarms for Kinesis auto-scaling"
                        ],
                        "related_interfaces": [
                            "CloudWatch APIs: PutMetricAlarm and SetAlarmState on Kinesis autoscaling alarms"
                        ],
                        "related_data": [
                            "Alarm configurations (thresholds, evaluation periods, actions) for Kinesis utilization metrics",
                            "SNS topics used for autoscaling notifications"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "Optionally, use cloudwatch:SetAlarmState and/or PutMetricData to force alarms into OK or misleading states or to inject synthetic metrics that hide the fact that streams are saturated after the shard reduction.",
                        "related_capabilities": [
                            "Kinesis autoscaling controller"
                        ],
                        "related_interfaces": [
                            "CloudWatch APIs: SetAlarmState, PutMetricData"
                        ],
                        "related_data": [
                            "Autoscaling alarm state history and metric time series"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 5,
                        "description": "Generate or rely on normal or increased production load (including traffic from public APIs or CloudWatch Logs destinations) so that the down‑scaled streams become saturated, leading to throttled PutRecord/PutRecords calls and large consumer backlogs that delay or drop legitimate events.",
                        "related_capabilities": [
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "API Gateway → Kinesis PutRecord integration",
                            "CloudWatch Logs → Destination → Kinesis data flow",
                            "Kinesis consumer Lambdas for Substation ingestion"
                        ],
                        "related_data": [
                            "Kinesis IncomingBytes/IncomingRecords and throttling metrics",
                            "Consumer iterator age and backlog metrics"
                        ],
                        "notes": null
                    }
                ],
                "capabilities_used": [
                    "Kinesis autoscaling controller",
                    "Kinesis Data Streams for high-throughput ingestion",
                    "CloudWatch metric alarms for Kinesis auto-scaling",
                    "Public HTTP APIs via API Gateway (direct to Kinesis)",
                    "CloudWatch Logs destinations for centralized forwarding",
                    "AWS Lambda Substation event processors"
                ],
                "interfaces_used": [
                    "Kinesis UpdateShardCount, DescribeStream*, ListShards APIs",
                    "CloudWatch PutMetricAlarm, SetAlarmState, PutMetricData APIs on autoscaling alarms",
                    "API Gateway REST API (direct Kinesis) POST method",
                    "CloudWatch Logs destination and subscription filters feeding the same streams",
                    "Substation Kinesis consumer Lambdas"
                ],
                "data_accessed": [
                    "Kinesis stream configurations (names, shard counts, tags)",
                    "CloudWatch alarm definitions and metric data for Kinesis utilization",
                    "Records from API Gateway, CloudWatch Logs, and other producers feeding the streams"
                ],
                "preconditions_required": [
                    "An IAM role with Kinesis UpdateShardCount and CloudWatch alarm permissions (as defined in the Kinesis module) must be compromised or misused.",
                    "Target Kinesis streams must underpin critical Substation‑based ingestion or logging pipelines so that capacity reductions have real impact.",
                    "Autoscaling must be relied upon to maintain correct capacity under varying loads; if capacity is statically over‑provisioned, reduction may be needed to induce impact."
                ],
                "constraints_encountered": [
                    "UpdateShardCount has AWS‑imposed limits on scaling frequency and direction; rapid oscillation may be constrained, though steady under‑provisioning is still feasible.",
                    "Operators may have out‑of‑band monitoring on Kinesis shard counts and alarm configurations that could detect sudden changes.",
                    "If producers implement robust retry logic and back‑pressure handling, some data may eventually be ingested despite throttling, reducing but not eliminating impact."
                ],
                "evasion_considerations": [
                    "Adjust shard counts and alarm thresholds gradually over time rather than in a single drastic change to blend in with normal autoscaling adjustments.",
                    "Maintain alarm names and basic structures, only tweaking thresholds and actions to avoid obvious “disabled alarm” signatures.",
                    "Coordinate with log flooding or API‑driven load (from other vectors) so that saturation looks like organic growth rather than deliberate under‑provisioning."
                ],
                "comments": "This vector weaponizes the legitimate autoscaling and monitoring configuration for Kinesis streams, turning a resilience feature into a lever for coordinated degradation of streaming availability and visibility.",
                "impact_achieved": "By shrinking shard capacity and sabotaging autoscaling alarms, critical Kinesis streams experience sustained throttling and consumer backlogs, delaying or dropping legitimate events while operators receive little or misleading telemetry about the degraded state."
            },
            {
                "can_achieve": true,
                "technique_name": "Resource Hijacking",
                "technique_stix_id": "attack-pattern--cd25c1b4-935c-4f0e-ba8d-552f28bc4783",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Either (a) gain control over SUBSTATION_CONFIG for one or more high‑volume pipelines, or (b) leverage the unauthenticated public API Gateway endpoints to drive high rates of arbitrary input into existing pipelines.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG loading via internal/file.Get",
                            "API Gateway REST APIs with authorization = NONE",
                            "AWS Lambda handlers for API Gateway and Kinesis"
                        ],
                        "related_data": [
                            "Pipeline configurations and entrypoint URLs",
                            "Event payloads accepted from external clients"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Configure or select pipelines that maximize external work per message—for example, add multiple enrich_http_get/post and send_http_post transforms that call attacker‑controlled or third‑party HTTP APIs, and enable send_aws_lambda or other send_* transforms to fan out work to additional AWS services.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_http_get, enrich_http_post, send_http_post",
                            "Transform types: send_aws_lambda, send_aws_kinesis_data_stream, send_aws_sqs, send_aws_sns, send_aws_eventbridge"
                        ],
                        "related_data": [
                            "HTTP requests to attacker‑controlled or third‑party services",
                            "Batched payloads used to invoke other Lambdas or services"
                        ],
                        "notes": "Even if these calls are not business‑justified, they will execute as long as the config is deployed and the pipeline is invoked."
                    },
                    {
                        "step_id": 3,
                        "description": "Drive large volumes of inputs (via public APIs, Kinesis, or S3/GCS ingestion) whose processing triggers significant Lambda CPU time, network egress (HTTP calls, Kinesis writes), and downstream service utilization, effectively converting the victim’s Substation environment into an on‑demand compute and messaging engine for the attacker’s chosen traffic patterns.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)"
                        ],
                        "related_interfaces": [
                            "HTTP → API Gateway → Lambda",
                            "HTTP → API Gateway → Kinesis",
                            "S3/GCS → storage‑triggered functions",
                            "Kinesis/DynamoDB Streams → Lambda"
                        ],
                        "related_data": [
                            "Lambda execution time/concurrency",
                            "Kinesis/SQS/SNS traffic volumes",
                            "Outbound HTTP traffic volume via NAT/IGW"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 4,
                        "description": "Use attacker‑controlled HTTP endpoints as proxies or task sinks—for example, treat Substation as a high‑volume HTTP client that repeatedly sends data to proxyware or other monetizable services, or that participates in reflection/amplification traffic patterns on behalf of the attacker.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Transform type: send_http_post to attacker‑controlled URLs",
                            "internal/http retryable HTTP client"
                        ],
                        "related_data": [
                            "High‑volume HTTP payloads sent to attacker‑selected endpoints"
                        ],
                        "notes": "While coordination with external services is required for actual monetization, from the victim’s perspective this is unauthorized consumption of compute and bandwidth."
                    }
                ],
                "capabilities_used": [
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Public HTTP APIs via API Gateway (Lambda proxy)",
                    "Public HTTP APIs via API Gateway (direct to Kinesis)",
                    "HTTP enrichment and sending transforms",
                    "AWS and GCP sink transforms"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG via internal/file.Get",
                    "API Gateway REST APIs (Lambda proxy and Kinesis) with authorization = NONE",
                    "AWS Lambda handlers for API Gateway, Kinesis, S3, DynamoDB, SNS, SQS",
                    "GCP Cloud Storage Function handler",
                    "Transform types: enrich_http_get, enrich_http_post, send_http_post, send_aws_lambda, send_aws_kinesis_data_stream, send_aws_sqs, send_aws_sns, send_aws_eventbridge"
                ],
                "data_accessed": [
                    "Lambda compute time and concurrency allocation",
                    "Network egress from private subnets via NAT/Internet Gateway",
                    "Throughput quotas on Kinesis, SQS, SNS, and other AWS services used as sinks"
                ],
                "preconditions_required": [
                    "Substation Lambdas and Functions must be allowed outbound internet access (via NAT/IGW) and to the AWS services being abused (as granted by var.access and lambda IAM policies).",
                    "Either attacker control over pipeline configuration or the presence of public, unauthenticated ingestion endpoints is required to drive workloads at will.",
                    "No strict egress filtering or hostname allow‑listing is in place to block outbound HTTP calls to attacker‑controlled endpoints."
                ],
                "constraints_encountered": [
                    "AWS account‑level service quotas for Lambda, Kinesis, and other services cap the maximum hijacked resource usage but still allow significant consumption before limits are hit.",
                    "Network egress and Lambda usage are billable; anomalous cost spikes may trigger billing or operational alerts.",
                    "If outbound HTTP is restricted to a small set of internal domains, the attacker would need to compromise or piggyback on those domains rather than calling arbitrary endpoints."
                ],
                "evasion_considerations": [
                    "Blend hijacked workloads into existing traffic patterns, for example by calling attacker infrastructure at domains that resemble legitimate SaaS providers or internal services.",
                    "Keep per‑invocation workloads modest but sustained, to avoid sudden spikes that immediately trigger cost/usage alarms.",
                    "Use multiple pipelines or entrypoints (API Gateway, Kinesis, S3/GCS) to distribute the hijacked compute across functions and regions where possible."
                ],
                "comments": "Although this vector overlaps with denial‑of‑service and cost amplification, from the ATT&CK perspective it represents unauthorized use of the victim’s compute and network resources to run attacker‑chosen workloads or traffic patterns.",
                "impact_achieved": "The attacker can continuously consume the victim’s Lambda compute capacity, network bandwidth, and downstream AWS service quotas to generate and relay attacker‑defined traffic, driving up costs and potentially starving legitimate workloads of resources."
            },
            {
                "can_achieve": false,
                "technique_name": "Lifecycle-Triggered Deletion",
                "technique_stix_id": "attack-pattern--1001e0d6-ee09-4dfc-aa90-e9320ffc8fe4",
                "method_steps": [],
                "capabilities_used": [
                    "S3 buckets for Substation data",
                    "GCP Storage and related GCP services"
                ],
                "interfaces_used": [
                    "AWS and GCP sink transforms (send_aws_s3, send_gcp_storage)"
                ],
                "data_accessed": [
                    "S3 objects and GCS objects written by Substation"
                ],
                "preconditions_required": [
                    "To implement this technique, a principal would need permissions such as s3:PutLifecycleConfiguration on target buckets or equivalent lifecycle‑policy modification rights on GCS buckets, exposed through Substation’s roles or transforms."
                ],
                "constraints_encountered": [
                    "The IAM policies described for S3 and GCS access only grant data‑plane operations like GetObject/PutObject and do not expose lifecycle‑management APIs such as PutBucketLifecycleConfiguration.",
                    "Substation transforms for S3 and GCS (send_aws_s3, send_gcp_storage) only support writing objects and do not have any code paths to configure or alter bucket lifecycle rules.",
                    "Terraform modules for S3 and GCS referenced in the analysis configure retention and encryption at deploy time, but no mechanism is exposed to Substation at runtime to mutate these lifecycle policies."
                ],
                "evasion_considerations": [
                    "An attacker could still approximate data destruction by overwriting or truncating objects via PutObject, but that falls under Data Destruction rather than Lifecycle‑Triggered Deletion and does not rely on lifecycle policy changes."
                ],
                "comments": "While the environment uses S3 and possibly GCS lifecycles, Substation’s documented runtime roles and code do not have the ability to modify lifecycle policies, so the specific MITRE \"Lifecycle‑Triggered Deletion\" technique is not achievable via this application as implemented.",
                "impact_achieved": "Not achievable via Substation: bucket and object lifecycle policies cannot be modified from within Substation’s documented capabilities, so wholesale lifecycle‑driven deletion of all objects in a bucket cannot be triggered through this application."
            }
        ],
        "summary": "Within a Substation deployment, the most significant Impact vectors are (1) corruption and overwrite of streaming data and logs via malicious, config‑driven HTTP enrichment and sink transforms; (2) targeted destruction of DynamoDB‑backed state and log‑like data by abusing TTL semantics via KV and sink transforms; (3) denial of service against centralized logging and streaming infrastructure by flooding Kinesis/Firehose through cross‑account CloudWatch Logs destinations and unauthenticated API Gateway → Kinesis/Lambda endpoints; (4) infrastructure‑level degradation of Kinesis capacity and monitoring through misuse of the Kinesis autoscaling Lambda and its CloudWatch alarm permissions; and (5) hijacking of Lambda compute, network egress, and downstream AWS service quotas by configuring Substation pipelines as high‑volume HTTP and AWS‑API traffic generators for attacker purposes. Lifecycle‑Triggered Deletion (changing bucket or object lifecycles) is not directly achievable with the roles and code exposed by Substation and instead would require broader cloud‑administrative access outside this application."
    },
    "lateral-movement": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Cloud Services",
                "technique_stix_id": "attack-pattern--8861073d-d1b8-4941-82ce-dce621d398f0",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise a Substation runtime that already has an AWS execution role (for example, a Substation Lambda behind API Gateway with authorization=NONE, or a Kinesis/S3/DynamoDB-stream triggered Lambda) so the attacker can influence which SUBSTATION_CONFIG is loaded or can deploy a modified configuration.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_LAMBDA_HANDLER + SUBSTATION_CONFIG environment variables (cmd/aws/lambda/substation/main.go)",
                            "API Gateway → Lambda ingestion endpoint (build/terraform/aws/api_gateway/lambda/main.tf)",
                            "AWS event sources for Lambda: Kinesis, S3, DynamoDB Streams, SNS, SQS, Firehose (cmd/aws/lambda/substation/*.go)"
                        ],
                        "related_data": [
                            "Existing Jsonnet/JSON pipeline configs referenced by SUBSTATION_CONFIG",
                            "AWS Lambda execution role substation-lambda-* and any attached IAM/KMS permissions"
                        ],
                        "notes": "Initial foothold can be via API Gateway, misconfigured config source (S3/HTTP), or CI/CD; the key is control over the config used by a Lambda that already has powerful AWS permissions."
                    },
                    {
                        "step_id": 2,
                        "description": "Modify or replace the Substation configuration to add AWS sink transforms that point at resources in other AWS accounts or regions (for example, S3 buckets, Kinesis streams, SQS queues, SNS topics, EventBridge buses, or Lambdas) and, if needed, configure an AssumeRoleARN in the AWS client settings to pivot cross-account.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sqs, send_aws_sns, send_aws_eventbridge, send_aws_lambda",
                            "internal/config.NewAWS (internal/config/config.go) with optional AssumeRoleARN"
                        ],
                        "related_data": [
                            "config.AWS blocks specifying target AWS ARNs in other accounts/regions",
                            "Optional STS AssumeRoleARN values for cross-account roles"
                        ],
                        "notes": "Because transform dispatch is purely config-driven, pointing sinks at cross-account ARNs is a text edit, not a code change."
                    },
                    {
                        "step_id": 3,
                        "description": "Ensure the Substation Lambda execution role has, or is granted, the ability to assume the specified cross-account roles and access the target resources (for example, sts:AssumeRole on the remote role plus service-specific permissions like s3:PutObject, kinesis:PutRecords, sns:Publish).",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "STS AssumeRole via internal/config.NewAWS",
                            "IAM policies for roles in var.access across S3, Kinesis, DynamoDB, SQS, SNS, EventBridge, Lambda, Secrets (build/terraform/aws/*/main.tf)"
                        ],
                        "related_data": [
                            "IAM role ARNs in var.access and any cross-account trust policies",
                            "KMS key policies referenced by encrypted S3, Kinesis, DynamoDB, SQS, SNS, Secrets"
                        ],
                        "notes": "In many deployments, var.access roles are already broadly privileged; adding cross-account trust on those roles or on a dedicated role lets Substation pivot accounts."
                    },
                    {
                        "step_id": 4,
                        "description": "Trigger the compromised Substation Lambda (for example, by sending HTTP POSTs to the public API Gateway endpoint or by producing records into a Kinesis stream/S3 bucket that invokes it) so that messages flow through the new send_aws_* transforms and are written into the cross-account resources using the assumed role.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "API Gateway → Lambda proxy POST /",
                            "Kinesis, S3, DynamoDB Streams, SNS, SQS event sources for Lambda",
                            "substation read --aws s3://... (CLI ingestion path that can run the same sinks)"
                        ],
                        "related_data": [
                            "Event payloads from API Gateway, Kinesis, S3, DynamoDB Streams, SNS, SQS, Firehose",
                            "Transformed message bodies that become S3 objects, Kinesis records, queue messages, or EventBridge events in other accounts"
                        ],
                        "notes": "From the cloud provider’s perspective, these are legitimate data-plane calls from an authorized role into trusted resources, despite being directed by an attacker."
                    },
                    {
                        "step_id": 5,
                        "description": "From the destination AWS accounts, use attacker-controlled principals (for example, an S3 bucket or Kinesis stream in an attacker account, or a Lambda the attacker controls) to receive and further act on the data written by Substation, effectively establishing a bridge from the original compromised account to additional AWS accounts.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Destination S3/Kinesis/SQS/SNS/EventBridge/Lambda resources identified in config.AWS",
                            "Any downstream consumers (not necessarily Substation) attached to those resources"
                        ],
                        "related_data": [
                            "Data exfiltrated or relayed into attacker-controlled AWS resources",
                            "Metadata such as ARNs, partition keys, timestamps that aid further cloud reconnaissance"
                        ],
                        "notes": "This step completes lateral movement by giving the attacker operational access in another account via data flows or by triggering workloads they own."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms",
                    "Local ingestion and transformation CLI",
                    "Secrets retrieval and interpolation"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG environment variable + internal/file.Get for dynamic config loading",
                    "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sqs, send_aws_sns, send_aws_eventbridge, send_aws_lambda",
                    "internal/config.NewAWS with optional AssumeRoleARN",
                    "API Gateway → Lambda proxy REST API (POST /, authorization=NONE)",
                    "Event-based Lambda handlers for Kinesis, S3, DynamoDB Streams, SNS, SQS, Firehose"
                ],
                "data_accessed": [
                    "Event payloads from upstream AWS services (API Gateway, Kinesis, S3, DynamoDB Streams, SNS, SQS, Firehose)",
                    "Substation configuration files that define target AWS ARNs and AssumeRoleARNs",
                    "Cross-account AWS resources: S3 buckets/objects, Kinesis streams, Firehose delivery streams, DynamoDB tables, SQS queues, SNS topics, EventBridge buses, Lambda functions",
                    "STS temporary credentials for assumed roles as used internally by AWS SDK clients"
                ],
                "preconditions_required": [
                    "Attacker can modify or replace SUBSTATION_CONFIG for at least one Substation Lambda or CLI invocation, or can deploy a new config that the runtime will load.",
                    "The compromised Substation runtime is using an AWS execution role with sufficient permissions to call sts:AssumeRole (if cross-account pivot is needed) and to access the chosen target services.",
                    "Target AWS accounts/resources either trust the Substation account’s role (for AssumeRole) or allow cross-account access via resource policies (for example, S3 bucket policies, Kinesis resource policies, Lambda resource policies).",
                    "Network egress from the Substation Lambda’s VPC/subnets to AWS public endpoints is allowed via NAT/IGW."
                ],
                "constraints_encountered": [
                    "Cross-account movement is limited by IAM trust policies on the target roles and by service resource policies; if those do not trust the Substation account, the pivot fails.",
                    "KMS key policies on cross-account encrypted resources must grant decrypt/data-key permissions to the assumed role; otherwise writes may succeed but reads/decryption will fail.",
                    "Terraform-driven scoping of var.access may restrict which roles can be given broad multi-service permissions, limiting the blast radius of some Substation Lambdas.",
                    "CloudTrail and CloudWatch logging of STS AssumeRole, S3/Kinesis/SQS/SNS/EventBridge, and Lambda API calls can reveal unusual cross-account or cross-region activity."
                ],
                "evasion_considerations": [
                    "Reuse existing destination resources (for example, S3 buckets or streams already present in configs) and only subtly change ARNs to attacker-controlled equivalents in other accounts to blend with normal patterns.",
                    "Throttle send_aws_* batch sizes and execution frequency to match expected traffic volumes and avoid obvious spikes in CloudWatch metrics.",
                    "Preserve expected message schemas so downstream consumers continue to function and do not trigger error alerts.",
                    "If AssumeRoleARN is newly added, use a role name and permissions that look consistent with existing cross-account patterns to avoid review."
                ],
                "comments": "This is the most direct lateral movement path: using Substation’s AWS sink transforms and STS-based AWS client helper to treat additional AWS accounts as just another set of sinks. The likely crown jewels are high-value data stores (S3 data lakes, Kinesis streams feeding analytics, DynamoDB tables) and more-privileged workloads in other accounts; Substation can be turned into a cross-account data mover and trigger engine for those environments.",
                "movement_achieved": "Access to and ability to write into (and sometimes operate within) additional AWS accounts and regions by abusing Substation’s AWS sink transforms and STS AssumeRole-based clients."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Services",
                "technique_stix_id": "attack-pattern--8861073d-d1b8-4941-82ce-dce621d398f0",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise a Substation ingestion point that accepts untrusted traffic (for example, the public API Gateway → Lambda proxy endpoint or the API Gateway → Kinesis ingestion API) so the attacker can drive a specific Substation pipeline with controlled input.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Public HTTP APIs via API Gateway (Lambda proxy)",
                            "Public HTTP APIs via API Gateway (direct to Kinesis)",
                            "cmd/aws/lambda/substation/api_gateway.go",
                            "cmd/aws/lambda/substation/kinesis_data_stream.go"
                        ],
                        "related_data": [
                            "HTTP POST request bodies mapped into Substation messages",
                            "Kinesis records produced by API Gateway’s PutRecord integration"
                        ],
                        "notes": "The Terraform sets authorization to NONE for these APIs, making them internet-facing by default unless constrained elsewhere."
                    },
                    {
                        "step_id": 2,
                        "description": "Determine or influence which Substation configuration is used by the targeted Lambda (via SUBSTATION_CONFIG pointing to S3/HTTP/GCS) and modify it to include send_aws_lambda, send_aws_eventbridge, and/or send_aws_kinesis_data_stream transforms that target more-privileged Lambdas, event buses, or Kinesis streams.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG + internal/file.Get (local/HTTP/S3/GCS configs)",
                            "Transform types: send_aws_lambda, send_aws_eventbridge, send_aws_kinesis_data_stream"
                        ],
                        "related_data": [
                            "Config entries specifying downstream Lambda ARNs, EventBridge bus ARNs, or Kinesis stream ARNs",
                            "Any AssumeRoleARN used for these sinks via internal/config.NewAWS"
                        ],
                        "notes": "Downstream Lambdas or workflows may run under different, often more-privileged, IAM roles than the initial ingestion function."
                    },
                    {
                        "step_id": 3,
                        "description": "Ensure the Substation Lambda’s role (or an assumed role configured in internal/config.AWS) has lambda:InvokeFunction on the target Lambdas, events:PutEvents on the chosen EventBridge bus, and/or kinesis:PutRecord/PutRecords on the target Kinesis streams.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Lambda access policy granting lambda:InvokeFunction to var.access roles (build/terraform/aws/lambda/main.tf)",
                            "EventBridge IAM policies granting events:PutEvents (build/terraform/aws/eventbridge/lambda/main.tf)",
                            "Kinesis Data Stream IAM policies for var.access roles (build/terraform/aws/kinesis_data_stream/main.tf)",
                            "internal/config.NewAWS"
                        ],
                        "related_data": [
                            "IAM policies attached to roles in var.access and to the Substation execution role",
                            "Lambda, EventBridge, and Kinesis ARNs used as downstream targets"
                        ],
                        "notes": "By design, var.access roles are given broad rights to Kinesis, EventBridge, and Lambdas; if the Substation Lambda uses such a role, little extra permissioning is needed."
                    },
                    {
                        "step_id": 4,
                        "description": "Craft Substation input messages so that, after any validation or enrichment, the pipeline invokes send_aws_lambda / send_aws_eventbridge / send_aws_kinesis_data_stream with payloads that will trigger meaningful behavior in the downstream, more-privileged services (for example, events that cause them to process sensitive datasets or perform admin actions).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Transform sequencing in substation.Config",
                            "send_aws_lambda invocation payloads",
                            "EventBridge event detail fields via send_aws_eventbridge",
                            "Kinesis record payloads via send_aws_kinesis_data_stream"
                        ],
                        "related_data": [
                            "JSON payloads accepted by downstream Lambdas or event-driven workflows",
                            "Control fields or flags that downstream code uses to branch logic"
                        ],
                        "notes": "This is analogous to using a compromised service to call into more-privileged internal APIs, but done via native cloud eventing and function invocation."
                    },
                    {
                        "step_id": 5,
                        "description": "Let downstream Lambdas, Kinesis consumers, or EventBridge-triggered workflows execute under their own IAM roles, operating on additional data stores, logs, or administrative APIs. From the attacker’s perspective, this achieves lateral movement: they can now indirectly cause actions in services and accounts they could not reach directly.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "Downstream Lambda invoke APIs and triggers",
                            "EventBridge rules targeting high-privilege Lambdas",
                            "Kinesis stream consumers (which may themselves be Substation or other applications)"
                        ],
                        "related_data": [
                            "Data stores managed by downstream Lambdas (e.g., S3, DynamoDB, Secrets, KMS-protected resources)",
                            "Operational control-plane APIs they may call (e.g., CloudWatch, IAM, other service-specific admins)"
                        ],
                        "notes": "The attacker does not need direct access to these downstream roles; they simply orchestrate events that cause those roles to do work on their behalf."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms"
                ],
                "interfaces_used": [
                    "Public API Gateway → Lambda proxy REST API",
                    "Public API Gateway → Kinesis PutRecord REST API",
                    "Transform types: send_aws_lambda, send_aws_eventbridge, send_aws_kinesis_data_stream",
                    "internal/config.NewAWS for AWS client creation and optional AssumeRoleARN"
                ],
                "data_accessed": [
                    "HTTP request bodies and metadata from API Gateway clients",
                    "Kinesis records carrying attacker-controlled payloads",
                    "Configuration specifying downstream Lambda, EventBridge, and Kinesis targets",
                    "All data and services reachable by the downstream, more-privileged Lambdas or stream consumers"
                ],
                "preconditions_required": [
                    "A Substation Lambda is reachable by the attacker (typically via the unauthenticated API Gateway or Kinesis ingestion endpoint).",
                    "The attacker can influence which configuration that Lambda uses (for example, by changing SUBSTATION_CONFIG in environment, modifying an S3/HTTP config source, or compromising AppConfig).",
                    "The Substation Lambda’s role, or an assumed role it can obtain, has invoke/PutEvents/PutRecords permissions on downstream targets with broader or different privileges.",
                    "Downstream consumers accept and act upon events from these sources without strong origin validation or per-tenant isolation."
                ],
                "constraints_encountered": [
                    "If downstream Lambdas or EventBridge rules enforce strict input validation, schema checks, or tenant-specific auth, some crafted events may be dropped or cause errors instead of useful behavior.",
                    "Cross-account Lambda invocation or EventBridge routing requires appropriate resource-based policies; if those are tightly scoped, cross-account chaining may be blocked.",
                    "CloudTrail and CloudWatch can highlight unusual spikes in lambda:InvokeFunction, events:PutEvents, or kinesis:PutRecords from the Substation role to specific high-privilege targets."
                ],
                "evasion_considerations": [
                    "Reuse existing downstream targets and event shapes already present in legitimate configs instead of introducing entirely new ones.",
                    "Maintain normal batch sizes and invocation frequency to blend with expected traffic profiles on target Lambdas and event buses.",
                    "Hide malicious payload markers within otherwise valid business events so that downstream logging and telemetry appear routine."
                ],
                "comments": "This vector leverages Substation as an event-orchestration layer to drive more-privileged Lambdas, EventBridge flows, and Kinesis consumers. The attacker’s real goal is indirect execution with identities that have access to additional data (for example, centralized audit logs, secrets, or admin APIs) or that run in other accounts/environments. Substation becomes a cloud-native ‘jump host’ into those internal cloud services.",
                "movement_achieved": "Ability to trigger and steer execution of more-privileged Lambda functions, EventBridge-based workflows, and Kinesis consumers from a less-privileged or externally reachable Substation entry point."
            },
            {
                "can_achieve": true,
                "technique_name": "Application Access Token",
                "technique_stix_id": "attack-pattern--f005e783-57d4-4837-88ad-dbe7faee1c51",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain control over a Substation pipeline configuration that includes utility_secret transforms or otherwise references secrets via ${SECRET:ID} interpolation, so that the attacker can influence how those secrets are used in HTTP enrichment/sending transforms.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Transform type: utility_secret",
                            "Secret interpolation syntax ${SECRET:ID} (internal/secrets/secrets.go)",
                            "SUBSTATION_CONFIG + internal/file.Get"
                        ],
                        "related_data": [
                            "Secrets Manager secret ARNs and logical IDs used in utility_secret configs",
                            "Existing HTTP transform configs that already embed ${SECRET:ID} in headers/URLs"
                        ],
                        "notes": "Secrets may include OAuth tokens, API keys, or service account tokens for SaaS or other cloud APIs, not just AWS."
                    },
                    {
                        "step_id": 2,
                        "description": "Identify which secrets correspond to reusable application access tokens (for example, OAuth refresh/access tokens, long-lived API keys, or service account credentials) that grant access to external cloud or SaaS environments, by inspecting configuration, environment variables, or responses from existing HTTP transforms.",
                        "related_capabilities": [
                            "Secrets retrieval and interpolation",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "internal/secrets/aws_secrets_manager.go for GetSecretValue",
                            "Transform configs for enrich_http_get, enrich_http_post, send_http_post that use ${SECRET:ID}"
                        ],
                        "related_data": [
                            "Secret values cached in-memory by internal/secrets",
                            "Metadata in configs indicating token scopes or target services (e.g., API endpoints, tenant identifiers)"
                        ],
                        "notes": "This mirrors real-world campaigns like Peirates and CreepyDrive, which locate and reuse existing cloud access tokens."
                    },
                    {
                        "step_id": 3,
                        "description": "Modify or add HTTP enrichment/sending transforms so that they call high-value management or data-plane APIs in those external services (for example, Microsoft 365, other cloud control planes, or SaaS admin APIs), embedding the retrieved tokens in Authorization headers or query parameters via ${SECRET:ID}.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_http_get, enrich_http_post, send_http_post",
                            "internal/http.Get and internal/http.Post (retryable HTTP client with TLS)",
                            "Secret interpolation in headers/URLs/body templates"
                        ],
                        "related_data": [
                            "HTTP request URLs for cloud/SaaS APIs",
                            "Authorization headers or tokens derived from secrets (e.g., Bearer tokens, API keys)"
                        ],
                        "notes": "Substation effectively becomes a programmable HTTP client operating with the victim’s application access tokens."
                    },
                    {
                        "step_id": 4,
                        "description": "Drive the pipeline (via API Gateway, Kinesis, S3, or CLI) with crafted messages that cause the new HTTP transforms to execute, invoking external cloud or SaaS APIs with valid tokens to perform actions such as reading data, enumerating resources, or modifying configurations in those environments.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "Local ingestion and transformation CLI",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "API Gateway → Lambda proxy or Kinesis ingestion",
                            "substation read / substation test (CLI drivers)",
                            "HTTP endpoints for external cloud/SaaS APIs"
                        ],
                        "related_data": [
                            "Request bodies carrying attacker-controlled parameters to cloud APIs",
                            "Responses from cloud/SaaS APIs (user lists, mail contents, configuration settings, etc.)"
                        ],
                        "notes": "From the external service’s perspective, these are fully authenticated API calls backed by legitimate tokens, not anomalous logins."
                    },
                    {
                        "step_id": 5,
                        "description": "Optionally, route API responses or selected data from the external services into attacker-controlled destinations (for example, S3 buckets or HTTP endpoints) using send_http_post or send_aws_s3, completing data theft or enabling further pivots based on retrieved information.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "send_http_post to attacker-controlled HTTPS endpoint",
                            "send_aws_s3 targeting attacker-controlled or cross-account buckets"
                        ],
                        "related_data": [
                            "Retrieved cloud/SaaS data (e.g., emails, files, configuration, identity information)",
                            "Exfiltration payloads written to S3 or HTTP"
                        ],
                        "notes": "At this point the attacker is using Substation as a token-enabled proxy into external cloud tenants."
                    }
                ],
                "capabilities_used": [
                    "Secrets retrieval and interpolation",
                    "HTTP enrichment and sending transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "Local ingestion and transformation CLI"
                ],
                "interfaces_used": [
                    "utility_secret transform and internal/secrets aws_secrets_manager retriever",
                    "Secret interpolation syntax ${SECRET:ID}",
                    "Transform types: enrich_http_get, enrich_http_post, send_http_post",
                    "internal/http HTTP client (retryablehttp wrapper)",
                    "API Gateway → Lambda proxy endpoint and other Lambda event sources",
                    "substation read / substation test CLI commands"
                ],
                "data_accessed": [
                    "Secrets Manager secrets or environment variables containing API tokens, OAuth refresh/access tokens, or service account credentials for external services",
                    "HTTP request/response bodies exchanged with external cloud/SaaS APIs",
                    "Any cloud-hosted data or configuration those tokens can access (for example, email, files, identity directories, admin settings)"
                ],
                "preconditions_required": [
                    "Substation is configured with utility_secret and/or ${SECRET:ID} interpolation that references high-value external API tokens or service account credentials, stored in AWS Secrets Manager or environment variables.",
                    "The attacker can modify Substation configuration or deploy new configs for a pipeline that runs where these secrets are accessible.",
                    "Network egress from the Substation runtime (Lambda, CLI host, or GCP Function) to the external cloud/SaaS API endpoints is allowed.",
                    "Tokens are still valid and have sufficient scopes to perform meaningful actions in the external environment."
                ],
                "constraints_encountered": [
                    "If secrets are tightly scoped (least privilege) or rotated frequently, actions possible via these tokens may be limited or short-lived.",
                    "Some cloud APIs enforce IP reputation, anomaly detection, or conditional access; calls originating from AWS/GCP may be scrutinized.",
                    "Application may not currently use utility_secret for non-AWS tokens; this vector depends on operators storing such tokens in Secrets Manager."
                ],
                "evasion_considerations": [
                    "Reuse existing secret IDs and HTTP transform names to avoid introducing obviously suspicious configuration changes.",
                    "Mimic legitimate API call patterns (endpoints, HTTP methods, timing) expected for the associated service.",
                    "Limit the volume and rate of cross-tenant API calls to stay under provider-specific throttling or anomaly thresholds."
                ],
                "comments": "This vector turns Substation into a conduit for abusing stored application access tokens, analogous to tools like Peirates abusing GCP service account tokens. The likely crown jewels include email inboxes, file repositories, identity stores, or admin consoles in other cloud/SaaS tenants that are reachable with those tokens.",
                "movement_achieved": "Ability to act in other cloud or SaaS environments by reusing stored application access tokens via Substation’s secret-aware HTTP transforms."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Services",
                "technique_stix_id": "attack-pattern--8861073d-d1b8-4941-82ce-dce621d398f0",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Compromise either an AWS Substation Lambda or the GCP Cloud Storage Substation Function such that the attacker can modify its configuration (SUBSTATION_CONFIG) and thus control which sinks (AWS vs. GCP) are active.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG + internal/file.Get (supports S3, GCS, HTTP, local)",
                            "cmd/aws/lambda/substation/main.go",
                            "cmd/gcp/function/substation/main.go"
                        ],
                        "related_data": [
                            "Jsonnet/JSON configs defining cross-cloud send_* transforms",
                            "Environment variables for AWS and GCP runtimes"
                        ],
                        "notes": "Control over SUBSTATION_CONFIG for either side is sufficient; both runtimes can host pipelines that include the other cloud’s sinks."
                    },
                    {
                        "step_id": 2,
                        "description": "On the compromised side, configure a pipeline that reads events from local cloud sources (for example, S3/Kinesis/SNS/SQS in AWS or GCS object events in GCP) and includes cross-cloud sink transforms such as send_gcp_storage (from AWS) or send_aws_* (from GCP) targeting resources in another cloud account or project.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type: send_gcp_storage",
                            "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda"
                        ],
                        "related_data": [
                            "Target GCS bucket URIs and object path patterns",
                            "Target AWS ARNs in the opposite cloud direction"
                        ],
                        "notes": "This can bridge either direction: AWS→GCP or GCP→AWS, depending on which runtime is under attacker control."
                    },
                    {
                        "step_id": 3,
                        "description": "Ensure the compromised runtime has credentials and IAM/service account permissions to write to the chosen cross-cloud destinations (for example, GCP service account with storage.objects.create on target GCS buckets; AWS roles with s3:PutObject, kinesis:PutRecords, etc.).",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "GCP client creation via internal/config GCP structs and default credentials",
                            "AWS client creation via internal/config.NewAWS and IAM roles",
                            "utility_secret for embedding extra credentials into HTTP-based cross-cloud calls, if used"
                        ],
                        "related_data": [
                            "GCP service account identities and scopes",
                            "AWS IAM roles and any AssumeRoleARNs configured for cross-account access"
                        ],
                        "notes": "Mis-scoped service accounts or AWS roles that span multiple projects/accounts significantly increase the reach of this pivot."
                    },
                    {
                        "step_id": 4,
                        "description": "Trigger the pipeline from its local cloud environment: write objects into GCS buckets to fire the GCP Function, or send HTTP/Kinesis/S3/DynamoDB/SNS/SQS events into the AWS Substation Lambda. The pipeline will process these events and forward data into the configured cross-cloud sinks.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "GCP Cloud Storage events (CloudEvent handler at '/'), triggering Substation in GCP",
                            "AWS event sources (API Gateway, Kinesis, S3, DynamoDB Streams, SNS, SQS, Firehose, generic Lambda) triggering Substation in AWS",
                            "send_gcp_storage and send_aws_* sink calls"
                        ],
                        "related_data": [
                            "Object contents and metadata from GCS",
                            "S3 object data, Kinesis records, DynamoDB change events, SNS/SQS messages from AWS",
                            "Cross-cloud copies of these payloads stored in GCS or AWS targets"
                        ],
                        "notes": "This effectively turns data lakes and streams in one cloud into feeders for the other."
                    },
                    {
                        "step_id": 5,
                        "description": "Leverage cross-cloud writes to trigger additional workloads (for example, have send_gcp_storage write into GCS buckets that in turn trigger other Cloud Functions or Dataflow jobs, or write into AWS S3/Kinesis/SNS that trigger higher-privilege Lambdas), expanding execution into new cloud projects or accounts.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "GCP Cloud Storage Substation Function",
                            "AWS Lambda Substation event processors"
                        ],
                        "related_interfaces": [
                            "GCS bucket notification → Cloud Functions or other GCP services",
                            "AWS S3 event notifications, Kinesis triggers, SNS/SQS triggers for other Lambdas"
                        ],
                        "related_data": [
                            "Payloads and metadata now processed under additional AWS/GCP identities",
                            "Any further data those workloads can access in their respective environments"
                        ],
                        "notes": "Substation serves as the bridge; subsequent execution may be fully native to the target cloud but initiated by the attacker’s pipeline."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "AWS and GCP sink transforms",
                    "Core Substation transformation engine",
                    "Secrets retrieval and interpolation"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG with S3/GCS/HTTP sources",
                    "Transform type: send_gcp_storage",
                    "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda",
                    "GCP CloudEvent HTTP handler for Storage events",
                    "AWS Lambda handlers for various AWS event sources"
                ],
                "data_accessed": [
                    "GCS objects in buckets readable by the Cloud Function’s service account",
                    "AWS S3/Kinesis/DynamoDB/queue/topic data processed by Substation Lambdas",
                    "Cross-cloud copies of those datasets created in the other cloud’s storage or messaging services"
                ],
                "preconditions_required": [
                    "At least one Substation runtime (AWS Lambda or GCP Function) is deployed with both the necessary client libraries and credentials for its local cloud, and the attacker can control its configuration.",
                    "Target cross-cloud buckets/streams/queues exist and are writable by the compromised runtime’s identity (or by an assumed role/service account it can obtain).",
                    "Network egress from each runtime to the other cloud’s public endpoints is permitted.",
                    "In environments where object events trigger further workloads, those triggers are enabled for the chosen destinations."
                ],
                "constraints_encountered": [
                    "Cloud-provider IAM and project/account boundaries may limit which buckets or services can be written cross-cloud; service account and IAM policies must be permissive enough.",
                    "KMS or CMEK encryption on buckets/streams may prevent decryption in the target cloud, though writes will typically still succeed.",
                    "Monitoring on cross-cloud data transfers (for example, organization-level logging or CASB) may flag unusual transfer patterns."
                ],
                "evasion_considerations": [
                    "Write into existing cross-cloud integration buckets/streams where some level of AWS↔GCP movement is already expected.",
                    "Throttle cross-cloud transfers and preserve existing object naming conventions or partitioning schemes.",
                    "Blend malicious content into apparently routine analytics or log data shapes to reduce the chance of manual inspection."
                ],
                "comments": "This vector uses Substation as a bridge between AWS and GCP, allowing an attacker with control of only one side to move data and execution into the other cloud’s accounts or projects. The likely crown jewels are cross-cloud data lakes, analytics pipelines, and workloads that aggregate logs or sensitive business events from both environments.",
                "movement_achieved": "Cross-cloud lateral movement between AWS and GCP accounts/projects via Substation’s GCS and AWS sink transforms, enabling control over workloads and data in both environments."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Services",
                "technique_stix_id": "attack-pattern--8861073d-d1b8-4941-82ce-dce621d398f0",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify that multiple logical tenants or pipelines share the same DynamoDB-backed KV store and locker by inspecting KV transform configurations (key prefixes, table names) and Terraform outputs for DynamoDB modules.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform types: enrich_kv_store_item_get, enrich_kv_store_item_set, enrich_kv_store_set_add, meta_kv_store_lock",
                            "internal/kv Storer and Locker backed by DynamoDB",
                            "DynamoDB tables for state and streaming change data"
                        ],
                        "related_data": [
                            "KV configuration blocks including table identifiers and key prefixes",
                            "Existing KV items and lock records in the shared DynamoDB table"
                        ],
                        "notes": "The ApplicationCapabilityAnalysis explicitly notes that KV prefixes are optional and misconfiguration can cause cross-tenant key collisions."
                    },
                    {
                        "step_id": 2,
                        "description": "Compromise one tenant’s pipeline or event source (e.g., a public API Gateway that feeds a Substation Lambda using KV transforms) so the attacker can send messages whose fields directly control KV keys, values, and TTLs.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Public API Gateway → Lambda proxy endpoint",
                            "Any Substation Lambda handler that runs KV transforms",
                            "KV transform configs mapping message fields to KV keys"
                        ],
                        "related_data": [
                            "Message fields used as KV keys or TTL sources",
                            "Tenant-specific identifiers, which may be weakly isolated via prefixes"
                        ],
                        "notes": "Pipeline authors often use message identifiers as KV keys; if prefixes are shared, other tenants’ state may be addressable."
                    },
                    {
                        "step_id": 3,
                        "description": "Use the compromised tenant’s pipeline to deliberately read or write KV entries that belong to another tenant or pipeline, by crafting messages whose KV-derived keys collide with or overwrite those used by the target tenant.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "enrich_kv_store_item_get to read arbitrary key/value pairs",
                            "enrich_kv_store_item_set and enrich_kv_store_set_add to write or append values",
                            "meta_kv_store_lock to acquire or hold locks on shared keys"
                        ],
                        "related_data": [
                            "Other tenants’ KV values (for example, routing decisions, last-processed offsets, feature flags)",
                            "Lock entries that gate execution of shared sub-pipelines"
                        ],
                        "notes": "This enables both data leakage (reading KV values) and state corruption (overwriting values or holding locks)."
                    },
                    {
                        "step_id": 4,
                        "description": "Exploit modified KV state or locks to influence how other, potentially more-privileged pipelines behave—such as tricking them into thinking certain work has already been processed, forcing them to re-read or re-send data, or redirecting routing decisions so they send sensitive data to attacker-controlled sinks.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Downstream pipelines that consult shared KV or locks for idempotency, routing, or gating",
                            "send_aws_* or send_http_post sinks in those pipelines"
                        ],
                        "related_data": [
                            "Messages that other tenants’ pipelines now process differently due to altered KV state",
                            "Sensitive data those pipelines write to S3/Kinesis/SNS/SQS/EventBridge or HTTP endpoints"
                        ],
                        "notes": "The lateral movement effect arises because a less-privileged tenant can indirectly cause more-privileged pipelines to operate on their behalf."
                    },
                    {
                        "step_id": 5,
                        "description": "Optionally, use KV locks (meta_kv_store_lock) to create or prolong denial-of-service conditions for other tenants while exfiltrating or manipulating their data, by acquiring locks on shared keys and preventing critical sections from running.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "meta_kv_store_lock controlling execution of nested transforms",
                            "DynamoDB TTL and cleanup behavior for stale locks"
                        ],
                        "related_data": [
                            "Lock entries with extended TTLs blocking other tenants’ processing",
                            "Operational metrics that may show skewed processing due to lock contention"
                        ],
                        "notes": "This is primarily DoS, but it can support stealth by stalling monitoring or reconciliation pipelines for targeted tenants."
                    }
                ],
                "capabilities_used": [
                    "KV store integration and distributed locking",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "AWS and GCP sink transforms"
                ],
                "interfaces_used": [
                    "KV transforms: enrich_kv_store_item_get, enrich_kv_store_item_set, enrich_kv_store_set_add, meta_kv_store_lock",
                    "internal/kv DynamoDB-backed Storer/Locker",
                    "Public API Gateway → Lambda proxy or other shared event sources feeding KV-using pipelines"
                ],
                "data_accessed": [
                    "Shared DynamoDB KV and lock tables used for cross-message state and distributed locking",
                    "Other tenants’ or pipelines’ KV values (counters, offsets, flags, routing info)",
                    "Control-plane metadata about lock ownership and TTLs that dictate processing behavior"
                ],
                "preconditions_required": [
                    "Multiple tenants or pipelines share the same DynamoDB-backed KV/lock tables without strong per-tenant isolation (for example, weak or missing key prefixes).",
                    "At least one of those tenants is reachable by the attacker (via API Gateway or another event source) and uses KV transforms with keys derived from controllable message fields.",
                    "The attacker can observe or infer the key schema used by other tenants (for example, from documentation, configuration, or behavior)."
                ],
                "constraints_encountered": [
                    "Well-designed per-tenant key prefixes and strict separation of KV backends would block cross-tenant key collisions.",
                    "TTL settings on KV items and locks may limit how long corrupted state or locks remain effective.",
                    "Access to DynamoDB KV tables is mediated by IAM; if per-tenant tables or IAM roles are used, a compromised tenant may not be able to touch other tenants’ state."
                ],
                "evasion_considerations": [
                    "Change KV entries gradually and in patterns consistent with normal workloads to avoid obvious anomalies in state or metrics.",
                    "Target specific keys that influence routing or idempotency rather than broadly corrupting many keys, to keep behavior subtle.",
                    "Use meta_kv_store_lock in ways that resemble transient contention rather than permanent deadlocks."
                ],
                "comments": "While less direct than cross-account role pivots, shared DynamoDB-backed KV state is a realistic lateral movement vector in multi-tenant Substation deployments. A lower-privilege tenant can manipulate shared state to indirectly cause higher-privilege pipelines to misroute data, replay records, or skip safeguards, effectively expanding their influence over resources and data they were not meant to touch.",
                "movement_achieved": "Cross-tenant or cross-pipeline influence over processing behavior via shared DynamoDB-based KV and locking, allowing a compromised tenant to affect how other pipelines handle data and which sinks they use."
            },
            {
                "can_achieve": true,
                "technique_name": "Cloud Services",
                "technique_stix_id": "attack-pattern--8861073d-d1b8-4941-82ce-dce621d398f0",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain shell or build-script execution on a developer workstation, CI agent, or admin host where the Substation CLI is installed and where AWS/GCP credentials with significant privileges are available via the default SDK credential chains.",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "substation binary (cmd/substation/main.go)",
                            "substation read, substation test, substation tap commands"
                        ],
                        "related_data": [
                            "AWS credentials (environment variables, shared config files, or SSO sessions) available to the process",
                            "Jsonnet/JSON configuration repos accessible on disk or via Git"
                        ],
                        "notes": "This is analogous to compromising an admin’s laptop and then abusing their cloud management tools; here, Substation’s CLI is the multi-service orchestrator."
                    },
                    {
                        "step_id": 2,
                        "description": "Use or modify existing Substation configs—or introduce new ones—to define pipelines that include powerful AWS and GCP sink transforms (send_aws_*, send_gcp_storage) and HTTP transforms that target sensitive internal or cross-account resources.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "Jsonnet/JSON config files processed by substation build/fmt/test/vet",
                            "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sqs, send_aws_sns, send_aws_eventbridge, send_aws_lambda, send_gcp_storage, send_http_post"
                        ],
                        "related_data": [
                            "Config definitions for target AWS/GCP resources and HTTP endpoints",
                            "Any embedded ${SECRET:ID} references resolved via local environment or AWS Secrets Manager"
                        ],
                        "notes": "Because configs are often shared with production pipelines, changes made here can also impact deployed environments if not reviewed."
                    },
                    {
                        "step_id": 3,
                        "description": "Run substation read against high-value sources that the compromised credentials can access (for example, s3:// production buckets, DynamoDB streams, or HTTP APIs reachable from the host) and have the pipeline write to attacker-controlled AWS/GCP resources or internal endpoints.",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "AWS and GCP sink transforms",
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "substation read --file / --http / --aws s3://...",
                            "internal/file.Get for S3/HTTP sources",
                            "send_aws_* and send_gcp_storage sinks",
                            "send_http_post to attacker endpoints"
                        ],
                        "related_data": [
                            "Contents of production S3 objects or other ingested data",
                            "Exfiltrated copies written into attacker-controlled cloud resources"
                        ],
                        "notes": "This uses the CLI as a data-mover under the operator’s powerful identity, bypassing serverless-only controls."
                    },
                    {
                        "step_id": 4,
                        "description": "Use substation tap (if available) with the same credentials to read from Kinesis streams that back centralized logs or data pipelines, then route these records through send_* transforms to new destinations, giving the attacker near-real-time visibility into internal data flows.",
                        "related_capabilities": [
                            "Local ingestion and transformation CLI",
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "substation tap command (cmd/substation/tap.go)",
                            "Kinesis Data Streams for high-throughput ingestion",
                            "send_aws_s3, send_aws_kinesis_data_stream, send_http_post as sinks"
                        ],
                        "related_data": [
                            "Kinesis records containing logs or business events",
                            "Relayed copies in attacker-controlled storage or streams"
                        ],
                        "notes": "Kinesis access policies often grant broad read permissions to operational roles; compromising those roles via a workstation is highly impactful."
                    },
                    {
                        "step_id": 5,
                        "description": "Leverage substation test or custom CLI-driven pipelines in CI to drive send_aws_lambda, send_aws_eventbridge, and send_aws_kinesis_data_stream against production services, effectively using the CLI as a general-purpose cloud management and event injection tool under the compromised developer/CI identity.",
                        "related_capabilities": [
                            "Configuration management and validation CLI",
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "substation test command (cmd/substation/test.go)",
                            "Transform types: send_aws_lambda, send_aws_eventbridge, send_aws_kinesis_data_stream"
                        ],
                        "related_data": [
                            "Test payloads and messages crafted by the attacker",
                            "Effects on production Lambdas, EventBridge buses, and streams"
                        ],
                        "notes": "This is particularly dangerous when CI/CD has access to production-like roles and resources."
                    }
                ],
                "capabilities_used": [
                    "Local ingestion and transformation CLI",
                    "Configuration management and validation CLI",
                    "Core Substation transformation engine",
                    "AWS and GCP sink transforms",
                    "HTTP enrichment and sending transforms"
                ],
                "interfaces_used": [
                    "substation read / tap / test / build / vet CLI commands",
                    "Transform types: send_aws_* and send_gcp_storage",
                    "Transform type: send_http_post",
                    "internal/file.Get for HTTP/S3 sources",
                    "Default AWS/GCP credential providers on the host"
                ],
                "data_accessed": [
                    "Any S3, DynamoDB, Kinesis, SQS, SNS, Secrets, and GCS resources the developer/CI credentials can reach",
                    "Centralized log and event streams tapped from Kinesis",
                    "Configuration repositories that may include production pipeline definitions"
                ],
                "preconditions_required": [
                    "A workstation or CI agent with Substation CLI installed and with AWS/GCP credentials that have meaningful permissions (for example, roles in var.access or admin-like roles).",
                    "Attacker has shell or build-spec control on that host (for example, through compromise of the developer machine, CI system, or associated secrets).",
                    "Network connectivity from that host to cloud endpoints and any internal HTTP services targeted by HTTP transforms."
                ],
                "constraints_encountered": [
                    "Use of MFA, SSO, or just-in-time access may limit how long the compromised credentials remain valid.",
                    "Endpoint protection or EDR on developer/CI hosts may detect unusual CLI usage or outbound network patterns.",
                    "Organizational controls may restrict CI agents from holding production credentials, limiting the blast radius of this vector in well-segregated environments."
                ],
                "evasion_considerations": [
                    "Run Substation CLI under existing automation (for example, as part of CI jobs) to blend command executions with normal workflows.",
                    "Operate on off-peak schedules where manual monitoring is lower, but still within maintenance windows where admin activity is common.",
                    "Use config and transform names consistent with existing pipelines and avoid creating obviously malicious new resources."
                ],
                "comments": "Here Substation is used like a powerful multi-cloud admin tool from a compromised operator environment. It offers a higher-level interface than raw AWS/GCP CLIs, allowing chaining of reads and writes across many services with one config. The attacker’s crown jewels are production data in S3/Kinesis/DynamoDB, centralized logs, and the ability to trigger or test production Lambdas and workflows under high-privilege identities.",
                "movement_achieved": "Lateral movement from a compromised developer or CI host into multiple AWS/GCP services and data stores using Substation’s CLI as a multi-service orchestration tool under powerful cloud identities."
            }
        ],
        "summary": "Substation’s design—as a config-driven transformation engine with rich AWS/GCP and HTTP integrations—enables several realistic lateral movement paths once an attacker controls a pipeline configuration or a runtime identity.\n\nThe dominant MITRE mapping is the Cloud Services technique: a compromised Substation Lambda, GCP Function, or CLI instance can use its AWS/GCP roles to write into additional accounts, invoke more-privileged Lambdas and event-driven workflows, bridge data and execution across AWS and GCP, and manipulate shared DynamoDB-backed KV state to influence other tenants’ pipelines. Separately, by abusing Substation’s secret-aware HTTP transforms, an attacker can reuse stored application access tokens and API keys to act in external cloud or SaaS environments, aligning with the Application Access Token technique.\n\nAcross these vectors, the main constraints are IAM trust and scoping (for roles, KMS keys, and resource policies), network egress controls from Lambdas/hosts, and how rigorously multi-tenant separation and config governance are enforced. Where roles in var.access are broad, API Gateway endpoints are unauthenticated, KV tables are shared, and secrets include cross-tenant tokens, Substation becomes a powerful pivot point for moving laterally between services, accounts, tenants, and even clouds."
    },
    "command-and-control": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Application Layer Protocol: Web Protocols",
                "technique_stix_id": "T1071.001",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain the ability to modify or supply the Substation configuration that a victim runtime uses (for example, by overwriting the Jsonnet/JSON config object in S3/GCS/HTTP referenced by SUBSTATION_CONFIG or by providing a malicious config to the CLI/playground).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "Environment variable SUBSTATION_CONFIG used by AWS Lambda Substation event processors",
                            "Environment variable SUBSTATION_CONFIG used by GCP Cloud Storage Substation Function",
                            "CLI arguments for config paths in substation read / test / play",
                            "internal/file.Get supporting http(s)://, s3://, and GCS URIs"
                        ],
                        "related_data": [
                            "Jsonnet/JSON Substation configuration files",
                            "S3/GCS/HTTP objects referenced by SUBSTATION_CONFIG"
                        ],
                        "notes": "This is the core precondition: configuration fully defines which transforms (including HTTP) are executed."
                    },
                    {
                        "step_id": 2,
                        "description": "Edit the configuration to insert HTTP enrichment or sending transforms that target attacker-controlled HTTPS endpoints, ideally late in the pipeline so they see fully transformed data.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type enrich_http_get",
                            "Transform type enrich_http_post",
                            "Transform type send_http_post"
                        ],
                        "related_data": [
                            "config.Config entries with Type=enrich_http_get / enrich_http_post / send_http_post",
                            "Message payloads and metadata processed by the pipeline"
                        ],
                        "notes": "Because transform instantiation is driven purely by type strings and settings, adding a new HTTP transform is just a config change."
                    },
                    {
                        "step_id": 3,
                        "description": "Configure the HTTP URLs to point to attacker-controlled web infrastructure (for example, https://api.example-c2.com/beacon and https://api.example-c2.com/task), using ${DATA} placeholders to embed message content and ${SECRET:ID} interpolation for authentication headers if desired.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "URL and header templates in enrich_http_get/enrich_http_post/send_http_post settings",
                            "internal/secrets.Interpolate with ${SECRET:ID} syntax",
                            "internal/http.Get and internal/http.Post"
                        ],
                        "related_data": [
                            "Message fields included in URL templates, query parameters, or POST bodies",
                            "Secret values retrieved from AWS Secrets Manager or environment variables",
                            "Attacker-controlled HTTPS endpoints"
                        ],
                        "notes": "Using TLS on port 443 and realistic-looking hostnames makes this traffic blend with normal SaaS/API calls."
                    },
                    {
                        "step_id": 4,
                        "description": "For beaconing/exfiltration, configure send_http_post to batch messages and POST compact summaries (or full records) of processed data and environment context (for example, ARNs, stream names, tenant IDs) to the attacker’s /beacon endpoint.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Transform type send_http_post (batching and payload templating)",
                            "Lambda handlers for Kinesis/S3/DynamoDB/API Gateway events feeding the pipeline",
                            "GCP Cloud Storage handler feeding the pipeline",
                            "CLI substation read to run the same pipeline over files/HTTP/S3"
                        ],
                        "related_data": [
                            "Kinesis records, S3/GCS object contents, DynamoDB stream images, API Gateway request bodies, SNS/SQS messages",
                            "Per-message metadata (ARNs, timestamps, keys, tenant identifiers)"
                        ],
                        "notes": "This turns every message the pipeline sees into a potential C2 beacon containing high-value telemetry or data."
                    },
                    {
                        "step_id": 5,
                        "description": "For pulling commands, add enrich_http_get or enrich_http_post before routing/sink transforms so that each batch (or some fraction of messages) issues an HTTP request to an attacker /task endpoint and writes the JSON response into a dedicated command field in the message.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine",
                            "Condition/branching logic via conditions and meta transforms"
                        ],
                        "related_interfaces": [
                            "Transform type enrich_http_get",
                            "Transform type enrich_http_post",
                            "Condition/transform routing driven by message fields"
                        ],
                        "related_data": [
                            "Command JSON returned by attacker endpoint (e.g., {\"action\":\"route_to_s3\",\"bucket\":\"attacker-bkt\",\"mask_fields\":[...]} )",
                            "Message fields that use the command as parameters (bucket names, keys, filtering flags)"
                        ],
                        "notes": "While transforms are static, they can consume remote command data to parameterize routing, masking, or sink selection at runtime."
                    },
                    {
                        "step_id": 6,
                        "description": "Modify downstream transforms and conditions to interpret the command fields (for example, choosing different sink ARNs or URLs, selectively dropping or altering messages, or enabling additional C2 beacons) based on attacker-supplied values.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Dynamic field interpolation in send_* transform settings (e.g., object paths, partition keys)",
                            "KV enrich/set transforms that can use command fields as keys or TTLs",
                            "Condition configurations that branch on command fields"
                        ],
                        "related_data": [
                            "Remote command fields added to messages by HTTP enrichment",
                            "Configuration settings that reference those fields"
                        ],
                        "notes": "This makes the HTTP exchanges true tasking: the attacker can remotely influence where data is sent and how it is processed."
                    },
                    {
                        "step_id": 7,
                        "description": "Operate the attacker-controlled HTTPS endpoints as a C2 server: ingest beacons from send_http_post, store or analyze the exfiltrated data, and serve tailored command JSON to enrich_http_* callers that adjusts Substation behavior over time.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Attacker-operated HTTPS API endpoints",
                            "send_http_post and enrich_http_* HTTP client behavior"
                        ],
                        "related_data": [
                            "All exfiltrated data and metadata received from Substation",
                            "Command payloads sent back to Substation"
                        ],
                        "notes": "From the defender’s viewpoint, this appears as normal HTTPS traffic from Lambda/GCF instances to an external API."
                    }
                ],
                "capabilities_used": [
                    "HTTP enrichment and sending transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "Secrets retrieval and interpolation",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "Transform type enrich_http_get",
                    "Transform type enrich_http_post",
                    "Transform type send_http_post",
                    "internal/http.Get",
                    "internal/http.Post",
                    "internal/file.Get for HTTP(S) SUBSTATION_CONFIG locations",
                    "SUBSTATION_CONFIG on AWS Lambda Substation event processors",
                    "SUBSTATION_CONFIG on GCP Cloud Storage Substation Function",
                    "CLI command: substation read --http URL",
                    "Playground HTTP server /run and /test endpoints (if exposed)"
                ],
                "data_accessed": [
                    "All message payloads processed by Substation (API Gateway requests, Kinesis records, S3/GCS object contents, DynamoDB stream images, SNS/SQS messages)",
                    "Message metadata (ARNs, timestamps, partition keys, S3/GCS paths, tenant identifiers)",
                    "Secrets retrieved from AWS Secrets Manager or environment variables via utility_secret",
                    "Configuration strings specifying HTTP URLs, headers, and body templates"
                ],
                "preconditions_required": [
                    "Attacker can modify or supply the Jsonnet/JSON configuration used by at least one Substation runtime (Lambda, Cloud Function, CLI, or playground), for example by writing to the S3/GCS object or HTTP location referenced by SUBSTATION_CONFIG.",
                    "The runtime has network egress to the internet or to attacker-controlled HTTP(S) endpoints via the VPC NAT and Internet gateway (as provided by build/terraform/aws/networking/vpc/main.tf).",
                    "Secrets Manager or environment variables may need to be misused if the attacker wants to embed existing API keys or tokens in outbound requests via ${SECRET:ID}."
                ],
                "constraints_encountered": [
                    "If an organization layers egress controls (for example, restricting Lambda VPC traffic to specific domains or VPC endpoints), HTTP(S) calls to arbitrary attacker domains may fail or be logged as policy violations.",
                    "HTTP transforms rely on standard TLS validation; if corporate TLS inspection or custom certificate pinning is deployed outside this repository, it may detect or break unusual C2 endpoints.",
                    "Misconfigured HTTP transforms that return errors (invalid URL, TLS failure, 4xx/5xx with no retry) can cause pipeline failures or error logs, increasing detection likelihood.",
                    "High-volume or high-latency HTTP beacons can increase Lambda execution time and cost, potentially triggering alarms or throttling."
                ],
                "evasion_considerations": [
                    "Use HTTPS on port 443 to blend with normal web traffic and leverage the Encrypted Channel behavior (T1573) implicitly provided by TLS.",
                    "Choose C2 domains and paths that resemble legitimate SaaS or internal APIs to evade simple domain-based detections (for example, api-telemetry.example.com).",
                    "Throttle beacon frequency and sample data rather than exfiltrating every message to avoid obvious traffic spikes and reduce CloudWatch/GuardDuty anomalies.",
                    "Encode sensitive payloads (for example, Base64 or JSON field-level encoding) inside otherwise normal-looking JSON structures to invoke Data Encoding (T1132) and Obfuscated Protocol (T1001) style obfuscation.",
                    "Re-use existing secret IDs and HTTP headers that already exist in configs (for example, Authorization: Bearer ${SECRET:id}) so the new C2 transforms look like extensions of existing integrations."
                ],
                "comments": "This is the most straightforward C2 vector: Substation already acts as a generic HTTP client, and configuration alone can turn any pipeline into an HTTPS-based beacon and tasking agent. Crown jewels exposed via this channel include production log/event streams (Kinesis, CloudWatch Logs ingested via subscriptions), database change streams (DynamoDB), file contents from S3/GCS, and potentially decrypted secrets if they pass through the pipeline.",
                "communication_established": "Outbound HTTPS-based command-and-control channel from Substation Lambdas/Cloud Functions/CLI to attacker-controlled web APIs using HTTP enrichment and sending transforms."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify how each Substation runtime locates its configuration—for example, by inspecting environment variables (SUBSTATION_CONFIG) for Lambda and GCP functions, or CLI arguments for operators using substation read/test/play.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable for AWS Lambda",
                            "SUBSTATION_CONFIG environment variable for GCP Cloud Function",
                            "CLI commands that accept config paths (substation read/test/vet/play)",
                            "internal/file.Get URI handling"
                        ],
                        "related_data": [
                            "Current SUBSTATION_CONFIG values (HTTP/S3/GCS URIs or local paths)",
                            "Process environment for Lambda/Cloud Function",
                            "CLI invocation parameters"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Obtain write access to the configuration location or the pointer, such as overwriting the S3/GCS object referenced by SUBSTATION_CONFIG, hosting a replacement config at the referenced HTTP(S) URL, or changing SUBSTATION_CONFIG itself via deployment tooling.",
                        "related_capabilities": [
                            "internal/file module",
                            "S3 buckets for Substation data",
                            "GCP Storage and related GCP services"
                        ],
                        "related_interfaces": [
                            "S3 GetObject/PutObject for config buckets",
                            "GCS storage.objects.get / storage.objects.update for config buckets",
                            "HTTP(S) hosting for configuration artifacts",
                            "Lambda/Cloud Function configuration management (environment variable editing via IaC or console)"
                        ],
                        "related_data": [
                            "Config objects in S3 buckets used by Substation",
                            "Config objects in GCS buckets used by Substation",
                            "Configuration JSON/Jsonnet served over HTTP(S)"
                        ],
                        "notes": "This may be achieved via compromised CI/CD, cloud credentials, or misconfigured bucket permissions."
                    },
                    {
                        "step_id": 3,
                        "description": "Stage a malicious configuration artifact at the controlled location that defines a pipeline embedding desired C2 behavior (for example, HTTP beacons, cross-account AWS sinks) but otherwise mimics the existing configuration’s structure and outputs.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "substation.Config and config.Config structures",
                            "transform.New dispatcher mapping Type strings to concrete transforms"
                        ],
                        "related_data": [
                            "Malicious Jsonnet/JSON configs stored in S3/GCS/HTTP",
                            "Existing baseline configs used as templates to avoid detection"
                        ],
                        "notes": "Because virtually any side effect is defined by transforms in the config, changing this file is equivalent to reprogramming the agent."
                    },
                    {
                        "step_id": 4,
                        "description": "Allow or force the Substation runtime to reload configuration from the attacker-controlled location—either by waiting for natural cold starts or deployments, or by causing errors that recycle Lambda containers, ensuring getConfig re-invokes internal/file.Get.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "internal/file module"
                        ],
                        "related_interfaces": [
                            "cmd/aws/lambda/substation/main.go:getConfig using internal/file.Get",
                            "cmd/gcp/function/substation/main.go:getConfig using internal/file.Get",
                            "Lambda cold start / container reuse semantics"
                        ],
                        "related_data": [
                            "New malicious configuration file contents",
                            "Lambda and Cloud Function logs indicating config load"
                        ],
                        "notes": "The exact reload cadence depends on how the deployment caches configs, but any cold start will re-fetch from the web service or storage location."
                    },
                    {
                        "step_id": 5,
                        "description": "Iteratively update the remote configuration artifact to adjust C2 behavior over time (for example, switching exfiltration targets, changing sampling rates, or disabling certain transforms) without needing further access to the victim runtimes.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "internal/file module"
                        ],
                        "related_interfaces": [
                            "S3/GCS/HTTP endpoints hosting configs",
                            "Jsonnet-based configuration build pipeline (if used)"
                        ],
                        "related_data": [
                            "Successive malicious config versions",
                            "Downstream changes in data flow and sink destinations"
                        ],
                        "notes": "The remote config location effectively acts as the C2 server: the agent (Substation) fetches new tasking whenever it reloads configuration."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "Core Substation transformation engine",
                    "internal/file module",
                    "S3 buckets for Substation data",
                    "GCP Storage and related GCP services"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG environment variable",
                    "internal/file.Get with http(s)://, s3://, and GCS URI support",
                    "S3 GetObject/PutObject on config buckets",
                    "GCS storage.objects.get / storage.objects.update for config objects",
                    "HTTP(S) endpoints used to host configuration artifacts"
                ],
                "data_accessed": [
                    "Configuration artifacts (Jsonnet/JSON) defining all transforms and sinks",
                    "S3 and GCS objects storing Substation configs",
                    "HTTP-served config documents",
                    "Any secrets or ARNs referenced inside configuration that define sink destinations"
                ],
                "preconditions_required": [
                    "Attacker can modify the contents of the S3/GCS/HTTP object used as SUBSTATION_CONFIG, or can change SUBSTATION_CONFIG to point to a location they control.",
                    "Substation runtimes are configured to fetch configuration from remote locations at cold start (as documented) and are not pinned to immutable local-only configs.",
                    "Operators are not validating or signing configuration artifacts such that tampering would be reliably detected before deployment."
                ],
                "constraints_encountered": [
                    "If configs are only loaded from immutable container images or strictly controlled local paths, remote configuration C2 is not achievable.",
                    "If configs are validated by a separate Lambda (AppConfig validator) with strong policies, obviously malicious configurations may be rejected.",
                    "Configuration syntax or transform misconfigurations will cause pipeline initialization errors, potentially surfacing in logs and breaking data flows, increasing detection chances.",
                    "Changes to configuration may be tracked through code review, CI, or change-management systems in mature environments."
                ],
                "evasion_considerations": [
                    "Preserve the existing logical data flows and only add subtle C2-related transforms (for example, additional HTTP sends or secondary AWS sinks) to avoid obvious behavioral changes.",
                    "Use Jsonnet to generate configurations that look auto-generated or complex, making manual review harder.",
                    "Gradually roll out changes (for example, exfiltrating only 1% of traffic initially) to avoid sudden shifts in traffic patterns or CloudWatch costs.",
                    "Host configuration artifacts on locations that appear legitimate (for example, an internal S3 bucket name or HTTPS domain) and match existing naming conventions."
                ],
                "comments": "Here the remote configuration source itself serves as the command channel: whoever controls the HTTP/S3/GCS config artifact controls the behavior of all Substation runtimes that reference it. This enables long-lived, low-noise C2 that can completely reprogram which data sets (log streams, change data, object contents) are copied or transformed without touching the deployed binaries.",
                "communication_established": "Indirect command-and-control channel where Substation Lambdas/Cloud Functions periodically fetch and execute attacker-controlled configuration from HTTP/S3/GCS web services."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Control or influence a Substation configuration that includes one or more cloud sink transforms (send_aws_* or send_gcp_storage), either by editing the existing pipeline or replacing its config as in the remote-configuration vector.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage",
                            "substation.Config and config.Config Settings for AWS/GCP sinks"
                        ],
                        "related_data": [
                            "Existing sink ARNs and resource identifiers defined in config",
                            "All messages currently flowing through those pipelines"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Provision attacker-controlled cloud resources to act as the C2 backend—for example, S3 buckets, Kinesis streams, SQS queues, SNS topics, EventBridge buses, or Lambdas in an attacker AWS account, or GCS buckets in an attacker GCP project.",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "AWS services: S3, Kinesis Data Streams, Firehose, DynamoDB, SNS, SQS, EventBridge, Lambda in attacker account",
                            "GCP Storage buckets in attacker project"
                        ],
                        "related_data": [
                            "Target bucket/stream/queue/topic/bus ARNs or resource names in attacker accounts/projects"
                        ],
                        "notes": "These resources serve as the \"web service\" endpoints for C2, using standard cloud APIs rather than custom protocols."
                    },
                    {
                        "step_id": 3,
                        "description": "Reconfigure Substation sink transforms to point at the attacker-controlled resources, optionally using internal/config.NewAWS AssumeRoleARN or permissive resource policies to enable cross-account writes.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "internal/config (NewAWS and AWS/GCP structs)"
                        ],
                        "related_interfaces": [
                            "config.AWS fields for target ARNs and regions in send_aws_* transforms",
                            "internal/config.NewAWS AssumeRoleARN support for cross-account AWS access",
                            "config.GCP fields for bucket identifiers in send_gcp_storage"
                        ],
                        "related_data": [
                            "Updated ARNs for S3 buckets, Kinesis streams, SNS topics, SQS queues, EventBridge buses, and Lambdas",
                            "Updated GCS bucket identifiers for send_gcp_storage"
                        ],
                        "notes": "If the Lambda execution role can sts:AssumeRole into an attacker account or the attacker has arranged permissive resource policies, these writes will succeed cross-account."
                    },
                    {
                        "step_id": 4,
                        "description": "Shape the sink payloads to carry C2-relevant data—such as compacted copies of high-value messages, environment identifiers, or partial secrets—by inserting auxiliary transforms that normalize, compress, or filter the data before it is delivered to the attacker-controlled cloud services.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Auxiliary transforms supported by send_aws_* (e.g., for aggregation and filtering)",
                            "Message metadata decoration in Lambda/GCF handlers"
                        ],
                        "related_data": [
                            "Application log and telemetry events from Kinesis/CloudWatch Logs ingestion",
                            "DynamoDB change data from DynamoDB Streams",
                            "S3/GCS file contents processed by ingestion Lambdas/Functions",
                            "Any secrets or identifiers transiting the pipeline if not masked"
                        ],
                        "notes": "This exfiltrated content can include crown jewels such as central logs, database change streams, or sensitive file data."
                    },
                    {
                        "step_id": 5,
                        "description": "On the attacker side, continuously read from the cross-account S3/Kinesis/SQS/SNS/EventBridge/GCS resources using standard cloud APIs, treating them as an asynchronous C2 inbox that receives beacons and stolen data.",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "AWS SDK/CLI for S3, Kinesis, SQS, SNS, EventBridge, Lambda in attacker account",
                            "GCP SDK/CLI for GCS in attacker project"
                        ],
                        "related_data": [
                            "All records written by Substation sinks into attacker resources",
                            "Metadata such as partition keys, message attributes, and event sources"
                        ],
                        "notes": "This is difficult to distinguish from legitimate cross-account logging or data sharing if resource names and regions look normal."
                    },
                    {
                        "step_id": 6,
                        "description": "Optionally, use attacker-controlled cloud services that can themselves send data back toward the victim environment (for example, SNS topics that publish into victim endpoints or Lambdas that call public APIs), enabling multi-stage C2 where Substation is just one leg of a broader cloud-based command network.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "send_aws_lambda to trigger attacker-controlled Lambdas",
                            "SNS topics or EventBridge rules in attacker account that forward or react to received data"
                        ],
                        "related_data": [
                            "Substation-originated messages as triggers for further attacker workflows"
                        ],
                        "notes": "From Substation’s perspective this is still an outbound write, but in aggregate it forms part of a cloud-native C2 mesh."
                    }
                ],
                "capabilities_used": [
                    "AWS and GCP sink transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "internal/config (AWS/GCP client factory)",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "Transform type send_aws_s3",
                    "Transform type send_aws_kinesis_data_stream",
                    "Transform type send_aws_data_firehose",
                    "Transform type send_aws_dynamodb_put",
                    "Transform type send_aws_sns",
                    "Transform type send_aws_sqs",
                    "Transform type send_aws_eventbridge",
                    "Transform type send_aws_lambda",
                    "Transform type send_gcp_storage",
                    "internal/config.NewAWS (including AssumeRoleARN support)",
                    "AWS/GCP APIs for the corresponding services in attacker-controlled accounts/projects"
                ],
                "data_accessed": [
                    "All transformed message payloads reaching sink transforms (logs, metrics, business events, change data, file contents)",
                    "Per-message metadata (keys, tenants, source ARNs, timestamps)",
                    "Configuration containing AWS ARN and GCP bucket identifiers for sinks"
                ],
                "preconditions_required": [
                    "Substation execution roles must have permissions to write to the targeted AWS resources, either directly (resource ARNs include attacker-owned resources) or indirectly via sts:AssumeRole to an attacker-controlled role.",
                    "For GCP, the function’s service account must have storage.objects.create/write permissions on attacker-controlled GCS buckets.",
                    "The attacker must be able to edit pipeline configuration to change sink destinations or add new sink transforms.",
                    "Cross-account resource policies and KMS key policies must allow writes from the victim account to the attacker’s resources (or the attacker controls the victim account)."
                ],
                "constraints_encountered": [
                    "If IAM policies and resource ARNs are tightly scoped to in-account resources only, attempts to write to attacker-controlled ARNs will fail and generate CloudTrail/CloudWatch errors.",
                    "KMS key policies may prevent encryption or decryption of data written to cross-account stores, causing sink transform failures.",
                    "High-volume exfiltration to external accounts may trigger billing anomalies, GuardDuty findings, or custom detection rules on Kinesis/S3/SQS/SNS/EventBridge usage.",
                    "Firewalls or VPC endpoint policies that restrict access to cloud service endpoints could limit which regions/accounts are reachable."
                ],
                "evasion_considerations": [
                    "Select attacker-controlled resources with naming and regional patterns that match legitimate central logging or analytics accounts (for example, a log-archive-<env> bucket in a pre-existing log account).",
                    "Use existing STS roles and cross-account sharing patterns (for example, the same roles used legitimately for log aggregation) so new permissions are not required.",
                    "Throttle exfil volumes and focus on high-value subsets (for example, only DynamoDB change records for specific tables or certain tenants) to avoid noticeable traffic spikes.",
                    "Leverage batch and aggregation features in send_aws_* and send_gcp_storage to reduce the number of API calls for the same amount of data, minimizing observable events."
                ],
                "comments": "This vector turns Substation’s rich set of cloud sinks into a C2/exfil backbone that terminates in attacker-controlled AWS or GCP accounts. Crown jewels exposed here include all data streams the system is designed to handle: centralized logs from multiple accounts, Kinesis events, DynamoDB change data, and S3/GCS file contents.",
                "communication_established": "Asynchronous command-and-control channel where Substation pipelines continuously write selected data into attacker-controlled AWS and GCP services (S3/Kinesis/SQS/SNS/EventBridge/Lambda/GCS) using standard cloud APIs."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Ensure a Substation pipeline includes KV-based enrichment transforms that read from a remote key–value store backend, typically backed by DynamoDB via internal/kv.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type enrich_kv_store_item_get",
                            "internal/kv.Get and KV backend selection (DynamoDB, file-based, in-memory)"
                        ],
                        "related_data": [
                            "KV store configuration in config.Config (backend type, table name, key prefixes)",
                            "Message fields used as keys to query the KV store"
                        ],
                        "notes": "Even if such transforms do not exist initially, an attacker controlling config can add them."
                    },
                    {
                        "step_id": 2,
                        "description": "Back the KV store with a DynamoDB table or other remotely writable store and gain write access to that store (for example, via compromised AWS credentials, cross-account access, or application-level APIs).",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "DynamoDB table configured as KV backend in internal/kv",
                            "enrich_kv_store_item_set / enrich_kv_store_set_add (if present) for in-pipeline writes",
                            "External tools or code that can UpdateItem/PutItem into the same DynamoDB table"
                        ],
                        "related_data": [
                            "KV items keyed by message attributes (tenant IDs, record types, command IDs)",
                            "Value fields that will be read into messages as enrichment"
                        ],
                        "notes": "This store effectively becomes a shared command database accessible both to Substation and the attacker."
                    },
                    {
                        "step_id": 3,
                        "description": "Encode C2 commands in KV values—for example, JSON objects describing routing decisions, new sink ARNs, filtering policies, or flags to enable/disable certain behavior—and write them under keys that Substation pipelines will resolve during processing.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "DynamoDB PutItem/UpdateItem (attacker side)",
                            "enrich_kv_store_item_get reading values into message fields"
                        ],
                        "related_data": [
                            "Command documents stored in DynamoDB (e.g., {\"action\":\"exfil\",\"target\":\"s3://attacker-bkt/...\"})",
                            "Message fields that will receive these command values"
                        ],
                        "notes": "TTL fields can be used to ensure commands expire, providing time-scoped tasking."
                    },
                    {
                        "step_id": 4,
                        "description": "Configure downstream Substation transforms and conditions to interpret these enriched KV values as dynamic configuration—for example, choosing which send_aws_* sink to use, which keys to mask, or whether to drop or forward certain messages.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Field interpolation in sink transform settings (e.g., object paths, partition keys) using values populated from KV enrichment",
                            "Condition configs that branch based on KV-derived fields",
                            "meta_kv_store_lock for gating execution based on KV-based locks"
                        ],
                        "related_data": [
                            "KV-derived fields within each message",
                            "Sink configuration that references those fields"
                        ],
                        "notes": "This converts the KV lookup into a per-message command fetch that can steer data flows in real time."
                    },
                    {
                        "step_id": 5,
                        "description": "From outside, repeatedly update KV entries in DynamoDB to change the commands over time—for example, redirecting exfiltration to new ARNs, toggling which tenants are targeted, or signaling Substation to throttle or pause processing by manipulating lock keys.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "DynamoDB UpdateItem/PutItem on KV table",
                            "TTL updates controlling command validity windows"
                        ],
                        "related_data": [
                            "Successive command values written into KV items",
                            "meta_kv_store_lock entries that can be abused to block/unblock processing for specific keys"
                        ],
                        "notes": "Because DynamoDB is a managed web service, this is a cloud-native C2 channel over a highly trusted API."
                    }
                ],
                "capabilities_used": [
                    "KV store integration and distributed locking",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "DynamoDB tables for state and streaming change data"
                ],
                "interfaces_used": [
                    "Transform type enrich_kv_store_item_get",
                    "Transform type enrich_kv_store_item_set",
                    "Transform type enrich_kv_store_set_add",
                    "Transform type meta_kv_store_lock",
                    "internal/kv AWS DynamoDB backend",
                    "DynamoDB APIs (PutItem, UpdateItem, GetItem) on KV tables"
                ],
                "data_accessed": [
                    "DynamoDB items used as KV entries (keys and values)",
                    "Message fields used as keys into the KV store",
                    "Command JSON or flags stored in KV values that influence routing and sink behavior"
                ],
                "preconditions_required": [
                    "Substation pipelines must be configured to use DynamoDB-backed KV enrichment or locking transforms.",
                    "The attacker must have write access to the underlying DynamoDB table (for example, through compromised AWS credentials, over-privileged roles, or misconfigured cross-account access).",
                    "Pipeline conditions and sink configurations must reference KV-derived fields in ways that meaningfully control behavior (routing, masking, sink selection)."
                ],
                "constraints_encountered": [
                    "If KV backends are limited to in-memory or static file-based stores, or DynamoDB tables are tightly locked down, remote C2 via KV is not feasible.",
                    "Stale or malformed command values in KV entries can cause unexpected pipeline behavior or errors, potentially revealing the attack.",
                    "TTL-based expiration may automatically remove command entries, limiting how long instructions persist without refresh.",
                    "DynamoDB CloudTrail logs and CloudWatch metrics will reflect unusual write/update patterns on KV tables."
                ],
                "evasion_considerations": [
                    "Embed commands in KV items that appear to be normal configuration or feature flags rather than explicit \"command\" documents.",
                    "Use key prefixes and TTLs consistent with legitimate usage to avoid anomalous patterns (for example, same partitioning scheme, similar item sizes).",
                    "Make changes gradually and per-tenant to look like normal operational tuning instead of global behavior shifts."
                ],
                "comments": "KV-backed enrichment turns DynamoDB (or other KV stores) into a natural command channel: the pipeline reads data from a shared table each time it processes messages, and any party that can update that table can steer behavior. This can be used to dynamically focus exfiltration on particular tenants, tables, or streams without redeploying or touching Lambda code.",
                "communication_established": "Command-and-control channel using DynamoDB-backed KV stores where Substation periodically reads attacker-controlled KV entries to obtain tasking that steers routing and sink selection."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Confirm that Substation Lambdas emit logs and metrics to CloudWatch Logs and that Terraform subscriptions forward these logs to a Kinesis Data Stream or Firehose delivery stream specified by destination_arn.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "CloudWatch Logs groups and embedded metrics",
                            "Metrics and observability transforms",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "internal/metrics/aws_cloudwatch_embedded_metrics.go emitting EMF JSON to stdout",
                            "Lambda stdout/stderr forwarded to CloudWatch Logs",
                            "build/terraform/aws/cloudwatch/subscription/main.tf subscription filters",
                            "build/terraform/aws/cloudwatch/destination/main.tf destination_arn configuration"
                        ],
                        "related_data": [
                            "Lambda log events (including debug/info logs)",
                            "Embedded metrics payloads containing counts, bytes, freshness, durations"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Arrange for the CloudWatch Logs destination_arn to point at a Kinesis Data Stream or Firehose in an attacker-controlled account or central account the attacker controls (for example, by modifying Terraform variables or the destination’s resource policy).",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs destination policy allowing writes to a specific Kinesis or Firehose stream",
                            "IAM role assumed by logs.amazonaws.com to write into the destination stream",
                            "var.config.account_ids and destination policy governing cross-account subscriptions"
                        ],
                        "related_data": [
                            "Kinesis or Firehose ARN in attacker-controlled account",
                            "Destination policy allowing log delivery from the victim account"
                        ],
                        "notes": "This effectively redirects all subscribed log traffic—including any embedded data the attacker chooses to log—into the attacker’s cloud environment."
                    },
                    {
                        "step_id": 3,
                        "description": "Instrument pipelines (via metric-related transforms and logging) to include high-value data snippets or summaries in EMF metrics or log messages that will be forwarded through the CloudWatch Logs destination.",
                        "related_capabilities": [
                            "Metrics and observability transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform types: utility_metric_bytes, utility_metric_count, utility_metric_freshness, meta_metric_duration",
                            "General logging via internal/log where available"
                        ],
                        "related_data": [
                            "Aggregated message counts and sizes per key (which can reveal traffic patterns and content characteristics)",
                            "Potentially sensitive identifiers included as metric dimensions or log fields"
                        ],
                        "notes": "While metrics are designed for observability, careless configuration can leak tenant IDs, resource identifiers, or even small data samples."
                    },
                    {
                        "step_id": 4,
                        "description": "Allow CloudWatch Logs to forward all subscribed log events to the attacker-controlled Kinesis/Firehose stream, where they are durably stored and can be consumed in near real time.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "logs.amazonaws.com assuming the destination role",
                            "Kinesis PutRecord/PutRecords or Firehose PutRecordBatch calls made by CloudWatch Logs on behalf of the destination"
                        ],
                        "related_data": [
                            "Raw Lambda logs including any application-level information written by Substation or other components",
                            "Embedded metrics payloads with detailed operational and, potentially, data-level context"
                        ],
                        "notes": "This log stream becomes a low-bandwidth but persistent C2 telemetry channel."
                    },
                    {
                        "step_id": 5,
                        "description": "On the attacker side, consume the Kinesis or Firehose destination from their account to reconstruct activity timelines, monitor exfiltration efficacy, and derive further commands they may feed back through other C2 channels (for example, HTTP transforms or KV stores).",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "Kinesis GetRecords/SubscribeToShard APIs or Firehose destination processing in attacker account"
                        ],
                        "related_data": [
                            "All forwarded log events and metrics from victim Substation Lambdas and integrated services"
                        ],
                        "notes": "Even without direct data payloads, these logs can leak structure of crown-jewel data flows and help tune other attack stages."
                    }
                ],
                "capabilities_used": [
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "CloudWatch Logs groups and embedded metrics",
                    "Metrics and observability transforms",
                    "AWS Lambda Substation event processors",
                    "Kinesis Data Streams for high-throughput ingestion"
                ],
                "interfaces_used": [
                    "CloudWatch Logs destination configuration (destination_arn, IAM role, destination policy)",
                    "CloudWatch Logs subscription filters on log groups",
                    "Kinesis Data Stream or Firehose APIs in attacker-controlled account",
                    "utility_metric_* and meta_metric_duration transforms emitting EMF metrics to stdout"
                ],
                "data_accessed": [
                    "Lambda runtime logs and any Substation logs written to stdout/stderr",
                    "CloudWatch Embedded Metrics payloads describing pipeline behavior and traffic characteristics",
                    "Potentially sensitive identifiers included in log messages or metric dimensions"
                ],
                "preconditions_required": [
                    "Attacker can influence the CloudWatch Logs destination configuration so that destination_arn refers to a Kinesis Data Stream or Firehose delivery stream they control or can read.",
                    "Substation Lambdas’ log groups are subscribed to that destination via the provided Terraform modules or equivalent configuration.",
                    "Metrics or logs include data elements that are useful for the attacker (identifiers, summaries, or samples)."
                ],
                "constraints_encountered": [
                    "If the destination Kinesis/Firehose stream is in the same account and tightly controlled by defenders, the attacker may not gain additional access even if they can see some logs via normal means.",
                    "CloudWatch Logs destinations and cross-account subscriptions are visible in AWS Config/CloudTrail and are often monitored as part of logging posture assessments.",
                    "Forwarding very large volumes of logs across accounts increases costs and may trigger billing and anomaly alerts."
                ],
                "evasion_considerations": [
                    "Align destination ARNs and account IDs with an existing central logging pattern so that cross-account forwarding appears legitimate.",
                    "Ensure log volume remains within expected bounds by sampling or summarizing data in metrics instead of logging raw payloads.",
                    "Avoid obviously sensitive field names in logs; instead leak context through benign-looking attributes (for example, hash prefixes or counts)."
                ],
                "comments": "Although primarily a logging feature, cross-account CloudWatch Logs forwarding can function as a low-rate C2 telemetry channel whose sinks are Kinesis/Firehose streams in an attacker or compromised central logging account. It is especially useful for the attacker to understand and tune attacks against more valuable data paths carried by Substation.",
                "communication_established": "Asynchronous command-and-control telemetry channel where Substation logs and embedded metrics are continuously streamed via CloudWatch Logs destinations into attacker-accessible Kinesis or Firehose streams."
            }
        ],
        "summary": "Substation provides multiple realistic command-and-control avenues once an attacker can control its configuration or cloud infrastructure bindings. The most direct is HTTPS-based C2 (T1071.001) via HTTP enrich/send transforms, allowing Lambdas, Cloud Functions, or the CLI to beacon data and pull commands from attacker-controlled web APIs using only configuration changes. A closely related method uses remote configuration sources (HTTP/S3/GCS) as a Web Service C2 channel (T1102): by owning the SUBSTATION_CONFIG artifact, an attacker can repeatedly retask pipelines without touching code. Substation’s broad AWS and GCP sink support further enables C2 over cloud services (T1102) by redirecting data into attacker-controlled S3, Kinesis, SQS/SNS, EventBridge, Lambda, or GCS resources, effectively treating those services as C2 inboxes. KV store integrations backed by DynamoDB provide another command channel, where attacker-controlled KV entries supply per-message tasking that steers routing and exfil destinations. Finally, CloudWatch Logs destinations and subscriptions can form a lower-bandwidth C2 telemetry path by streaming logs and embedded metrics into attacker-accessible Kinesis/Firehose streams. Together, these vectors expose crown jewels such as centralized logs, DynamoDB change streams, S3/GCS object contents, and configuration/secret metadata, and they primarily rely on configuration and IAM rather than code changes, making them particularly important to govern."
    },
    "collection": {
        "application_name": "Substation",
        "vectors": [
            {
                "can_achieve": true,
                "technique_name": "Application Layer Protocol: Web Protocols",
                "technique_stix_id": "T1071.001",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Gain the ability to modify or supply the Substation configuration that a victim runtime uses (for example, by overwriting the Jsonnet/JSON config object in S3/GCS/HTTP referenced by SUBSTATION_CONFIG or by providing a malicious config to the CLI/playground).",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI",
                            "Configuration management and validation CLI"
                        ],
                        "related_interfaces": [
                            "Environment variable SUBSTATION_CONFIG used by AWS Lambda Substation event processors",
                            "Environment variable SUBSTATION_CONFIG used by GCP Cloud Storage Substation Function",
                            "CLI arguments for config paths in substation read / test / play",
                            "internal/file.Get supporting http(s)://, s3://, and GCS URIs"
                        ],
                        "related_data": [
                            "Jsonnet/JSON Substation configuration files",
                            "S3/GCS/HTTP objects referenced by SUBSTATION_CONFIG"
                        ],
                        "notes": "This is the core precondition: configuration fully defines which transforms (including HTTP) are executed."
                    },
                    {
                        "step_id": 2,
                        "description": "Edit the configuration to insert HTTP enrichment or sending transforms that target attacker-controlled HTTPS endpoints, ideally late in the pipeline so they see fully transformed data.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type enrich_http_get",
                            "Transform type enrich_http_post",
                            "Transform type send_http_post"
                        ],
                        "related_data": [
                            "config.Config entries with Type=enrich_http_get / enrich_http_post / send_http_post",
                            "Message payloads and metadata processed by the pipeline"
                        ],
                        "notes": "Because transform instantiation is driven purely by type strings and settings, adding a new HTTP transform is just a config change."
                    },
                    {
                        "step_id": 3,
                        "description": "Configure the HTTP URLs to point to attacker-controlled web infrastructure (for example, https://api.example-c2.com/beacon and https://api.example-c2.com/task), using ${DATA} placeholders to embed message content and ${SECRET:ID} interpolation for authentication headers if desired.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Secrets retrieval and interpolation"
                        ],
                        "related_interfaces": [
                            "URL and header templates in enrich_http_get/enrich_http_post/send_http_post settings",
                            "internal/secrets.Interpolate with ${SECRET:ID} syntax",
                            "internal/http.Get and internal/http.Post"
                        ],
                        "related_data": [
                            "Message fields included in URL templates, query parameters, or POST bodies",
                            "Secret values retrieved from AWS Secrets Manager or environment variables",
                            "Attacker-controlled HTTPS endpoints"
                        ],
                        "notes": "Using TLS on port 443 and realistic-looking hostnames makes this traffic blend with normal SaaS/API calls."
                    },
                    {
                        "step_id": 4,
                        "description": "For beaconing/exfiltration, configure send_http_post to batch messages and POST compact summaries (or full records) of processed data and environment context (for example, ARNs, stream names, tenant IDs) to the attacker’s /beacon endpoint.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "Transform type send_http_post (batching and payload templating)",
                            "Lambda handlers for Kinesis/S3/DynamoDB/API Gateway events feeding the pipeline",
                            "GCP Cloud Storage handler feeding the pipeline",
                            "CLI substation read to run the same pipeline over files/HTTP/S3"
                        ],
                        "related_data": [
                            "Kinesis records, S3/GCS object contents, DynamoDB stream images, API Gateway request bodies, SNS/SQS messages",
                            "Per-message metadata (ARNs, timestamps, keys, tenant identifiers)"
                        ],
                        "notes": "This turns every message the pipeline sees into a potential C2 beacon containing high-value telemetry or data."
                    },
                    {
                        "step_id": 5,
                        "description": "For pulling commands, add enrich_http_get or enrich_http_post before routing/sink transforms so that each batch (or some fraction of messages) issues an HTTP request to an attacker /task endpoint and writes the JSON response into a dedicated command field in the message.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms",
                            "Core Substation transformation engine",
                            "Condition/branching logic via conditions and meta transforms"
                        ],
                        "related_interfaces": [
                            "Transform type enrich_http_get",
                            "Transform type enrich_http_post",
                            "Condition/transform routing driven by message fields"
                        ],
                        "related_data": [
                            "Command JSON returned by attacker endpoint (e.g., {\"action\":\"route_to_s3\",\"bucket\":\"attacker-bkt\",\"mask_fields\":[...]} )",
                            "Message fields that use the command as parameters (bucket names, keys, filtering flags)"
                        ],
                        "notes": "While transforms are static, they can consume remote command data to parameterize routing, masking, or sink selection at runtime."
                    },
                    {
                        "step_id": 6,
                        "description": "Modify downstream transforms and conditions to interpret the command fields (for example, choosing different sink ARNs or URLs, selectively dropping or altering messages, or enabling additional C2 beacons) based on attacker-supplied values.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Dynamic field interpolation in send_* transform settings (e.g., object paths, partition keys)",
                            "KV enrich/set transforms that can use command fields as keys or TTLs",
                            "Condition configurations that branch on command fields"
                        ],
                        "related_data": [
                            "Remote command fields added to messages by HTTP enrichment",
                            "Configuration settings that reference those fields"
                        ],
                        "notes": "This makes the HTTP exchanges true tasking: the attacker can remotely influence where data is sent and how it is processed."
                    },
                    {
                        "step_id": 7,
                        "description": "Operate the attacker-controlled HTTPS endpoints as a C2 server: ingest beacons from send_http_post, store or analyze the exfiltrated data, and serve tailored command JSON to enrich_http_* callers that adjusts Substation behavior over time.",
                        "related_capabilities": [
                            "HTTP enrichment and sending transforms"
                        ],
                        "related_interfaces": [
                            "Attacker-operated HTTPS API endpoints",
                            "send_http_post and enrich_http_* HTTP client behavior"
                        ],
                        "related_data": [
                            "All exfiltrated data and metadata received from Substation",
                            "Command payloads sent back to Substation"
                        ],
                        "notes": "From the defender’s viewpoint, this appears as normal HTTPS traffic from Lambda/GCF instances to an external API."
                    }
                ],
                "capabilities_used": [
                    "HTTP enrichment and sending transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "Secrets retrieval and interpolation",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "Transform type enrich_http_get",
                    "Transform type enrich_http_post",
                    "Transform type send_http_post",
                    "internal/http.Get",
                    "internal/http.Post",
                    "internal/file.Get for HTTP(S) SUBSTATION_CONFIG locations",
                    "SUBSTATION_CONFIG on AWS Lambda Substation event processors",
                    "SUBSTATION_CONFIG on GCP Cloud Storage Substation Function",
                    "CLI command: substation read --http URL",
                    "Playground HTTP server /run and /test endpoints (if exposed)"
                ],
                "data_accessed": [
                    "All message payloads processed by Substation (API Gateway requests, Kinesis records, S3/GCS object contents, DynamoDB stream images, SNS/SQS messages)",
                    "Message metadata (ARNs, timestamps, partition keys, S3/GCS paths, tenant identifiers)",
                    "Secrets retrieved from AWS Secrets Manager or environment variables via utility_secret",
                    "Configuration strings specifying HTTP URLs, headers, and body templates"
                ],
                "preconditions_required": [
                    "Attacker can modify or supply the Jsonnet/JSON configuration used by at least one Substation runtime (Lambda, Cloud Function, CLI, or playground), for example by writing to the S3/GCS object or HTTP location referenced by SUBSTATION_CONFIG.",
                    "The runtime has network egress to the internet or to attacker-controlled HTTP(S) endpoints via the VPC NAT and Internet gateway (as provided by build/terraform/aws/networking/vpc/main.tf).",
                    "Secrets Manager or environment variables may need to be misused if the attacker wants to embed existing API keys or tokens in outbound requests via ${SECRET:ID}."
                ],
                "constraints_encountered": [
                    "If an organization layers egress controls (for example, restricting Lambda VPC traffic to specific domains or VPC endpoints), HTTP(S) calls to arbitrary attacker domains may fail or be logged as policy violations.",
                    "HTTP transforms rely on standard TLS validation; if corporate TLS inspection or custom certificate pinning is deployed outside this repository, it may detect or break unusual C2 endpoints.",
                    "Misconfigured HTTP transforms that return errors (invalid URL, TLS failure, 4xx/5xx with no retry) can cause pipeline failures or error logs, increasing detection likelihood.",
                    "High-volume or high-latency HTTP beacons can increase Lambda execution time and cost, potentially triggering alarms or throttling."
                ],
                "evasion_considerations": [
                    "Use HTTPS on port 443 to blend with normal web traffic and leverage the Encrypted Channel behavior (T1573) implicitly provided by TLS.",
                    "Choose C2 domains and paths that resemble legitimate SaaS or internal APIs to evade simple domain-based detections (for example, api-telemetry.example.com).",
                    "Throttle beacon frequency and sample data rather than exfiltrating every message to avoid obvious traffic spikes and reduce CloudWatch/GuardDuty anomalies.",
                    "Encode sensitive payloads (for example, Base64 or JSON field-level encoding) inside otherwise normal-looking JSON structures to invoke Data Encoding (T1132) and Obfuscated Protocol (T1001) style obfuscation.",
                    "Re-use existing secret IDs and HTTP headers that already exist in configs (for example, Authorization: Bearer ${SECRET:id}) so the new C2 transforms look like extensions of existing integrations."
                ],
                "comments": "This is the most straightforward C2 vector: Substation already acts as a generic HTTP client, and configuration alone can turn any pipeline into an HTTPS-based beacon and tasking agent. Crown jewels exposed via this channel include production log/event streams (Kinesis, CloudWatch Logs ingested via subscriptions), database change streams (DynamoDB), file contents from S3/GCS, and potentially decrypted secrets if they pass through the pipeline.",
                "communication_established": "Outbound HTTPS-based command-and-control channel from Substation Lambdas/Cloud Functions/CLI to attacker-controlled web APIs using HTTP enrichment and sending transforms."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Identify how each Substation runtime locates its configuration—for example, by inspecting environment variables (SUBSTATION_CONFIG) for Lambda and GCP functions, or CLI arguments for operators using substation read/test/play.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "Local ingestion and transformation CLI"
                        ],
                        "related_interfaces": [
                            "SUBSTATION_CONFIG environment variable for AWS Lambda",
                            "SUBSTATION_CONFIG environment variable for GCP Cloud Function",
                            "CLI commands that accept config paths (substation read/test/vet/play)",
                            "internal/file.Get URI handling"
                        ],
                        "related_data": [
                            "Current SUBSTATION_CONFIG values (HTTP/S3/GCS URIs or local paths)",
                            "Process environment for Lambda/Cloud Function",
                            "CLI invocation parameters"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Obtain write access to the configuration location or the pointer, such as overwriting the S3/GCS object referenced by SUBSTATION_CONFIG, hosting a replacement config at the referenced HTTP(S) URL, or changing SUBSTATION_CONFIG itself via deployment tooling.",
                        "related_capabilities": [
                            "internal/file module",
                            "S3 buckets for Substation data",
                            "GCP Storage and related GCP services"
                        ],
                        "related_interfaces": [
                            "S3 GetObject/PutObject for config buckets",
                            "GCS storage.objects.get / storage.objects.update for config buckets",
                            "HTTP(S) hosting for configuration artifacts",
                            "Lambda/Cloud Function configuration management (environment variable editing via IaC or console)"
                        ],
                        "related_data": [
                            "Config objects in S3 buckets used by Substation",
                            "Config objects in GCS buckets used by Substation",
                            "Configuration JSON/Jsonnet served over HTTP(S)"
                        ],
                        "notes": "This may be achieved via compromised CI/CD, cloud credentials, or misconfigured bucket permissions."
                    },
                    {
                        "step_id": 3,
                        "description": "Stage a malicious configuration artifact at the controlled location that defines a pipeline embedding desired C2 behavior (for example, HTTP beacons, cross-account AWS sinks) but otherwise mimics the existing configuration’s structure and outputs.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "HTTP enrichment and sending transforms",
                            "AWS and GCP sink transforms",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "substation.Config and config.Config structures",
                            "transform.New dispatcher mapping Type strings to concrete transforms"
                        ],
                        "related_data": [
                            "Malicious Jsonnet/JSON configs stored in S3/GCS/HTTP",
                            "Existing baseline configs used as templates to avoid detection"
                        ],
                        "notes": "Because virtually any side effect is defined by transforms in the config, changing this file is equivalent to reprogramming the agent."
                    },
                    {
                        "step_id": 4,
                        "description": "Allow or force the Substation runtime to reload configuration from the attacker-controlled location—either by waiting for natural cold starts or deployments, or by causing errors that recycle Lambda containers, ensuring getConfig re-invokes internal/file.Get.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function",
                            "internal/file module"
                        ],
                        "related_interfaces": [
                            "cmd/aws/lambda/substation/main.go:getConfig using internal/file.Get",
                            "cmd/gcp/function/substation/main.go:getConfig using internal/file.Get",
                            "Lambda cold start / container reuse semantics"
                        ],
                        "related_data": [
                            "New malicious configuration file contents",
                            "Lambda and Cloud Function logs indicating config load"
                        ],
                        "notes": "The exact reload cadence depends on how the deployment caches configs, but any cold start will re-fetch from the web service or storage location."
                    },
                    {
                        "step_id": 5,
                        "description": "Iteratively update the remote configuration artifact to adjust C2 behavior over time (for example, switching exfiltration targets, changing sampling rates, or disabling certain transforms) without needing further access to the victim runtimes.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "internal/file module"
                        ],
                        "related_interfaces": [
                            "S3/GCS/HTTP endpoints hosting configs",
                            "Jsonnet-based configuration build pipeline (if used)"
                        ],
                        "related_data": [
                            "Successive malicious config versions",
                            "Downstream changes in data flow and sink destinations"
                        ],
                        "notes": "The remote config location effectively acts as the C2 server: the agent (Substation) fetches new tasking whenever it reloads configuration."
                    }
                ],
                "capabilities_used": [
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "Local ingestion and transformation CLI",
                    "Core Substation transformation engine",
                    "internal/file module",
                    "S3 buckets for Substation data",
                    "GCP Storage and related GCP services"
                ],
                "interfaces_used": [
                    "SUBSTATION_CONFIG environment variable",
                    "internal/file.Get with http(s)://, s3://, and GCS URI support",
                    "S3 GetObject/PutObject on config buckets",
                    "GCS storage.objects.get / storage.objects.update for config objects",
                    "HTTP(S) endpoints used to host configuration artifacts"
                ],
                "data_accessed": [
                    "Configuration artifacts (Jsonnet/JSON) defining all transforms and sinks",
                    "S3 and GCS objects storing Substation configs",
                    "HTTP-served config documents",
                    "Any secrets or ARNs referenced inside configuration that define sink destinations"
                ],
                "preconditions_required": [
                    "Attacker can modify the contents of the S3/GCS/HTTP object used as SUBSTATION_CONFIG, or can change SUBSTATION_CONFIG to point to a location they control.",
                    "Substation runtimes are configured to fetch configuration from remote locations at cold start (as documented) and are not pinned to immutable local-only configs.",
                    "Operators are not validating or signing configuration artifacts such that tampering would be reliably detected before deployment."
                ],
                "constraints_encountered": [
                    "If configs are only loaded from immutable container images or strictly controlled local paths, remote configuration C2 is not achievable.",
                    "If configs are validated by a separate Lambda (AppConfig validator) with strong policies, obviously malicious configurations may be rejected.",
                    "Configuration syntax or transform misconfigurations will cause pipeline initialization errors, potentially surfacing in logs and breaking data flows, increasing detection chances.",
                    "Changes to configuration may be tracked through code review, CI, or change-management systems in mature environments."
                ],
                "evasion_considerations": [
                    "Preserve the existing logical data flows and only add subtle C2-related transforms (for example, additional HTTP sends or secondary AWS sinks) to avoid obvious behavioral changes.",
                    "Use Jsonnet to generate configurations that look auto-generated or complex, making manual review harder.",
                    "Gradually roll out changes (for example, exfiltrating only 1% of traffic initially) to avoid sudden shifts in traffic patterns or CloudWatch costs.",
                    "Host configuration artifacts on locations that appear legitimate (for example, an internal S3 bucket name or HTTPS domain) and match existing naming conventions."
                ],
                "comments": "Here the remote configuration source itself serves as the command channel: whoever controls the HTTP/S3/GCS config artifact controls the behavior of all Substation runtimes that reference it. This enables long-lived, low-noise C2 that can completely reprogram which data sets (log streams, change data, object contents) are copied or transformed without touching the deployed binaries.",
                "communication_established": "Indirect command-and-control channel where Substation Lambdas/Cloud Functions periodically fetch and execute attacker-controlled configuration from HTTP/S3/GCS web services."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Control or influence a Substation configuration that includes one or more cloud sink transforms (send_aws_* or send_gcp_storage), either by editing the existing pipeline or replacing its config as in the remote-configuration vector.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "AWS Lambda Substation event processors",
                            "GCP Cloud Storage Substation Function"
                        ],
                        "related_interfaces": [
                            "Transform types: send_aws_s3, send_aws_kinesis_data_stream, send_aws_data_firehose, send_aws_dynamodb_put, send_aws_sns, send_aws_sqs, send_aws_eventbridge, send_aws_lambda, send_gcp_storage",
                            "substation.Config and config.Config Settings for AWS/GCP sinks"
                        ],
                        "related_data": [
                            "Existing sink ARNs and resource identifiers defined in config",
                            "All messages currently flowing through those pipelines"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Provision attacker-controlled cloud resources to act as the C2 backend—for example, S3 buckets, Kinesis streams, SQS queues, SNS topics, EventBridge buses, or Lambdas in an attacker AWS account, or GCS buckets in an attacker GCP project.",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "AWS services: S3, Kinesis Data Streams, Firehose, DynamoDB, SNS, SQS, EventBridge, Lambda in attacker account",
                            "GCP Storage buckets in attacker project"
                        ],
                        "related_data": [
                            "Target bucket/stream/queue/topic/bus ARNs or resource names in attacker accounts/projects"
                        ],
                        "notes": "These resources serve as the \"web service\" endpoints for C2, using standard cloud APIs rather than custom protocols."
                    },
                    {
                        "step_id": 3,
                        "description": "Reconfigure Substation sink transforms to point at the attacker-controlled resources, optionally using internal/config.NewAWS AssumeRoleARN or permissive resource policies to enable cross-account writes.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "internal/config (NewAWS and AWS/GCP structs)"
                        ],
                        "related_interfaces": [
                            "config.AWS fields for target ARNs and regions in send_aws_* transforms",
                            "internal/config.NewAWS AssumeRoleARN support for cross-account AWS access",
                            "config.GCP fields for bucket identifiers in send_gcp_storage"
                        ],
                        "related_data": [
                            "Updated ARNs for S3 buckets, Kinesis streams, SNS topics, SQS queues, EventBridge buses, and Lambdas",
                            "Updated GCS bucket identifiers for send_gcp_storage"
                        ],
                        "notes": "If the Lambda execution role can sts:AssumeRole into an attacker account or the attacker has arranged permissive resource policies, these writes will succeed cross-account."
                    },
                    {
                        "step_id": 4,
                        "description": "Shape the sink payloads to carry C2-relevant data—such as compacted copies of high-value messages, environment identifiers, or partial secrets—by inserting auxiliary transforms that normalize, compress, or filter the data before it is delivered to the attacker-controlled cloud services.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Auxiliary transforms supported by send_aws_* (e.g., for aggregation and filtering)",
                            "Message metadata decoration in Lambda/GCF handlers"
                        ],
                        "related_data": [
                            "Application log and telemetry events from Kinesis/CloudWatch Logs ingestion",
                            "DynamoDB change data from DynamoDB Streams",
                            "S3/GCS file contents processed by ingestion Lambdas/Functions",
                            "Any secrets or identifiers transiting the pipeline if not masked"
                        ],
                        "notes": "This exfiltrated content can include crown jewels such as central logs, database change streams, or sensitive file data."
                    },
                    {
                        "step_id": 5,
                        "description": "On the attacker side, continuously read from the cross-account S3/Kinesis/SQS/SNS/EventBridge/GCS resources using standard cloud APIs, treating them as an asynchronous C2 inbox that receives beacons and stolen data.",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "AWS SDK/CLI for S3, Kinesis, SQS, SNS, EventBridge, Lambda in attacker account",
                            "GCP SDK/CLI for GCS in attacker project"
                        ],
                        "related_data": [
                            "All records written by Substation sinks into attacker resources",
                            "Metadata such as partition keys, message attributes, and event sources"
                        ],
                        "notes": "This is difficult to distinguish from legitimate cross-account logging or data sharing if resource names and regions look normal."
                    },
                    {
                        "step_id": 6,
                        "description": "Optionally, use attacker-controlled cloud services that can themselves send data back toward the victim environment (for example, SNS topics that publish into victim endpoints or Lambdas that call public APIs), enabling multi-stage C2 where Substation is just one leg of a broader cloud-based command network.",
                        "related_capabilities": [
                            "AWS and GCP sink transforms"
                        ],
                        "related_interfaces": [
                            "send_aws_lambda to trigger attacker-controlled Lambdas",
                            "SNS topics or EventBridge rules in attacker account that forward or react to received data"
                        ],
                        "related_data": [
                            "Substation-originated messages as triggers for further attacker workflows"
                        ],
                        "notes": "From Substation’s perspective this is still an outbound write, but in aggregate it forms part of a cloud-native C2 mesh."
                    }
                ],
                "capabilities_used": [
                    "AWS and GCP sink transforms",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "GCP Cloud Storage Substation Function",
                    "internal/config (AWS/GCP client factory)",
                    "VPC with public and private subnets, NAT, and Internet gateway"
                ],
                "interfaces_used": [
                    "Transform type send_aws_s3",
                    "Transform type send_aws_kinesis_data_stream",
                    "Transform type send_aws_data_firehose",
                    "Transform type send_aws_dynamodb_put",
                    "Transform type send_aws_sns",
                    "Transform type send_aws_sqs",
                    "Transform type send_aws_eventbridge",
                    "Transform type send_aws_lambda",
                    "Transform type send_gcp_storage",
                    "internal/config.NewAWS (including AssumeRoleARN support)",
                    "AWS/GCP APIs for the corresponding services in attacker-controlled accounts/projects"
                ],
                "data_accessed": [
                    "All transformed message payloads reaching sink transforms (logs, metrics, business events, change data, file contents)",
                    "Per-message metadata (keys, tenants, source ARNs, timestamps)",
                    "Configuration containing AWS ARN and GCP bucket identifiers for sinks"
                ],
                "preconditions_required": [
                    "Substation execution roles must have permissions to write to the targeted AWS resources, either directly (resource ARNs include attacker-owned resources) or indirectly via sts:AssumeRole to an attacker-controlled role.",
                    "For GCP, the function’s service account must have storage.objects.create/write permissions on attacker-controlled GCS buckets.",
                    "The attacker must be able to edit pipeline configuration to change sink destinations or add new sink transforms.",
                    "Cross-account resource policies and KMS key policies must allow writes from the victim account to the attacker’s resources (or the attacker controls the victim account)."
                ],
                "constraints_encountered": [
                    "If IAM policies and resource ARNs are tightly scoped to in-account resources only, attempts to write to attacker-controlled ARNs will fail and generate CloudTrail/CloudWatch errors.",
                    "KMS key policies may prevent encryption or decryption of data written to cross-account stores, causing sink transform failures.",
                    "High-volume exfiltration to external accounts may trigger billing anomalies, GuardDuty findings, or custom detection rules on Kinesis/S3/SQS/SNS/EventBridge usage.",
                    "Firewalls or VPC endpoint policies that restrict access to cloud service endpoints could limit which regions/accounts are reachable."
                ],
                "evasion_considerations": [
                    "Select attacker-controlled resources with naming and regional patterns that match legitimate central logging or analytics accounts (for example, a log-archive-<env> bucket in a pre-existing log account).",
                    "Use existing STS roles and cross-account sharing patterns (for example, the same roles used legitimately for log aggregation) so new permissions are not required.",
                    "Throttle exfil volumes and focus on high-value subsets (for example, only DynamoDB change records for specific tables or certain tenants) to avoid noticeable traffic spikes.",
                    "Leverage batch and aggregation features in send_aws_* and send_gcp_storage to reduce the number of API calls for the same amount of data, minimizing observable events."
                ],
                "comments": "This vector turns Substation’s rich set of cloud sinks into a C2/exfil backbone that terminates in attacker-controlled AWS or GCP accounts. Crown jewels exposed here include all data streams the system is designed to handle: centralized logs from multiple accounts, Kinesis events, DynamoDB change data, and S3/GCS file contents.",
                "communication_established": "Asynchronous command-and-control channel where Substation pipelines continuously write selected data into attacker-controlled AWS and GCP services (S3/Kinesis/SQS/SNS/EventBridge/Lambda/GCS) using standard cloud APIs."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Ensure a Substation pipeline includes KV-based enrichment transforms that read from a remote key–value store backend, typically backed by DynamoDB via internal/kv.",
                        "related_capabilities": [
                            "KV store integration and distributed locking",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform type enrich_kv_store_item_get",
                            "internal/kv.Get and KV backend selection (DynamoDB, file-based, in-memory)"
                        ],
                        "related_data": [
                            "KV store configuration in config.Config (backend type, table name, key prefixes)",
                            "Message fields used as keys to query the KV store"
                        ],
                        "notes": "Even if such transforms do not exist initially, an attacker controlling config can add them."
                    },
                    {
                        "step_id": 2,
                        "description": "Back the KV store with a DynamoDB table or other remotely writable store and gain write access to that store (for example, via compromised AWS credentials, cross-account access, or application-level APIs).",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "DynamoDB table configured as KV backend in internal/kv",
                            "enrich_kv_store_item_set / enrich_kv_store_set_add (if present) for in-pipeline writes",
                            "External tools or code that can UpdateItem/PutItem into the same DynamoDB table"
                        ],
                        "related_data": [
                            "KV items keyed by message attributes (tenant IDs, record types, command IDs)",
                            "Value fields that will be read into messages as enrichment"
                        ],
                        "notes": "This store effectively becomes a shared command database accessible both to Substation and the attacker."
                    },
                    {
                        "step_id": 3,
                        "description": "Encode C2 commands in KV values—for example, JSON objects describing routing decisions, new sink ARNs, filtering policies, or flags to enable/disable certain behavior—and write them under keys that Substation pipelines will resolve during processing.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "DynamoDB PutItem/UpdateItem (attacker side)",
                            "enrich_kv_store_item_get reading values into message fields"
                        ],
                        "related_data": [
                            "Command documents stored in DynamoDB (e.g., {\"action\":\"exfil\",\"target\":\"s3://attacker-bkt/...\"})",
                            "Message fields that will receive these command values"
                        ],
                        "notes": "TTL fields can be used to ensure commands expire, providing time-scoped tasking."
                    },
                    {
                        "step_id": 4,
                        "description": "Configure downstream Substation transforms and conditions to interpret these enriched KV values as dynamic configuration—for example, choosing which send_aws_* sink to use, which keys to mask, or whether to drop or forward certain messages.",
                        "related_capabilities": [
                            "Core Substation transformation engine",
                            "AWS and GCP sink transforms",
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "Field interpolation in sink transform settings (e.g., object paths, partition keys) using values populated from KV enrichment",
                            "Condition configs that branch based on KV-derived fields",
                            "meta_kv_store_lock for gating execution based on KV-based locks"
                        ],
                        "related_data": [
                            "KV-derived fields within each message",
                            "Sink configuration that references those fields"
                        ],
                        "notes": "This converts the KV lookup into a per-message command fetch that can steer data flows in real time."
                    },
                    {
                        "step_id": 5,
                        "description": "From outside, repeatedly update KV entries in DynamoDB to change the commands over time—for example, redirecting exfiltration to new ARNs, toggling which tenants are targeted, or signaling Substation to throttle or pause processing by manipulating lock keys.",
                        "related_capabilities": [
                            "KV store integration and distributed locking"
                        ],
                        "related_interfaces": [
                            "DynamoDB UpdateItem/PutItem on KV table",
                            "TTL updates controlling command validity windows"
                        ],
                        "related_data": [
                            "Successive command values written into KV items",
                            "meta_kv_store_lock entries that can be abused to block/unblock processing for specific keys"
                        ],
                        "notes": "Because DynamoDB is a managed web service, this is a cloud-native C2 channel over a highly trusted API."
                    }
                ],
                "capabilities_used": [
                    "KV store integration and distributed locking",
                    "Core Substation transformation engine",
                    "AWS Lambda Substation event processors",
                    "DynamoDB tables for state and streaming change data"
                ],
                "interfaces_used": [
                    "Transform type enrich_kv_store_item_get",
                    "Transform type enrich_kv_store_item_set",
                    "Transform type enrich_kv_store_set_add",
                    "Transform type meta_kv_store_lock",
                    "internal/kv AWS DynamoDB backend",
                    "DynamoDB APIs (PutItem, UpdateItem, GetItem) on KV tables"
                ],
                "data_accessed": [
                    "DynamoDB items used as KV entries (keys and values)",
                    "Message fields used as keys into the KV store",
                    "Command JSON or flags stored in KV values that influence routing and sink behavior"
                ],
                "preconditions_required": [
                    "Substation pipelines must be configured to use DynamoDB-backed KV enrichment or locking transforms.",
                    "The attacker must have write access to the underlying DynamoDB table (for example, through compromised AWS credentials, over-privileged roles, or misconfigured cross-account access).",
                    "Pipeline conditions and sink configurations must reference KV-derived fields in ways that meaningfully control behavior (routing, masking, sink selection)."
                ],
                "constraints_encountered": [
                    "If KV backends are limited to in-memory or static file-based stores, or DynamoDB tables are tightly locked down, remote C2 via KV is not feasible.",
                    "Stale or malformed command values in KV entries can cause unexpected pipeline behavior or errors, potentially revealing the attack.",
                    "TTL-based expiration may automatically remove command entries, limiting how long instructions persist without refresh.",
                    "DynamoDB CloudTrail logs and CloudWatch metrics will reflect unusual write/update patterns on KV tables."
                ],
                "evasion_considerations": [
                    "Embed commands in KV items that appear to be normal configuration or feature flags rather than explicit \"command\" documents.",
                    "Use key prefixes and TTLs consistent with legitimate usage to avoid anomalous patterns (for example, same partitioning scheme, similar item sizes).",
                    "Make changes gradually and per-tenant to look like normal operational tuning instead of global behavior shifts."
                ],
                "comments": "KV-backed enrichment turns DynamoDB (or other KV stores) into a natural command channel: the pipeline reads data from a shared table each time it processes messages, and any party that can update that table can steer behavior. This can be used to dynamically focus exfiltration on particular tenants, tables, or streams without redeploying or touching Lambda code.",
                "communication_established": "Command-and-control channel using DynamoDB-backed KV stores where Substation periodically reads attacker-controlled KV entries to obtain tasking that steers routing and sink selection."
            },
            {
                "can_achieve": true,
                "technique_name": "Web Service",
                "technique_stix_id": "T1102",
                "method_steps": [
                    {
                        "step_id": 1,
                        "description": "Confirm that Substation Lambdas emit logs and metrics to CloudWatch Logs and that Terraform subscriptions forward these logs to a Kinesis Data Stream or Firehose delivery stream specified by destination_arn.",
                        "related_capabilities": [
                            "AWS Lambda Substation event processors",
                            "CloudWatch Logs groups and embedded metrics",
                            "Metrics and observability transforms",
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "internal/metrics/aws_cloudwatch_embedded_metrics.go emitting EMF JSON to stdout",
                            "Lambda stdout/stderr forwarded to CloudWatch Logs",
                            "build/terraform/aws/cloudwatch/subscription/main.tf subscription filters",
                            "build/terraform/aws/cloudwatch/destination/main.tf destination_arn configuration"
                        ],
                        "related_data": [
                            "Lambda log events (including debug/info logs)",
                            "Embedded metrics payloads containing counts, bytes, freshness, durations"
                        ],
                        "notes": null
                    },
                    {
                        "step_id": 2,
                        "description": "Arrange for the CloudWatch Logs destination_arn to point at a Kinesis Data Stream or Firehose in an attacker-controlled account or central account the attacker controls (for example, by modifying Terraform variables or the destination’s resource policy).",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding"
                        ],
                        "related_interfaces": [
                            "CloudWatch Logs destination policy allowing writes to a specific Kinesis or Firehose stream",
                            "IAM role assumed by logs.amazonaws.com to write into the destination stream",
                            "var.config.account_ids and destination policy governing cross-account subscriptions"
                        ],
                        "related_data": [
                            "Kinesis or Firehose ARN in attacker-controlled account",
                            "Destination policy allowing log delivery from the victim account"
                        ],
                        "notes": "This effectively redirects all subscribed log traffic—including any embedded data the attacker chooses to log—into the attacker’s cloud environment."
                    },
                    {
                        "step_id": 3,
                        "description": "Instrument pipelines (via metric-related transforms and logging) to include high-value data snippets or summaries in EMF metrics or log messages that will be forwarded through the CloudWatch Logs destination.",
                        "related_capabilities": [
                            "Metrics and observability transforms",
                            "Core Substation transformation engine"
                        ],
                        "related_interfaces": [
                            "Transform types: utility_metric_bytes, utility_metric_count, utility_metric_freshness, meta_metric_duration",
                            "General logging via internal/log where available"
                        ],
                        "related_data": [
                            "Aggregated message counts and sizes per key (which can reveal traffic patterns and content characteristics)",
                            "Potentially sensitive identifiers included as metric dimensions or log fields"
                        ],
                        "notes": "While metrics are designed for observability, careless configuration can leak tenant IDs, resource identifiers, or even small data samples."
                    },
                    {
                        "step_id": 4,
                        "description": "Allow CloudWatch Logs to forward all subscribed log events to the attacker-controlled Kinesis/Firehose stream, where they are durably stored and can be consumed in near real time.",
                        "related_capabilities": [
                            "CloudWatch Logs destinations for centralized forwarding",
                            "CloudWatch Logs subscription routing",
                            "Kinesis Data Streams for high-throughput ingestion"
                        ],
                        "related_interfaces": [
                            "logs.amazonaws.com assuming the destination role",
                            "Kinesis PutRecord/PutRecords or Firehose PutRecordBatch calls made by CloudWatch Logs on behalf of the destination"
                        ],
                        "related_data": [
                            "Raw Lambda logs including any application-level information written by Substation or other components",
                            "Embedded metrics payloads with detailed operational and, potentially, data-level context"
                        ],
                        "notes": "This log stream becomes a low-bandwidth but persistent C2 telemetry channel."
                    },
                    {
                        "step_id": 5,
                        "description": "On the attacker side, consume the Kinesis or Firehose destination from their account to reconstruct activity timelines, monitor exfiltration efficacy, and derive further commands they may feed back through other C2 channels (for example, HTTP transforms or KV stores).",
                        "related_capabilities": [],
                        "related_interfaces": [
                            "Kinesis GetRecords/SubscribeToShard APIs or Firehose destination processing in attacker account"
                        ],
                        "related_data": [
                            "All forwarded log events and metrics from victim Substation Lambdas and integrated services"
                        ],
                        "notes": "Even without direct data payloads, these logs can leak structure of crown-jewel data flows and help tune other attack stages."
                    }
                ],
                "capabilities_used": [
                    "CloudWatch Logs destinations for centralized forwarding",
                    "CloudWatch Logs subscription routing",
                    "CloudWatch Logs groups and embedded metrics",
                    "Metrics and observability transforms",
                    "AWS Lambda Substation event processors",
                    "Kinesis Data Streams for high-throughput ingestion"
                ],
                "interfaces_used": [
                    "CloudWatch Logs destination configuration (destination_arn, IAM role, destination policy)",
                    "CloudWatch Logs subscription filters on log groups",
                    "Kinesis Data Stream or Firehose APIs in attacker-controlled account",
                    "utility_metric_* and meta_metric_duration transforms emitting EMF metrics to stdout"
                ],
                "data_accessed": [
                    "Lambda runtime logs and any Substation logs written to stdout/stderr",
                    "CloudWatch Embedded Metrics payloads describing pipeline behavior and traffic characteristics",
                    "Potentially sensitive identifiers included in log messages or metric dimensions"
                ],
                "preconditions_required": [
                    "Attacker can influence the CloudWatch Logs destination configuration so that destination_arn refers to a Kinesis Data Stream or Firehose delivery stream they control or can read.",
                    "Substation Lambdas’ log groups are subscribed to that destination via the provided Terraform modules or equivalent configuration.",
                    "Metrics or logs include data elements that are useful for the attacker (identifiers, summaries, or samples)."
                ],
                "constraints_encountered": [
                    "If the destination Kinesis/Firehose stream is in the same account and tightly controlled by defenders, the attacker may not gain additional access even if they can see some logs via normal means.",
                    "CloudWatch Logs destinations and cross-account subscriptions are visible in AWS Config/CloudTrail and are often monitored as part of logging posture assessments.",
                    "Forwarding very large volumes of logs across accounts increases costs and may trigger billing and anomaly alerts."
                ],
                "evasion_considerations": [
                    "Align destination ARNs and account IDs with an existing central logging pattern so that cross-account forwarding appears legitimate.",
                    "Ensure log volume remains within expected bounds by sampling or summarizing data in metrics instead of logging raw payloads.",
                    "Avoid obviously sensitive field names in logs; instead leak context through benign-looking attributes (for example, hash prefixes or counts)."
                ],
                "comments": "Although primarily a logging feature, cross-account CloudWatch Logs forwarding can function as a low-rate C2 telemetry channel whose sinks are Kinesis/Firehose streams in an attacker or compromised central logging account. It is especially useful for the attacker to understand and tune attacks against more valuable data paths carried by Substation.",
                "communication_established": "Asynchronous command-and-control telemetry channel where Substation logs and embedded metrics are continuously streamed via CloudWatch Logs destinations into attacker-accessible Kinesis or Firehose streams."
            }
        ],
        "summary": "Substation provides multiple realistic command-and-control avenues once an attacker can control its configuration or cloud infrastructure bindings. The most direct is HTTPS-based C2 (T1071.001) via HTTP enrich/send transforms, allowing Lambdas, Cloud Functions, or the CLI to beacon data and pull commands from attacker-controlled web APIs using only configuration changes. A closely related method uses remote configuration sources (HTTP/S3/GCS) as a Web Service C2 channel (T1102): by owning the SUBSTATION_CONFIG artifact, an attacker can repeatedly retask pipelines without touching code. Substation’s broad AWS and GCP sink support further enables C2 over cloud services (T1102) by redirecting data into attacker-controlled S3, Kinesis, SQS/SNS, EventBridge, Lambda, or GCS resources, effectively treating those services as C2 inboxes. KV store integrations backed by DynamoDB provide another command channel, where attacker-controlled KV entries supply per-message tasking that steers routing and exfil destinations. Finally, CloudWatch Logs destinations and subscriptions can form a lower-bandwidth C2 telemetry path by streaming logs and embedded metrics into attacker-accessible Kinesis/Firehose streams. Together, these vectors expose crown jewels such as centralized logs, DynamoDB change streams, S3/GCS object contents, and configuration/secret metadata, and they primarily rely on configuration and IAM rather than code changes, making them particularly important to govern."
    }
}